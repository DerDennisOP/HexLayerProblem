// Generated by Futhark 0.24.0 (prerelease - include info below when reporting bugs)
// git: 0dca3bc5f056efb62bdaa5886573b479273977cf

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_program_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_program_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_u8_1d;
struct futhark_u8_1d *futhark_new_u8_1d(struct futhark_context *ctx, const uint8_t *data, int64_t dim0);
struct futhark_u8_1d *futhark_new_raw_u8_1d(struct futhark_context *ctx, const CUdeviceptr data, int64_t offset, int64_t dim0);
int futhark_free_u8_1d(struct futhark_context *ctx, struct futhark_u8_1d *arr);
int futhark_values_u8_1d(struct futhark_context *ctx, struct futhark_u8_1d *arr, uint8_t *data);
CUdeviceptr futhark_values_raw_u8_1d(struct futhark_context *ctx, struct futhark_u8_1d *arr);
const int64_t *futhark_shape_u8_1d(struct futhark_context *ctx, struct futhark_u8_1d *arr);

// Opaque values



// Entry points
int futhark_entry_main(struct futhark_context *ctx, bool *out0, struct futhark_u8_1d **out1, struct futhark_u8_1d **out2, struct futhark_u8_1d **out3, struct futhark_u8_1d **out4, struct futhark_u8_1d **out5, struct futhark_u8_1d **out6);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_report(struct futhark_context *ctx);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}


static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

static uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

static float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

static uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
#include <getopt.h>
#include <ctype.h>
#include <inttypes.h>
#include <unistd.h>
// Start of values.h.

//// Text I/O

typedef int (*writer)(FILE*, const void*);
typedef int (*bin_reader)(void*);
typedef int (*str_reader)(const char *, void*);

struct array_reader {
  char* elems;
  int64_t n_elems_space;
  int64_t elem_size;
  int64_t n_elems_used;
  int64_t *shape;
  str_reader elem_reader;
};

static void skipspaces(FILE *f) {
  int c;
  do {
    c = getc(f);
  } while (isspace(c));

  if (c != EOF) {
    ungetc(c, f);
  }
}

static int constituent(char c) {
  return isalnum(c) || c == '.' || c == '-' || c == '+' || c == '_';
}

// Produces an empty token only on EOF.
static void next_token(FILE *f, char *buf, int bufsize) {
 start:
  skipspaces(f);

  int i = 0;
  while (i < bufsize) {
    int c = getc(f);
    buf[i] = (char)c;

    if (c == EOF) {
      buf[i] = 0;
      return;
    } else if (c == '-' && i == 1 && buf[0] == '-') {
      // Line comment, so skip to end of line and start over.
      for (; c != '\n' && c != EOF; c = getc(f));
      goto start;
    } else if (!constituent((char)c)) {
      if (i == 0) {
        // We permit single-character tokens that are not
        // constituents; this lets things like ']' and ',' be
        // tokens.
        buf[i+1] = 0;
        return;
      } else {
        ungetc(c, f);
        buf[i] = 0;
        return;
      }
    }

    i++;
  }

  buf[bufsize-1] = 0;
}

static int next_token_is(FILE *f, char *buf, int bufsize, const char* expected) {
  next_token(f, buf, bufsize);
  return strcmp(buf, expected) == 0;
}

static void remove_underscores(char *buf) {
  char *w = buf;

  for (char *r = buf; *r; r++) {
    if (*r != '_') {
      *w++ = *r;
    }
  }

  *w++ = 0;
}

static int read_str_elem(char *buf, struct array_reader *reader) {
  int ret;
  if (reader->n_elems_used == reader->n_elems_space) {
    reader->n_elems_space *= 2;
    reader->elems = (char*) realloc(reader->elems,
                                    (size_t)(reader->n_elems_space * reader->elem_size));
  }

  ret = reader->elem_reader(buf, reader->elems + reader->n_elems_used * reader->elem_size);

  if (ret == 0) {
    reader->n_elems_used++;
  }

  return ret;
}

static int read_str_array_elems(FILE *f,
                                char *buf, int bufsize,
                                struct array_reader *reader, int64_t dims) {
  int ret;
  int first = 1;
  char *knows_dimsize = (char*) calloc((size_t)dims, sizeof(char));
  int cur_dim = (int)dims-1;
  int64_t *elems_read_in_dim = (int64_t*) calloc((size_t)dims, sizeof(int64_t));

  while (1) {
    next_token(f, buf, bufsize);

    if (strcmp(buf, "]") == 0) {
      if (knows_dimsize[cur_dim]) {
        if (reader->shape[cur_dim] != elems_read_in_dim[cur_dim]) {
          ret = 1;
          break;
        }
      } else {
        knows_dimsize[cur_dim] = 1;
        reader->shape[cur_dim] = elems_read_in_dim[cur_dim];
      }
      if (cur_dim == 0) {
        ret = 0;
        break;
      } else {
        cur_dim--;
        elems_read_in_dim[cur_dim]++;
      }
    } else if (strcmp(buf, ",") == 0) {
      next_token(f, buf, bufsize);
      if (strcmp(buf, "[") == 0) {
        if (cur_dim == dims - 1) {
          ret = 1;
          break;
        }
        first = 1;
        cur_dim++;
        elems_read_in_dim[cur_dim] = 0;
      } else if (cur_dim == dims - 1) {
        ret = read_str_elem(buf, reader);
        if (ret != 0) {
          break;
        }
        elems_read_in_dim[cur_dim]++;
      } else {
        ret = 1;
        break;
      }
    } else if (strlen(buf) == 0) {
      // EOF
      ret = 1;
      break;
    } else if (first) {
      if (strcmp(buf, "[") == 0) {
        if (cur_dim == dims - 1) {
          ret = 1;
          break;
        }
        cur_dim++;
        elems_read_in_dim[cur_dim] = 0;
      } else {
        ret = read_str_elem(buf, reader);
        if (ret != 0) {
          break;
        }
        elems_read_in_dim[cur_dim]++;
        first = 0;
      }
    } else {
      ret = 1;
      break;
    }
  }

  free(knows_dimsize);
  free(elems_read_in_dim);
  return ret;
}

static int read_str_empty_array(FILE *f, char *buf, int bufsize,
                                const char *type_name, int64_t *shape, int64_t dims) {
  if (strlen(buf) == 0) {
    // EOF
    return 1;
  }

  if (strcmp(buf, "empty") != 0) {
    return 1;
  }

  if (!next_token_is(f, buf, bufsize, "(")) {
    return 1;
  }

  for (int i = 0; i < dims; i++) {
    if (!next_token_is(f, buf, bufsize, "[")) {
      return 1;
    }

    next_token(f, buf, bufsize);

    if (sscanf(buf, "%"SCNu64, (uint64_t*)&shape[i]) != 1) {
      return 1;
    }

    if (!next_token_is(f, buf, bufsize, "]")) {
      return 1;
    }
  }

  if (!next_token_is(f, buf, bufsize, type_name)) {
    return 1;
  }


  if (!next_token_is(f, buf, bufsize, ")")) {
    return 1;
  }

  // Check whether the array really is empty.
  for (int i = 0; i < dims; i++) {
    if (shape[i] == 0) {
      return 0;
    }
  }

  // Not an empty array!
  return 1;
}

static int read_str_array(FILE *f,
                          int64_t elem_size, str_reader elem_reader,
                          const char *type_name,
                          void **data, int64_t *shape, int64_t dims) {
  int ret;
  struct array_reader reader;
  char buf[100];

  int dims_seen;
  for (dims_seen = 0; dims_seen < dims; dims_seen++) {
    if (!next_token_is(f, buf, sizeof(buf), "[")) {
      break;
    }
  }

  if (dims_seen == 0) {
    return read_str_empty_array(f, buf, sizeof(buf), type_name, shape, dims);
  }

  if (dims_seen != dims) {
    return 1;
  }

  reader.shape = shape;
  reader.n_elems_used = 0;
  reader.elem_size = elem_size;
  reader.n_elems_space = 16;
  reader.elems = (char*) realloc(*data, (size_t)(elem_size*reader.n_elems_space));
  reader.elem_reader = elem_reader;

  ret = read_str_array_elems(f, buf, sizeof(buf), &reader, dims);

  *data = reader.elems;

  return ret;
}

#define READ_STR(MACRO, PTR, SUFFIX)                                   \
  remove_underscores(buf);                                              \
  int j;                                                                \
  if (sscanf(buf, "%"MACRO"%n", (PTR*)dest, &j) == 1) {                 \
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, SUFFIX) == 0);     \
  } else {                                                              \
    return 1;                                                           \
  }

static int read_str_i8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNi8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(int8_t*)dest = (int8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "i8") == 0);
  } else {
    return 1;
  }
}

static int read_str_u8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNu8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(uint8_t*)dest = (uint8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "u8") == 0);
  } else {
    return 1;
  }
}

static int read_str_i16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "i16");
}

static int read_str_u16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "u16");
}

static int read_str_i32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "i32");
}

static int read_str_u32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "u32");
}

static int read_str_i64(char *buf, void* dest) {
  READ_STR(SCNi64, int64_t, "i64");
}

static int read_str_u64(char *buf, void* dest) {
  // FIXME: This is not correct, as SCNu64 only permits decimal
  // literals.  However, SCNi64 does not handle very large numbers
  // correctly (it's really for signed numbers, so that's fair).
  READ_STR(SCNu64, uint64_t, "u64");
}

static int read_str_f16(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f16.nan") == 0) {
    *(uint16_t*)dest = float2halfbits(NAN);
    return 0;
  } else if (strcmp(buf, "f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(INFINITY);
    return 0;
  } else if (strcmp(buf, "-f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(-INFINITY);
    return 0;
  } else {
    int j;
    float x;
    if (sscanf(buf, "%f%n", &x, &j) == 1) {
      if (strcmp(buf+j, "") == 0 || strcmp(buf+j, "f16") == 0) {
        *(uint16_t*)dest = float2halfbits(x);
        return 0;
      }
    }
    return 1;
  }
}

static int read_str_f32(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f32.nan") == 0) {
    *(float*)dest = (float)NAN;
    return 0;
  } else if (strcmp(buf, "f32.inf") == 0) {
    *(float*)dest = (float)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f32.inf") == 0) {
    *(float*)dest = (float)-INFINITY;
    return 0;
  } else {
    READ_STR("f", float, "f32");
  }
}

static int read_str_f64(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f64.nan") == 0) {
    *(double*)dest = (double)NAN;
    return 0;
  } else if (strcmp(buf, "f64.inf") == 0) {
    *(double*)dest = (double)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f64.inf") == 0) {
    *(double*)dest = (double)-INFINITY;
    return 0;
  } else {
    READ_STR("lf", double, "f64");
  }
}

static int read_str_bool(char *buf, void* dest) {
  if (strcmp(buf, "true") == 0) {
    *(char*)dest = 1;
    return 0;
  } else if (strcmp(buf, "false") == 0) {
    *(char*)dest = 0;
    return 0;
  } else {
    return 1;
  }
}

static int write_str_i8(FILE *out, int8_t *src) {
  return fprintf(out, "%hhdi8", *src);
}

static int write_str_u8(FILE *out, uint8_t *src) {
  return fprintf(out, "%hhuu8", *src);
}

static int write_str_i16(FILE *out, int16_t *src) {
  return fprintf(out, "%hdi16", *src);
}

static int write_str_u16(FILE *out, uint16_t *src) {
  return fprintf(out, "%huu16", *src);
}

static int write_str_i32(FILE *out, int32_t *src) {
  return fprintf(out, "%di32", *src);
}

static int write_str_u32(FILE *out, uint32_t *src) {
  return fprintf(out, "%uu32", *src);
}

static int write_str_i64(FILE *out, int64_t *src) {
  return fprintf(out, "%"PRIi64"i64", *src);
}

static int write_str_u64(FILE *out, uint64_t *src) {
  return fprintf(out, "%"PRIu64"u64", *src);
}

static int write_str_f16(FILE *out, uint16_t *src) {
  float x = halfbits2float(*src);
  if (isnan(x)) {
    return fprintf(out, "f16.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f16.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f16.inf");
  } else {
    return fprintf(out, "%.6ff16", x);
  }
}

static int write_str_f32(FILE *out, float *src) {
  float x = *src;
  if (isnan(x)) {
    return fprintf(out, "f32.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f32.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f32.inf");
  } else {
    return fprintf(out, "%.6ff32", x);
  }
}

static int write_str_f64(FILE *out, double *src) {
  double x = *src;
  if (isnan(x)) {
    return fprintf(out, "f64.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f64.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f64.inf");
  } else {
    return fprintf(out, "%.6ff64", *src);
  }
}

static int write_str_bool(FILE *out, void *src) {
  return fprintf(out, *(char*)src ? "true" : "false");
}

//// Binary I/O

#define BINARY_FORMAT_VERSION 2
#define IS_BIG_ENDIAN (!*(unsigned char *)&(uint16_t){1})

static void flip_bytes(size_t elem_size, unsigned char *elem) {
  for (size_t j=0; j<elem_size/2; j++) {
    unsigned char head = elem[j];
    size_t tail_index = elem_size-1-j;
    elem[j] = elem[tail_index];
    elem[tail_index] = head;
  }
}

// On Windows we need to explicitly set the file mode to not mangle
// newline characters.  On *nix there is no difference.
#ifdef _WIN32
#include <io.h>
#include <fcntl.h>
static void set_binary_mode(FILE *f) {
  setmode(fileno(f), O_BINARY);
}
#else
static void set_binary_mode(FILE *f) {
  (void)f;
}
#endif

static int read_byte(FILE *f, void* dest) {
  size_t num_elems_read = fread(dest, 1, 1, f);
  return num_elems_read == 1 ? 0 : 1;
}

//// Types

struct primtype_info_t {
  const char binname[4]; // Used for parsing binary data.
  const char* type_name; // Same name as in Futhark.
  const int64_t size; // in bytes
  const writer write_str; // Write in text format.
  const str_reader read_str; // Read in text format.
};

static const struct primtype_info_t i8_info =
  {.binname = "  i8", .type_name = "i8",   .size = 1,
   .write_str = (writer)write_str_i8, .read_str = (str_reader)read_str_i8};
static const struct primtype_info_t i16_info =
  {.binname = " i16", .type_name = "i16",  .size = 2,
   .write_str = (writer)write_str_i16, .read_str = (str_reader)read_str_i16};
static const struct primtype_info_t i32_info =
  {.binname = " i32", .type_name = "i32",  .size = 4,
   .write_str = (writer)write_str_i32, .read_str = (str_reader)read_str_i32};
static const struct primtype_info_t i64_info =
  {.binname = " i64", .type_name = "i64",  .size = 8,
   .write_str = (writer)write_str_i64, .read_str = (str_reader)read_str_i64};
static const struct primtype_info_t u8_info =
  {.binname = "  u8", .type_name = "u8",   .size = 1,
   .write_str = (writer)write_str_u8, .read_str = (str_reader)read_str_u8};
static const struct primtype_info_t u16_info =
  {.binname = " u16", .type_name = "u16",  .size = 2,
   .write_str = (writer)write_str_u16, .read_str = (str_reader)read_str_u16};
static const struct primtype_info_t u32_info =
  {.binname = " u32", .type_name = "u32",  .size = 4,
   .write_str = (writer)write_str_u32, .read_str = (str_reader)read_str_u32};
static const struct primtype_info_t u64_info =
  {.binname = " u64", .type_name = "u64",  .size = 8,
   .write_str = (writer)write_str_u64, .read_str = (str_reader)read_str_u64};
static const struct primtype_info_t f16_info =
  {.binname = " f16", .type_name = "f16",  .size = 2,
   .write_str = (writer)write_str_f16, .read_str = (str_reader)read_str_f16};
static const struct primtype_info_t f32_info =
  {.binname = " f32", .type_name = "f32",  .size = 4,
   .write_str = (writer)write_str_f32, .read_str = (str_reader)read_str_f32};
static const struct primtype_info_t f64_info =
  {.binname = " f64", .type_name = "f64",  .size = 8,
   .write_str = (writer)write_str_f64, .read_str = (str_reader)read_str_f64};
static const struct primtype_info_t bool_info =
  {.binname = "bool", .type_name = "bool", .size = 1,
   .write_str = (writer)write_str_bool, .read_str = (str_reader)read_str_bool};

static const struct primtype_info_t* primtypes[] = {
  &i8_info, &i16_info, &i32_info, &i64_info,
  &u8_info, &u16_info, &u32_info, &u64_info,
  &f16_info, &f32_info, &f64_info,
  &bool_info,
  NULL // NULL-terminated
};

// General value interface.  All endian business taken care of at
// lower layers.

static int read_is_binary(FILE *f) {
  skipspaces(f);
  int c = getc(f);
  if (c == 'b') {
    int8_t bin_version;
    int ret = read_byte(f, &bin_version);

    if (ret != 0) { futhark_panic(1, "binary-input: could not read version.\n"); }

    if (bin_version != BINARY_FORMAT_VERSION) {
      futhark_panic(1, "binary-input: File uses version %i, but I only understand version %i.\n",
            bin_version, BINARY_FORMAT_VERSION);
    }

    return 1;
  }
  ungetc(c, f);
  return 0;
}

static const struct primtype_info_t* read_bin_read_type_enum(FILE *f) {
  char read_binname[4];

  int num_matched = fscanf(f, "%4c", read_binname);
  if (num_matched != 1) { futhark_panic(1, "binary-input: Couldn't read element type.\n"); }

  const struct primtype_info_t **type = primtypes;

  for (; *type != NULL; type++) {
    // I compare the 4 characters manually instead of using strncmp because
    // this allows any value to be used, also NULL bytes
    if (memcmp(read_binname, (*type)->binname, 4) == 0) {
      return *type;
    }
  }
  futhark_panic(1, "binary-input: Did not recognize the type '%s'.\n", read_binname);
  return NULL;
}

static void read_bin_ensure_scalar(FILE *f, const struct primtype_info_t *expected_type) {
  int8_t bin_dims;
  int ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != 0) {
    futhark_panic(1, "binary-input: Expected scalar (0 dimensions), but got array with %i dimensions.\n",
          bin_dims);
  }

  const struct primtype_info_t *bin_type = read_bin_read_type_enum(f);
  if (bin_type != expected_type) {
    futhark_panic(1, "binary-input: Expected scalar of type %s but got scalar of type %s.\n",
          expected_type->type_name,
          bin_type->type_name);
  }
}

//// High-level interface

static int read_bin_array(FILE *f,
                          const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  int ret;

  int8_t bin_dims;
  ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != dims) {
    futhark_panic(1, "binary-input: Expected %i dimensions, but got array with %i dimensions.\n",
          dims, bin_dims);
  }

  const struct primtype_info_t *bin_primtype = read_bin_read_type_enum(f);
  if (expected_type != bin_primtype) {
    futhark_panic(1, "binary-input: Expected %iD-array with element type '%s' but got %iD-array with element type '%s'.\n",
          dims, expected_type->type_name, dims, bin_primtype->type_name);
  }

  int64_t elem_count = 1;
  for (int i=0; i<dims; i++) {
    int64_t bin_shape;
    ret = (int)fread(&bin_shape, sizeof(bin_shape), 1, f);
    if (ret != 1) {
      futhark_panic(1, "binary-input: Couldn't read size for dimension %i of array.\n", i);
    }
    if (IS_BIG_ENDIAN) {
      flip_bytes(sizeof(bin_shape), (unsigned char*) &bin_shape);
    }
    elem_count *= bin_shape;
    shape[i] = bin_shape;
  }

  int64_t elem_size = expected_type->size;
  void* tmp = realloc(*data, (size_t)(elem_count * elem_size));
  if (tmp == NULL) {
    futhark_panic(1, "binary-input: Failed to allocate array of size %i.\n",
          elem_count * elem_size);
  }
  *data = tmp;

  int64_t num_elems_read = (int64_t)fread(*data, (size_t)elem_size, (size_t)elem_count, f);
  if (num_elems_read != elem_count) {
    futhark_panic(1, "binary-input: tried to read %i elements of an array, but only got %i elements.\n",
          elem_count, num_elems_read);
  }

  // If we're on big endian platform we must change all multibyte elements
  // from using little endian to big endian
  if (IS_BIG_ENDIAN && elem_size != 1) {
    flip_bytes((size_t)elem_size, (unsigned char*) *data);
  }

  return 0;
}

static int read_array(FILE *f, const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  if (!read_is_binary(f)) {
    return read_str_array(f, expected_type->size, (str_reader)expected_type->read_str, expected_type->type_name, data, shape, dims);
  } else {
    return read_bin_array(f, expected_type, data, shape, dims);
  }
}

static int end_of_input(FILE *f) {
  skipspaces(f);
  char token[2];
  next_token(f, token, sizeof(token));
  if (strcmp(token, "") == 0) {
    return 0;
  } else {
    return 1;
  }
}

static int write_str_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  if (rank==0) {
    elem_type->write_str(out, (const void*)data);
  } else {
    int64_t len = (int64_t)shape[0];
    int64_t slice_size = 1;

    int64_t elem_size = elem_type->size;
    for (int8_t i = 1; i < rank; i++) {
      slice_size *= shape[i];
    }

    if (len*slice_size == 0) {
      fprintf(out, "empty(");
      for (int64_t i = 0; i < rank; i++) {
        fprintf(out, "[%"PRIi64"]", shape[i]);
      }
      fprintf(out, "%s", elem_type->type_name);
      fprintf(out, ")");
    } else if (rank==1) {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        elem_type->write_str(out, (const void*) (data + i * elem_size));
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    } else {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        write_str_array(out, elem_type, data + i * slice_size * elem_size, shape+1, rank-1);
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    }
  }
  return 0;
}

static int write_bin_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  int64_t num_elems = 1;
  for (int64_t i = 0; i < rank; i++) {
    num_elems *= shape[i];
  }

  fputc('b', out);
  fputc((char)BINARY_FORMAT_VERSION, out);
  fwrite(&rank, sizeof(int8_t), 1, out);
  fwrite(elem_type->binname, 4, 1, out);
  if (shape != NULL) {
    fwrite(shape, sizeof(int64_t), (size_t)rank, out);
  }

  if (IS_BIG_ENDIAN) {
    for (int64_t i = 0; i < num_elems; i++) {
      const unsigned char *elem = data+i*elem_type->size;
      for (int64_t j = 0; j < elem_type->size; j++) {
        fwrite(&elem[elem_type->size-j], 1, 1, out);
      }
    }
  } else {
    fwrite(data, (size_t)elem_type->size, (size_t)num_elems, out);
  }

  return 0;
}

static int write_array(FILE *out, int write_binary,
                       const struct primtype_info_t *elem_type,
                       const void *data,
                       const int64_t *shape,
                       const int8_t rank) {
  if (write_binary) {
    return write_bin_array(out, elem_type, data, shape, rank);
  } else {
    return write_str_array(out, elem_type, data, shape, rank);
  }
}

static int read_scalar(FILE *f,
                       const struct primtype_info_t *expected_type, void *dest) {
  if (!read_is_binary(f)) {
    char buf[100];
    next_token(f, buf, sizeof(buf));
    return expected_type->read_str(buf, dest);
  } else {
    read_bin_ensure_scalar(f, expected_type);
    size_t elem_size = (size_t)expected_type->size;
    size_t num_elems_read = fread(dest, elem_size, 1, f);
    if (IS_BIG_ENDIAN) {
      flip_bytes(elem_size, (unsigned char*) dest);
    }
    return num_elems_read == 1 ? 0 : 1;
  }
}

static int write_scalar(FILE *out, int write_binary, const struct primtype_info_t *type, void *src) {
  if (write_binary) {
    return write_bin_array(out, type, src, NULL, 0);
  } else {
    return type->write_str(out, src);
  }
}

// End of values.h.

static int binary_output = 0;
static int print_result = 1;
static int print_report = 0;
static FILE *runtime_file;
static int perform_warmup = 0;
static int num_runs = 1;
static const char *entry_point = "main";
// Start of tuning.h.

static char* load_tuning_file(const char *fname,
                              void *cfg,
                              int (*set_tuning_param)(void*, const char*, size_t)) {
  const int max_line_len = 1024;
  char* line = (char*) malloc(max_line_len);

  FILE *f = fopen(fname, "r");

  if (f == NULL) {
    snprintf(line, max_line_len, "Cannot open file: %s", strerror(errno));
    return line;
  }

  int lineno = 0;
  while (fgets(line, max_line_len, f) != NULL) {
    lineno++;
    char *eql = strstr(line, "=");
    if (eql) {
      *eql = 0;
      int value = atoi(eql+1);
      if (set_tuning_param(cfg, line, (size_t)value) != 0) {
        char* err = (char*) malloc(max_line_len + 50);
        snprintf(err, max_line_len + 50, "Unknown name '%s' on line %d.", line, lineno);
        free(line);
        return err;
      }
    } else {
      snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
               lineno);
      return line;
    }
  }

  free(line);

  return NULL;
}

// End of tuning.h.

int parse_options(struct futhark_context_config *cfg, int argc, char *const argv[])
{
    int ch;
    static struct option long_options[] = {{"write-runtime-to", required_argument, NULL, 1}, {"runs", required_argument, NULL, 2}, {"debugging", no_argument, NULL, 3}, {"log", no_argument, NULL, 4}, {"entry-point", required_argument, NULL, 5}, {"binary-output", no_argument, NULL, 6}, {"no-print-result", no_argument, NULL, 7}, {"help", no_argument, NULL, 8}, {"print-params", no_argument, NULL, 9}, {"param", required_argument, NULL, 10}, {"tuning", required_argument, NULL, 11}, {"cache-file", required_argument, NULL, 12}, {"device", required_argument, NULL, 13}, {"default-group-size", required_argument, NULL, 14}, {"default-num-groups", required_argument, NULL, 15}, {"default-tile-size", required_argument, NULL, 16}, {"default-reg-tile-size", required_argument, NULL, 17}, {"default-threshold", required_argument, NULL, 18}, {"dump-cuda", required_argument, NULL, 19}, {"load-cuda", required_argument, NULL, 20}, {"dump-ptx", required_argument, NULL, 21}, {"load-ptx", required_argument, NULL, 22}, {"nvrtc-option", required_argument, NULL, 23}, {"profile", no_argument, NULL, 24}, {0, 0, 0, 0}};
    static char *option_descriptions = "  -t/--write-runtime-to FILE  Print the time taken to execute the program to the indicated file, an integral number of microseconds.\n  -r/--runs INT               Perform NUM runs of the program.\n  -D/--debugging              Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                    Print various low-overhead logging information to stderr while running.\n  -e/--entry-point NAME       The entry point to run. Defaults to main.\n  -b/--binary-output          Print the program result in the binary output format.\n  -n/--no-print-result        Do not print the program result.\n  -h/--help                   Print help information and exit.\n  --print-params              Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT          Set a tuning parameter to the given value.\n  --tuning FILE               Read size=value assignments from the given file.\n  --cache-file FILE           Store program cache here.\n  -d/--device NAME            Use the first OpenCL device whose name contains the given string.\n  --default-group-size INT    The default size of OpenCL workgroups that are launched.\n  --default-num-groups INT    The default number of OpenCL workgroups that are launched.\n  --default-tile-size INT     The default tile size used when performing two-dimensional tiling.\n  --default-reg-tile-size INT The default register tile size used when performing two-dimensional tiling.\n  --default-threshold INT     The default parallelism threshold.\n  --dump-cuda FILE            Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE            Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE             Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE             Load PTX code from the indicated file.\n  --nvrtc-option OPT          Add an additional build option to the string passed to NVRTC.\n  -P/--profile                Gather profiling data while executing and print out a summary at the end.\n";
    
    while ((ch = getopt_long(argc, argv, ":t:r:DLe:bnhd:P", long_options, NULL)) != -1) {
        if (ch == 1 || ch == 't') {
            runtime_file = fopen(optarg, "w");
            if (runtime_file == NULL)
                futhark_panic(1, "Cannot open %s: %s\n", optarg, strerror(errno));
        }
        if (ch == 2 || ch == 'r') {
            num_runs = atoi(optarg);
            perform_warmup = 1;
            if (num_runs <= 0)
                futhark_panic(1, "Need a positive number of runs, not %s\n", optarg);
        }
        if (ch == 3 || ch == 'D') {
            futhark_context_config_set_debugging(cfg, 1);
            print_report = 1;
        }
        if (ch == 4 || ch == 'L') {
            futhark_context_config_set_logging(cfg, 1);
            print_report = 1;
        }
        if (ch == 5 || ch == 'e') {
            if (entry_point != NULL)
                entry_point = optarg;
        }
        if (ch == 6 || ch == 'b')
            binary_output = 1;
        if (ch == 7 || ch == 'n')
            print_result = 0;
        if (ch == 8 || ch == 'h') {
            printf("Usage: %s [OPTION]...\nOptions:\n\n%s\nFor more information, consult the Futhark User's Guide or the man pages.\n", fut_progname, option_descriptions);
            exit(0);
        }
        if (ch == 9) {
            int n = futhark_get_tuning_param_count();
            
            for (int i = 0; i < n; i++)
                printf("%s (%s)\n", futhark_get_tuning_param_name(i), futhark_get_tuning_param_class(i));
            exit(0);
        }
        if (ch == 10) {
            char *name = optarg;
            char *equals = strstr(optarg, "=");
            char *value_str = equals != NULL ? equals + 1 : optarg;
            int value = atoi(value_str);
            
            if (equals != NULL) {
                *equals = 0;
                if (futhark_context_config_set_tuning_param(cfg, name, (size_t) value) != 0)
                    futhark_panic(1, "Unknown size: %s\n", name);
            } else
                futhark_panic(1, "Invalid argument for size option: %s\n", optarg);
        }
        if (ch == 11) {
            char *ret = load_tuning_file(optarg, cfg, (int (*)(void *, const char *, size_t)) futhark_context_config_set_tuning_param);
            
            if (ret != NULL)
                futhark_panic(1, "When loading tuning from '%s': %s\n", optarg, ret);
        }
        if (ch == 12)
            futhark_context_config_set_cache_file(cfg, optarg);
        if (ch == 13 || ch == 'd')
            futhark_context_config_set_device(cfg, optarg);
        if (ch == 14)
            futhark_context_config_set_default_group_size(cfg, atoi(optarg));
        if (ch == 15)
            futhark_context_config_set_default_num_groups(cfg, atoi(optarg));
        if (ch == 16)
            futhark_context_config_set_default_tile_size(cfg, atoi(optarg));
        if (ch == 17)
            futhark_context_config_set_default_reg_tile_size(cfg, atoi(optarg));
        if (ch == 18)
            futhark_context_config_set_default_threshold(cfg, atoi(optarg));
        if (ch == 19) {
            futhark_context_config_dump_program_to(cfg, optarg);
            entry_point = NULL;
        }
        if (ch == 20)
            futhark_context_config_load_program_from(cfg, optarg);
        if (ch == 21) {
            futhark_context_config_dump_ptx_to(cfg, optarg);
            entry_point = NULL;
        }
        if (ch == 22)
            futhark_context_config_load_ptx_from(cfg, optarg);
        if (ch == 23)
            futhark_context_config_add_nvrtc_option(cfg, optarg);
        if (ch == 24 || ch == 'P')
            futhark_context_config_set_profiling(cfg, 1);
        if (ch == ':')
            futhark_panic(-1, "Missing argument for option %s\n", argv[optind - 1]);
        if (ch == '?') {
            fprintf(stderr, "Usage: %s [OPTIONS]...\nOptions:\n\n%s\n", fut_progname, "  -t/--write-runtime-to FILE  Print the time taken to execute the program to the indicated file, an integral number of microseconds.\n  -r/--runs INT               Perform NUM runs of the program.\n  -D/--debugging              Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                    Print various low-overhead logging information to stderr while running.\n  -e/--entry-point NAME       The entry point to run. Defaults to main.\n  -b/--binary-output          Print the program result in the binary output format.\n  -n/--no-print-result        Do not print the program result.\n  -h/--help                   Print help information and exit.\n  --print-params              Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT          Set a tuning parameter to the given value.\n  --tuning FILE               Read size=value assignments from the given file.\n  --cache-file FILE           Store program cache here.\n  -d/--device NAME            Use the first OpenCL device whose name contains the given string.\n  --default-group-size INT    The default size of OpenCL workgroups that are launched.\n  --default-num-groups INT    The default number of OpenCL workgroups that are launched.\n  --default-tile-size INT     The default tile size used when performing two-dimensional tiling.\n  --default-reg-tile-size INT The default register tile size used when performing two-dimensional tiling.\n  --default-threshold INT     The default parallelism threshold.\n  --dump-cuda FILE            Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE            Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE             Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE             Load PTX code from the indicated file.\n  --nvrtc-option OPT          Add an additional build option to the string passed to NVRTC.\n  -P/--profile                Gather profiling data while executing and print out a summary at the end.\n");
            futhark_panic(1, "Unknown option: %s\n", argv[optind - 1]);
        }
    }
    return optind;
}
static int futrts_cli_entry_main(struct futhark_context *ctx)
{
    int64_t t_start, t_end;
    int time_runs = 0, profile_run = 0;
    int retval = 0;
    
    // We do not want to profile all the initialisation.
    futhark_context_pause_profiling(ctx);
    // Declare and read input.
    set_binary_mode(stdin);
    if (end_of_input(stdin) != 0)
        futhark_panic(1, "Expected EOF on stdin after reading input for \"%s\".\n", "main");
    
    bool result_0;
    struct futhark_u8_1d * result_1;
    struct futhark_u8_1d * result_2;
    struct futhark_u8_1d * result_3;
    struct futhark_u8_1d * result_4;
    struct futhark_u8_1d * result_5;
    struct futhark_u8_1d * result_6;
    
    if (perform_warmup) {
        int r;
        
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_main(ctx, &result_0, &result_1, &result_2, &result_3, &result_4, &result_5, &result_6);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        ;
        assert(futhark_free_u8_1d(ctx, result_1) == 0);
        assert(futhark_free_u8_1d(ctx, result_2) == 0);
        assert(futhark_free_u8_1d(ctx, result_3) == 0);
        assert(futhark_free_u8_1d(ctx, result_4) == 0);
        assert(futhark_free_u8_1d(ctx, result_5) == 0);
        assert(futhark_free_u8_1d(ctx, result_6) == 0);
    }
    time_runs = 1;
    // Proper run.
    for (int run = 0; run < num_runs; run++) {
        // Only profile last run.
        profile_run = run == num_runs - 1;
        
        int r;
        
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_main(ctx, &result_0, &result_1, &result_2, &result_3, &result_4, &result_5, &result_6);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        if (run < num_runs - 1) {
            ;
            assert(futhark_free_u8_1d(ctx, result_1) == 0);
            assert(futhark_free_u8_1d(ctx, result_2) == 0);
            assert(futhark_free_u8_1d(ctx, result_3) == 0);
            assert(futhark_free_u8_1d(ctx, result_4) == 0);
            assert(futhark_free_u8_1d(ctx, result_5) == 0);
            assert(futhark_free_u8_1d(ctx, result_6) == 0);
        }
    }
    if (print_result) {
        // Print the final result.
        if (binary_output)
            set_binary_mode(stdout);
        write_scalar(stdout, binary_output, &bool_info, &result_0);
        printf("\n");
        {
            uint8_t *arr = calloc(futhark_shape_u8_1d(ctx, result_1)[0], u8_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_u8_1d(ctx, result_1, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &u8_info, arr, futhark_shape_u8_1d(ctx, result_1), 1);
            free(arr);
        }
        printf("\n");
        {
            uint8_t *arr = calloc(futhark_shape_u8_1d(ctx, result_2)[0], u8_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_u8_1d(ctx, result_2, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &u8_info, arr, futhark_shape_u8_1d(ctx, result_2), 1);
            free(arr);
        }
        printf("\n");
        {
            uint8_t *arr = calloc(futhark_shape_u8_1d(ctx, result_3)[0], u8_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_u8_1d(ctx, result_3, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &u8_info, arr, futhark_shape_u8_1d(ctx, result_3), 1);
            free(arr);
        }
        printf("\n");
        {
            uint8_t *arr = calloc(futhark_shape_u8_1d(ctx, result_4)[0], u8_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_u8_1d(ctx, result_4, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &u8_info, arr, futhark_shape_u8_1d(ctx, result_4), 1);
            free(arr);
        }
        printf("\n");
        {
            uint8_t *arr = calloc(futhark_shape_u8_1d(ctx, result_5)[0], u8_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_u8_1d(ctx, result_5, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &u8_info, arr, futhark_shape_u8_1d(ctx, result_5), 1);
            free(arr);
        }
        printf("\n");
        {
            uint8_t *arr = calloc(futhark_shape_u8_1d(ctx, result_6)[0], u8_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_u8_1d(ctx, result_6, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &u8_info, arr, futhark_shape_u8_1d(ctx, result_6), 1);
            free(arr);
        }
        printf("\n");
    }
    
  print_end:
    { }
    ;
    assert(futhark_free_u8_1d(ctx, result_1) == 0);
    assert(futhark_free_u8_1d(ctx, result_2) == 0);
    assert(futhark_free_u8_1d(ctx, result_3) == 0);
    assert(futhark_free_u8_1d(ctx, result_4) == 0);
    assert(futhark_free_u8_1d(ctx, result_5) == 0);
    assert(futhark_free_u8_1d(ctx, result_6) == 0);
    return retval;
}
typedef int entry_point_fun(struct futhark_context *);
struct entry_point_entry {
    const char *name;
    entry_point_fun *fun;
};
int main(int argc, char **argv)
{
    int retval = 0;
    
    fut_progname = argv[0];
    
    struct futhark_context_config *cfg = futhark_context_config_new();
    
    assert(cfg != NULL);
    
    int parsed_options = parse_options(cfg, argc, argv);
    
    argc -= parsed_options;
    argv += parsed_options;
    if (argc != 0)
        futhark_panic(1, "Excess non-option: %s\n", argv[0]);
    
    struct futhark_context *ctx = futhark_context_new(cfg);
    
    assert(ctx != NULL);
    
    char *error = futhark_context_get_error(ctx);
    
    if (error != NULL)
        futhark_panic(1, "%s", error);
    
    struct entry_point_entry entry_points[] = {{.name ="main", .fun =futrts_cli_entry_main}};
    
    if (entry_point != NULL) {
        int num_entry_points = sizeof(entry_points) / sizeof(entry_points[0]);
        entry_point_fun *entry_point_fun = NULL;
        
        for (int i = 0; i < num_entry_points; i++) {
            if (strcmp(entry_points[i].name, entry_point) == 0) {
                entry_point_fun = entry_points[i].fun;
                break;
            }
        }
        if (entry_point_fun == NULL) {
            fprintf(stderr, "No entry point '%s'.  Select another with --entry-point.  Options are:\n", entry_point);
            for (int i = 0; i < num_entry_points; i++)
                fprintf(stderr, "%s\n", entry_points[i].name);
            return 1;
        }
        if (isatty(fileno(stdin))) {
            fprintf(stderr, "Reading input from TTY.\n");
            fprintf(stderr, "Send EOF (CTRL-d) after typing all input values.\n");
        }
        retval = entry_point_fun(ctx);
        if (runtime_file != NULL)
            fclose(runtime_file);
        if (print_report) {
            char *report = futhark_context_report(ctx);
            
            fputs(report, stderr);
            free(report);
        }
    }
    futhark_context_free(ctx);
    futhark_context_config_free(cfg);
    return retval;
}

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

static inline uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

static inline uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

static inline uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

static inline uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

static inline uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

static inline uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

static inline uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

static inline uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

static inline uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

static inline uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

static inline uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

static inline uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

static inline uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

static inline uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x / ys;
}

static inline uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  

  return x / ys;
}

static inline uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  

  return x / ys;
}

static inline uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  

  return (x + y - 1) / ys;
}

static inline uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return (x + y - 1) / ys;
}

static inline uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return (x + y - 1) / ys;
}

static inline uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return (x + y - 1) / ys;
}

static inline uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  

  return x % ys;
}

static inline uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : (x + y - 1) / ys;
}

static inline uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : (x + y - 1) / ys;
}

static inline uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : (x + y - 1) / ys;
}

static inline uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : (x + y - 1) / ys;
}

static inline uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

static inline int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

static inline int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

static inline int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

static inline int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

static inline int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

static inline int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

static inline int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

static inline int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

static inline int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

static inline int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

static inline int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

static inline int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

static inline int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

static inline int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

static inline int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

static inline int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x / ys;
}

static inline int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x / ys;
}

static inline int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x / ys;
}

static inline int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x / ys;
}

static inline int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return x % ys;
}

static inline int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x / ys;
}

static inline int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

static inline int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  
  return y == 0 ? 0 : x % ys;
}

#else

static inline uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

static inline uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

static inline uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

static inline uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

static inline uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

static inline uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

static inline uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

static inline uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

static inline uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

static inline uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

static inline uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

static inline uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

static inline uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

static inline uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

static inline uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

static inline uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

static inline uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

static inline uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

static inline int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

static inline int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

static inline int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

static inline int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

static inline int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

static inline int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

static inline int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

static inline int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

static inline int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

static inline int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

static inline int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

static inline int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

static inline int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

static inline int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

static inline int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

static inline int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

static inline int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

static inline int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

static inline int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

static inline int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

static inline int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

static inline int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

static inline int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

static inline int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

static inline int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

static inline int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

static inline int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

static inline int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

static inline int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

static inline int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

static inline int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

static inline int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

static inline uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

static inline uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

static inline uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

static inline uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

static inline int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

static inline int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

static inline int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

static inline int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

static inline uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

static inline uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

static inline uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

static inline uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

static inline uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

static inline uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

static inline uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

static inline uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

static inline uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

static inline uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

static inline uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

static inline uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

static inline int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

static inline int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

static inline int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

static inline int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

static inline uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

static inline uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

static inline uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

static inline uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

static inline uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

static inline uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

static inline uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

static inline uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

static inline uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

static inline uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

static inline uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

static inline uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

static inline bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

static inline bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

static inline bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

static inline bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

static inline bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

static inline bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

static inline bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

static inline bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

static inline bool slt8(int8_t x, int8_t y) {
  return x < y;
}

static inline bool slt16(int16_t x, int16_t y) {
  return x < y;
}

static inline bool slt32(int32_t x, int32_t y) {
  return x < y;
}

static inline bool slt64(int64_t x, int64_t y) {
  return x < y;
}

static inline bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

static inline bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

static inline bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

static inline bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

static inline uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

static inline bool itob_i8_bool(int8_t x) {
  return x != 0;
}

static inline bool itob_i16_bool(int16_t x) {
  return x != 0;
}

static inline bool itob_i32_bool(int32_t x) {
  return x != 0;
}

static inline bool itob_i64_bool(int64_t x) {
  return x != 0;
}

static inline int8_t btoi_bool_i8(bool x) {
  return x;
}

static inline int16_t btoi_bool_i16(bool x) {
  return x;
}

static inline int32_t btoi_bool_i32(bool x) {
  return x;
}

static inline int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

static int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

static int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

static int32_t abs32(int32_t x) {
  return abs(x);
}

static int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
static int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

static int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

static int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

static int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

static int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

static int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

static int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

static int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

static int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

static int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

static int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

static int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
static uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
static uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
static uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
static uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
static uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
static uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
static uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
static uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
static  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
static uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
static uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
static uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
static  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
static uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
static uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
static uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
static uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
static uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
static uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
static uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
static  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
static int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
static int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
static int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
static uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
static uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
static uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
static uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
static int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
static int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
static int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
static int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
static  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
static uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
static uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
static uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
static  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
static uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
static uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
static uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

static  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
static uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
static uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
static uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
static  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
static uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
static uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
static uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
static int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

static int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

static int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

static int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

static int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

static int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

static int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

static int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

static int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

static int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

static int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

static int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

static int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

static int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

static int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

static int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
static int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

static int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

static int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

static int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

static int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

static int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

static int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

static int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

static int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

static int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

static int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

static int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

static int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

static int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

static int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

static int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

static inline float fdiv32(float x, float y) {
  return x / y;
}

static inline float fadd32(float x, float y) {
  return x + y;
}

static inline float fsub32(float x, float y) {
  return x - y;
}

static inline float fmul32(float x, float y) {
  return x * y;
}

static inline bool cmplt32(float x, float y) {
  return x < y;
}

static inline bool cmple32(float x, float y) {
  return x <= y;
}

static inline float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

static inline float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

static inline float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

static inline float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

static inline float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

static inline float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

static inline float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

static inline float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
static inline float fabs32(float x) {
  return fabs(x);
}

static inline float fmax32(float x, float y) {
  return fmax(x, y);
}

static inline float fmin32(float x, float y) {
  return fmin(x, y);
}

static inline float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

static inline float fabs32(float x) {
  return abs(x);
}

static inline float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

static inline float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

static inline float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

static inline float fabs32(float x) {
  return fabsf(x);
}

static inline float fmax32(float x, float y) {
  return fmaxf(x, y);
}

static inline float fmin32(float x, float y) {
  return fminf(x, y);
}

static inline float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

static inline bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

static inline bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

static inline bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

static inline bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

static inline int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

static inline int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

static inline int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

static inline int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

static inline uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

static inline uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

static inline uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

static inline uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

static inline bool ftob_f32_bool(float x) {
  return x != 0;
}

static inline float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
static inline float futrts_log32(float x) {
  return log(x);
}

static inline float futrts_log2_32(float x) {
  return log2(x);
}

static inline float futrts_log10_32(float x) {
  return log10(x);
}

static inline float futrts_log1p_32(float x) {
  return log1p(x);
}

static inline float futrts_sqrt32(float x) {
  return sqrt(x);
}

static inline float futrts_cbrt32(float x) {
  return cbrt(x);
}

static inline float futrts_exp32(float x) {
  return exp(x);
}

static inline float futrts_cos32(float x) {
  return cos(x);
}

static inline float futrts_sin32(float x) {
  return sin(x);
}

static inline float futrts_tan32(float x) {
  return tan(x);
}

static inline float futrts_acos32(float x) {
  return acos(x);
}

static inline float futrts_asin32(float x) {
  return asin(x);
}

static inline float futrts_atan32(float x) {
  return atan(x);
}

static inline float futrts_cosh32(float x) {
  return cosh(x);
}

static inline float futrts_sinh32(float x) {
  return sinh(x);
}

static inline float futrts_tanh32(float x) {
  return tanh(x);
}

static inline float futrts_acosh32(float x) {
  return acosh(x);
}

static inline float futrts_asinh32(float x) {
  return asinh(x);
}

static inline float futrts_atanh32(float x) {
  return atanh(x);
}

static inline float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

static inline float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

static inline float futrts_gamma32(float x) {
  return tgamma(x);
}

static inline float futrts_lgamma32(float x) {
  return lgamma(x);
}

static inline float futrts_erf32(float x) {
  return erf(x);
}

static inline float futrts_erfc32(float x) {
  return erfc(x);
}

static inline float fmod32(float x, float y) {
  return fmod(x, y);
}

static inline float futrts_round32(float x) {
  return rint(x);
}

static inline float futrts_floor32(float x) {
  return floor(x);
}

static inline float futrts_ceil32(float x) {
  return ceil(x);
}

static inline float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

static inline float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

static inline float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

static inline float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

static inline float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

static inline float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

static inline float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

static inline float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

static inline float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
static inline float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline float futrts_exp32(float x) {
  return exp(x);
}

static inline float futrts_cos32(float x) {
  return cos(x);
}

static inline float futrts_sin32(float x) {
  return sin(x);
}

static inline float futrts_tan32(float x) {
  return tan(x);
}

static inline float futrts_acos32(float x) {
  return acos(x);
}

static inline float futrts_asin32(float x) {
  return asin(x);
}

static inline float futrts_atan32(float x) {
  return atan(x);
}

static inline float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

static inline float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

static inline float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

static inline float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

static inline float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

static inline float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

static inline float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

static inline float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
static inline float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
static inline float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
static inline float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
static inline float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

static inline float futrts_round32(float x) {
  return round(x);
}

static inline float futrts_floor32(float x) {
  return floor(x);
}

static inline float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
static inline float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

static inline float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

static inline float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

static inline float futrts_log32(float x) {
  return logf(x);
}

static inline float futrts_log2_32(float x) {
  return log2f(x);
}

static inline float futrts_log10_32(float x) {
  return log10f(x);
}

static inline float futrts_log1p_32(float x) {
  return log1pf(x);
}

static inline float futrts_sqrt32(float x) {
  return sqrtf(x);
}

static inline float futrts_cbrt32(float x) {
  return cbrtf(x);
}

static inline float futrts_exp32(float x) {
  return expf(x);
}

static inline float futrts_cos32(float x) {
  return cosf(x);
}

static inline float futrts_sin32(float x) {
  return sinf(x);
}

static inline float futrts_tan32(float x) {
  return tanf(x);
}

static inline float futrts_acos32(float x) {
  return acosf(x);
}

static inline float futrts_asin32(float x) {
  return asinf(x);
}

static inline float futrts_atan32(float x) {
  return atanf(x);
}

static inline float futrts_cosh32(float x) {
  return coshf(x);
}

static inline float futrts_sinh32(float x) {
  return sinhf(x);
}

static inline float futrts_tanh32(float x) {
  return tanhf(x);
}

static inline float futrts_acosh32(float x) {
  return acoshf(x);
}

static inline float futrts_asinh32(float x) {
  return asinhf(x);
}

static inline float futrts_atanh32(float x) {
  return atanhf(x);
}

static inline float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

static inline float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

static inline float futrts_gamma32(float x) {
  return tgammaf(x);
}

static inline float futrts_lgamma32(float x) {
  return lgammaf(x);
}

static inline float futrts_erf32(float x) {
  return erff(x);
}

static inline float futrts_erfc32(float x) {
  return erfcf(x);
}

static inline float fmod32(float x, float y) {
  return fmodf(x, y);
}

static inline float futrts_round32(float x) {
  return rintf(x);
}

static inline float futrts_floor32(float x) {
  return floorf(x);
}

static inline float futrts_ceil32(float x) {
  return ceilf(x);
}

static inline float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

static inline float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

static inline float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

static inline float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
static inline int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

static inline float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
static inline int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

static inline float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

static inline float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

#if ISPC
static inline bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

static inline bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

static inline double fdiv64(double x, double y) {
  return x / y;
}

static inline double fadd64(double x, double y) {
  return x + y;
}

static inline double fsub64(double x, double y) {
  return x - y;
}

static inline double fmul64(double x, double y) {
  return x * y;
}

static inline bool cmplt64(double x, double y) {
  return x < y;
}

static inline bool cmple64(double x, double y) {
  return x <= y;
}

static inline double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

static inline double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

static inline double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

static inline double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

static inline double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

static inline double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

static inline double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

static inline double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

static inline double fabs64(double x) {
  return abs(x);
}

static inline double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

static inline double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

static inline double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

static inline double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

static inline double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

static inline double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

static inline double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

static inline double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
static inline double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline double futrts_exp64(double x) {
  return exp(x);
}

static inline double futrts_cos64(double x) {
  return cos(x);
}

static inline double futrts_sin64(double x) {
  return sin(x);
}

static inline double futrts_tan64(double x) {
  return tan(x);
}

static inline double futrts_acos64(double x) {
  return acos(x);
}

static inline double futrts_asin64(double x) {
  return asin(x);
}

static inline double futrts_atan64(double x) {
  return atan(x);
}

static inline double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

static inline double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

static inline double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

static inline double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

static inline double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

static inline double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

static inline double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
static inline double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
static inline double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
static inline double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
static inline double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
static inline double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

static inline double futrts_round64(double x) {
  return round(x);
}

static inline double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
static inline float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline double futrts_floor64(double x) {
  return floor(x);
}

static inline bool futrts_isnan64(double x) {
  return isnan(x);
}

static inline int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

static inline int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

static inline int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

static inline int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

static inline uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

static inline uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

static inline uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

static inline uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

static inline bool ftob_f64_bool(double x) {
  return x != 0.0;
}

static inline double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

static inline int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

static inline double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

static inline double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

static inline double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

static inline double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

static inline double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

static inline float fpconv_f32_f32(float x) {
  return (float) x;
}

static inline double fpconv_f32_f64(float x) {
  return (double) x;
}

static inline float fpconv_f64_f32(double x) {
  return (float) x;
}

static inline double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

static inline double fdiv64(double x, double y) {
  return x / y;
}

static inline double fadd64(double x, double y) {
  return x + y;
}

static inline double fsub64(double x, double y) {
  return x - y;
}

static inline double fmul64(double x, double y) {
  return x * y;
}

static inline bool cmplt64(double x, double y) {
  return x < y;
}

static inline bool cmple64(double x, double y) {
  return x <= y;
}

static inline double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

static inline double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

static inline double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

static inline double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

static inline double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

static inline double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

static inline double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

static inline double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

static inline double fabs64(double x) {
  return fabs(x);
}

static inline double fmax64(double x, double y) {
  return fmax(x, y);
}

static inline double fmin64(double x, double y) {
  return fmin(x, y);
}

static inline double fpow64(double x, double y) {
  return pow(x, y);
}

static inline double futrts_log64(double x) {
  return log(x);
}

static inline double futrts_log2_64(double x) {
  return log2(x);
}

static inline double futrts_log10_64(double x) {
  return log10(x);
}

static inline double futrts_log1p_64(double x) {
  return log1p(x);
}

static inline double futrts_sqrt64(double x) {
  return sqrt(x);
}

static inline double futrts_cbrt64(double x) {
  return cbrt(x);
}

static inline double futrts_exp64(double x) {
  return exp(x);
}

static inline double futrts_cos64(double x) {
  return cos(x);
}

static inline double futrts_sin64(double x) {
  return sin(x);
}

static inline double futrts_tan64(double x) {
  return tan(x);
}

static inline double futrts_acos64(double x) {
  return acos(x);
}

static inline double futrts_asin64(double x) {
  return asin(x);
}

static inline double futrts_atan64(double x) {
  return atan(x);
}

static inline double futrts_cosh64(double x) {
  return cosh(x);
}

static inline double futrts_sinh64(double x) {
  return sinh(x);
}

static inline double futrts_tanh64(double x) {
  return tanh(x);
}

static inline double futrts_acosh64(double x) {
  return acosh(x);
}

static inline double futrts_asinh64(double x) {
  return asinh(x);
}

static inline double futrts_atanh64(double x) {
  return atanh(x);
}

static inline double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

static inline double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

static inline double futrts_gamma64(double x) {
  return tgamma(x);
}

static inline double futrts_lgamma64(double x) {
  return lgamma(x);
}

static inline double futrts_erf64(double x) {
  return erf(x);
}

static inline double futrts_erfc64(double x) {
  return erfc(x);
}

static inline double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

static inline double futrts_round64(double x) {
  return rint(x);
}

static inline double futrts_ceil64(double x) {
  return ceil(x);
}

static inline float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

static inline double futrts_floor64(double x) {
  return floor(x);
}

static inline bool futrts_isnan64(double x) {
  return isnan(x);
}

static inline bool futrts_isinf64(double x) {
  return isinf(x);
}

static inline int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

static inline int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

static inline int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

static inline int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

static inline uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

static inline uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

static inline uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

static inline uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

static inline bool ftob_f64_bool(double x) {
  return x != 0;
}

static inline double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

static inline int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

static inline double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

static inline double fmod64(double x, double y) {
  return fmod(x, y);
}

static inline double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

static inline double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

static inline double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

static inline float fpconv_f32_f32(float x) {
  return (float) x;
}

static inline double fpconv_f32_f64(float x) {
  return (double) x;
}

static inline float fpconv_f64_f32(double x) {
  return (float) x;
}

static inline double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

static inline f16 fadd16(f16 x, f16 y) {
  return x + y;
}

static inline f16 fsub16(f16 x, f16 y) {
  return x - y;
}

static inline f16 fmul16(f16 x, f16 y) {
  return x * y;
}

static inline bool cmplt16(f16 x, f16 y) {
  return x < y;
}

static inline bool cmple16(f16 x, f16 y) {
  return x <= y;
}

static inline f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

static inline f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

static inline f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

static inline f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

static inline f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

static inline f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

static inline f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

static inline f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

static inline int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

static inline int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

static inline int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

static inline int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

static inline uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

static inline uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

static inline uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

static inline uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

static inline bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

static inline f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
static inline bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

static inline f16 fabs16(f16 x) {
  return fabs(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
static inline f16 fabs16(f16 x) {
  return abs(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}
#else // Assuming CUDA.

static inline f16 fabs16(f16 x) {
  return fabsf(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
static inline bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
static inline bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

static inline bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
static inline f16 futrts_log16(f16 x) {
  return log(x);
}

static inline f16 futrts_log2_16(f16 x) {
  return log2(x);
}

static inline f16 futrts_log10_16(f16 x) {
  return log10(x);
}

static inline f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

static inline f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

static inline f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

static inline f16 futrts_exp16(f16 x) {
  return exp(x);
}

static inline f16 futrts_cos16(f16 x) {
  return cos(x);
}

static inline f16 futrts_sin16(f16 x) {
  return sin(x);
}

static inline f16 futrts_tan16(f16 x) {
  return tan(x);
}

static inline f16 futrts_acos16(f16 x) {
  return acos(x);
}

static inline f16 futrts_asin16(f16 x) {
  return asin(x);
}

static inline f16 futrts_atan16(f16 x) {
  return atan(x);
}

static inline f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

static inline f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

static inline f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

static inline f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

static inline f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

static inline f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

static inline f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

static inline f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

static inline f16 futrts_erf16(f16 x) {
  return erf(x);
}

static inline f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

static inline f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

static inline f16 futrts_round16(f16 x) {
  return rint(x);
}

static inline f16 futrts_floor16(f16 x) {
  return floor(x);
}

static inline f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

static inline f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

static inline f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

static inline f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

static inline f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

static inline f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

static inline f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

static inline f16 futrts_exp16(f16 x) {
  return exp(x);
}

static inline f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

static inline f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

static inline f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

static inline f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

static inline f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

static inline f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

static inline f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

static inline f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

static inline f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

static inline f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

static inline f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

static inline f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
static inline f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
static inline f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

static inline f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

static inline f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

static inline f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

static inline f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

static inline f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

static inline f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

static inline f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

static inline f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

static inline f16 futrts_log16(f16 x) {
  return hlog(x);
}

static inline f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

static inline f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

static inline f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

static inline f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

static inline f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

static inline f16 futrts_exp16(f16 x) {
  return hexp(x);
}

static inline f16 futrts_cos16(f16 x) {
  return hcos(x);
}

static inline f16 futrts_sin16(f16 x) {
  return hsin(x);
}

static inline f16 futrts_tan16(f16 x) {
  return tanf(x);
}

static inline f16 futrts_acos16(f16 x) {
  return acosf(x);
}

static inline f16 futrts_asin16(f16 x) {
  return asinf(x);
}

static inline f16 futrts_atan16(f16 x) {
  return atanf(x);
}

static inline f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

static inline f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

static inline f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

static inline f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

static inline f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

static inline f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

static inline f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

static inline f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

static inline f16 futrts_erf16(f16 x) {
  return erff(x);
}

static inline f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

static inline f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

static inline f16 futrts_round16(f16 x) {
  return rintf(x);
}

static inline f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

static inline f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

static inline f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
static inline int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
static inline f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

static inline int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

static inline f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
static inline int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

static inline f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

static inline f16 fabs16(f16 x) {
  return fabs32(x);
}

static inline f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

static inline f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

static inline f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

static inline bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

static inline bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

static inline f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

static inline f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

static inline f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

static inline f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

static inline f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

static inline f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

static inline f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

static inline f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

static inline f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

static inline f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

static inline f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

static inline f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

static inline f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

static inline f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

static inline f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

static inline f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

static inline f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

static inline f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

static inline f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

static inline f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

static inline f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

static inline f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

static inline f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

static inline f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

static inline f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

static inline f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

static inline f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

static inline f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

static inline f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

static inline f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

static inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

static inline f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

static inline f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

static inline int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

static inline f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

static inline int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

static inline f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

static inline f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

static inline float fpconv_f16_f16(f16 x) {
  return x;
}

static inline float fpconv_f16_f32(f16 x) {
  return x;
}

static inline f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

static inline double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
static inline f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
static inline f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_19057;
    struct memblock_device counters_mem_19143;
    bool main_res_8974;
    struct memblock_device mem_18296;
    int64_t triplayer2_9262;
    int64_t triplayer3_9268;
    int64_t triplayer4_9274;
    int64_t triplayer5_9280;
};
static int8_t static_array_realtype_19179[2] = {(int8_t) 0, (int8_t) 1};
static int8_t static_array_realtype_19180[16] = {(int8_t) 0, (int8_t) 1, (int8_t) 2, (int8_t) 3, (int8_t) 4, (int8_t) 5, (int8_t) 6, (int8_t) 7, (int8_t) 8, (int8_t) 9, (int8_t) 10, (int8_t) 11, (int8_t) 12, (int8_t) 13, (int8_t) 14, (int8_t) 15};
struct tuning_params {
    int64_t *builtinzhreplicate_boolzigroup_sizze_18801;
    int64_t *builtinzhreplicate_i16zigroup_sizze_18761;
    int64_t *builtinzhreplicate_i32zigroup_sizze_19068;
    int64_t *builtinzhreplicate_i64zigroup_sizze_18781;
    int64_t *segmap_group_sizze_14231;
    int64_t *segmap_group_sizze_14275;
    int64_t *segmap_group_sizze_14337;
    int64_t *segmap_group_sizze_14423;
    int64_t *segmap_group_sizze_14754;
    int64_t *segmap_group_sizze_15014;
    int64_t *segmap_group_sizze_15153;
    int64_t *segmap_group_sizze_15426;
    int64_t *segmap_num_groups_14233;
    int64_t *segmap_num_groups_14756;
    int64_t *segmap_num_groups_15016;
    int64_t *segmap_num_groups_15155;
    int64_t *segmap_num_groups_15428;
    int64_t *segred_group_sizze_15459;
    int64_t *segred_group_sizze_17182;
    int64_t *segred_num_groups_15461;
    int64_t *segred_num_groups_17184;
    int64_t *suff_outer_par_0;
    int64_t *suff_outer_par_1;
    int64_t *suff_outer_par_2;
    int64_t *suff_outer_par_3;
    int64_t *tile_sizze_17460;
};
static const int num_tuning_params = 26;
static const char *tuning_param_names[] = {"builtin#replicate_bool.group_size_18801", "builtin#replicate_i16.group_size_18761", "builtin#replicate_i32.group_size_19068", "builtin#replicate_i64.group_size_18781", "segmap_group_size_14231", "segmap_group_size_14275", "segmap_group_size_14337", "segmap_group_size_14423", "segmap_group_size_14754", "segmap_group_size_15014", "segmap_group_size_15153", "segmap_group_size_15426", "segmap_num_groups_14233", "segmap_num_groups_14756", "segmap_num_groups_15016", "segmap_num_groups_15155", "segmap_num_groups_15428", "segred_group_size_15459", "segred_group_size_17182", "segred_num_groups_15461", "segred_num_groups_17184", "suff_outer_par_0", "suff_outer_par_1", "suff_outer_par_2", "suff_outer_par_3", "tile_size_17460"};
static const char *tuning_param_vars[] = {"builtinzhreplicate_boolzigroup_sizze_18801", "builtinzhreplicate_i16zigroup_sizze_18761", "builtinzhreplicate_i32zigroup_sizze_19068", "builtinzhreplicate_i64zigroup_sizze_18781", "segmap_group_sizze_14231", "segmap_group_sizze_14275", "segmap_group_sizze_14337", "segmap_group_sizze_14423", "segmap_group_sizze_14754", "segmap_group_sizze_15014", "segmap_group_sizze_15153", "segmap_group_sizze_15426", "segmap_num_groups_14233", "segmap_num_groups_14756", "segmap_num_groups_15016", "segmap_num_groups_15155", "segmap_num_groups_15428", "segred_group_sizze_15459", "segred_group_sizze_17182", "segred_num_groups_15461", "segred_num_groups_17184", "suff_outer_par_0", "suff_outer_par_1", "suff_outer_par_2", "suff_outer_par_3", "tile_sizze_17460"};
static const char *tuning_param_classes[] = {"group_size", "group_size", "group_size", "group_size", "group_size", "group_size", "group_size", "group_size", "group_size", "group_size", "group_size", "group_size", "num_groups", "num_groups", "num_groups", "num_groups", "num_groups", "group_size", "group_size", "num_groups", "num_groups", "threshold(def, )", "threshold(def, !suff_outer_par_0)", "threshold(def, !suff_outer_par_1 !suff_outer_par_0)", "threshold(def, !suff_outer_par_2 !suff_outer_par_1 !suff_outer_par_0)", "group_size"};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 4;
static const char *cuda_program[] = {"\n#define FUTHARK_CUDA\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\ntypedef uint8_t uchar;\ntypedef uint16_t ushort;\ntypedef uint32_t uint;\ntypedef uint64_t ulong;\n#define __kernel extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline int get_group_id_fn(int block_dim0, int block_dim1, int block_dim2, int d) {\n  switch (d) {\n    case 0: d = block_dim0; break;\n    case 1: d = block_dim1; break;\n    case 2: d = block_dim2; break;\n  }\n  switch (d) {\n    case 0: return blockIdx.x;\n    case 1: return blockIdx.y;\n    case 2: return blockIdx.z;\n    default: return 0;\n  }\n}\n#define get_group_id(d) get_group_id_fn(block_dim0, block_dim1, block_dim2, d)\n\nstatic inline int get_num_groups_fn(int block_dim0, int block_dim1, int block_dim2, int d) {\n  switch (d) {\n    case 0: d = block_dim0; break;\n    case 1: d = block_dim1; break;\n    case 2: d = block_dim2; break;\n  }\n  switch(d) {\n    case 0: return gridDim.x;\n    case 1: return gridDim.y;\n    case 2: return gridDim.z;\n    default: return 0;\n  }\n}\n#define get_num_groups(d) get_num_groups_fn(block_dim0, block_dim1, block_dim2, d)\n\nstatic inline int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline void barrier(int x) {\n  __syncthreads();\n}\nstatic inline void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline void mem_fenc", "e_global() {\n  __threadfence();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char shared_mem[];\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x00", "00, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000",
                                     ", 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24", ", 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x355", "00000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x3",
                                     "7320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x3", "7AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x3", "7FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0",
                                     "x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0", "x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0", "x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n ",
                                     " 0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000,", " 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000,", " 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000,",
                                     " 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x3864600", "0, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x3879000", "0, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nstatic uint16_t float2halfbits(float value) {\n  un",
                                     "ion { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nstatic float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nstatic uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n// Double-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nstatic inline uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nstatic inline uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nstatic inline uint32_t add32(uint32_t x, uint32_t y) {\n", "  return x + y;\n}\n\nstatic inline uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nstatic inline uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nstatic inline uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nstatic inline uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nstatic inline uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nstatic inline uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nstatic inline uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nstatic inline uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nstatic inline uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nstatic inline uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nstatic inline uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x / ys;\n}\n\nstatic inline uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n\n  return x / ys;\n}\n\nstatic inline uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n\n  return x / ys;\n}\n\nstatic inline uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n\n  return (x + y - 1) / ys;\n}\n\nstatic inline uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return (x + y - 1) / ys;\n}\n\nstatic inline uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return (x + y - 1) / ys;\n}\n\nstatic inline uint64_t udiv_up64(uint64_t x, uint64_t y) {\n ", " uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return (x + y - 1) / ys;\n}\n\nstatic inline uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x % ys;\n}\n\nstatic inline uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n\n  return x % ys;\n}\n\nstatic inline uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x % ys;\n}\n\nstatic inline uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x % ys;\n}\n\nstatic inline uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x / ys;\n}\n\nstatic inline uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x / ys;\n}\n\nstatic inline uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x / ys;\n}\n\nstatic inline uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x / ys;\n}\n\nstatic inline uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nstatic inline uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nstatic inline uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nstatic inline uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nstatic inline uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  ",
                                     "}\n  \n  return y == 0 ? 0 : x % ys;\n}\n\nstatic inline uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x % ys;\n}\n\nstatic inline uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x % ys;\n}\n\nstatic inline uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x % ys;\n}\n\nstatic inline int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nstatic inline int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nstatic inline int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nstatic inline int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nstatic inline int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  int", "16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nstatic inline int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nstatic inline int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nstatic inline int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nstatic inline int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nstatic inline int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nstatic inline int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nstatic inline int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nstatic inline int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nstatic inline int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nstatic inline int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nstatic inline int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nstatic inline int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x / ys;\n}\n\nstatic inline int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x / ys;\n}\n\nstatic inline int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n", "  foreach_active(i){\n    ys = y;\n  }\n  \n  return x / ys;\n}\n\nstatic inline int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x / ys;\n}\n\nstatic inline int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x % ys;\n}\n\nstatic inline int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x % ys;\n}\n\nstatic inline int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x % ys;\n}\n\nstatic inline int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return x % ys;\n}\n\nstatic inline int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x / ys;\n}\n\nstatic inline int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x / ys;\n}\n\nstatic inline int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x / ys;\n}\n\nstatic inline int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x / ys;\n}\n\nstatic inline int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x % ys;\n}\n\nstatic inline int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x % ys;\n}\n\nstatic inline int32_t srem_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x % ys;\n}\n\nstatic inline int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  \n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nstatic inline uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nstatic inline uint16_t udi",
                                     "v16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nstatic inline uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nstatic inline uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nstatic inline uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nstatic inline uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nstatic inline uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nstatic inline uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nstatic inline uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nstatic inline uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nstatic inline uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nstatic inline uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nstatic inline uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nstatic inline uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nstatic inline uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nstatic inline uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nstatic inline uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\ns", "tatic inline int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nstatic inline int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nstatic inline int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nstatic inline int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nstatic inline int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nstatic inline int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nstatic inline int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nstatic inline int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nstatic inline int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nstatic inline int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nstatic inline int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x", " + y - 1, y);\n}\n\nstatic inline int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nstatic inline int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nstatic inline int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nstatic inline int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nstatic inline int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nstatic inline int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nstatic inline int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nstatic inline int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nstatic inline int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nstatic inline int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nstatic inline int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nstatic inline int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nstatic inline int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nstatic inline int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nstatic inline int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nstatic inline int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline int16_t squot_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline int32_t squot_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nstatic inline int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nstatic inline int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nstat",
                                     "ic inline int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nstatic inline int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nstatic inline uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nstatic inline uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nstatic inline uint32_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nstatic inline uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nstatic inline uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nstatic inline uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nstatic inline uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nstatic inline uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nstatic inline int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nstatic inline int16_t ashr16", "(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nstatic inline int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nstatic inline int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nstatic inline uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nstatic inline uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nstatic inline uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nstatic inline uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nstatic inline uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nstatic inline uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nstatic inline uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nstatic inline uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nstatic inline uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nstatic inline uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nstatic inline uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nstatic inline uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nstatic inline bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nstatic inline bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nstatic inline bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nstatic inline bool ult64(uint64_t x, uint64_t y) {\n  return x < y;\n}\n\nstatic inline bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nstatic inline bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nstatic inline bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nstatic inline bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nstatic inline bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nstatic inline bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nstatic inline bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nstatic inline bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nstatic inline bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nstatic inline bool sle16(int16_t x, int16_t ", "y) {\n  return x <= y;\n}\n\nstatic inline bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nstatic inline bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nstatic inline uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nstatic inline uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nstatic inline uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nstatic inline uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nstatic inline bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nstatic inline bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nstatic inline bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nstatic inline bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nstatic inline int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nstatic inline int16_t btoi_bool_i16(bool x) {\n  return x;\n}\n\nstatic inline int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nstatic inline int64_t btoi_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#def",
                                     "ine sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nstatic int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nstatic int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nstatic int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nstatic int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VERSION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\nstatic int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nstatic int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nstatic int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nstatic int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nstatic int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nstatic int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nstatic int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nstatic int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nstatic int32_t futrts_popc8(uint8_t x", ") {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nstatic int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nstatic int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nstatic int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nstatic uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nstatic uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nstatic uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nstatic uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nstatic uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nstatic uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nstatic uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nstatic uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nstatic  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nstatic uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nstatic uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nstatic uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nstatic  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nstatic uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nstatic uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nstatic uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nstatic uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nstatic uint16_t futrts_umul_hi16(uint16_t a, uint16_t b)", " { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nstatic uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nstatic uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nstatic  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nstatic int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nstatic int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nstatic int64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nstatic uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nstatic uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nstatic uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nstatic uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((_",
                                     "_uint128_t)b) >> 64; }\nstatic int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nstatic int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nstatic int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nstatic int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nstatic  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nstatic uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nstatic uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nstatic uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nstatic  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }\nstatic uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nstatic uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nstatic uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nstatic  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nstatic uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nstatic uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nstatic uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nstatic  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nstatic uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nstatic uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nstatic ", "uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nstatic int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nstatic int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nstatic int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nstatic int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nstatic int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nstatic int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nstatic int32_t futrts_clzz32(int32_t x) {\n  return __clz(x);\n}\n\nstatic int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nstatic int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nstatic int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nstatic int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nstatic int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nstatic int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nstatic int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nstatic int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nstatic int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nstatic int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nstatic int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nstatic int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nstatic int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;", "\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nstatic int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nstatic int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nstatic int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nstatic int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1;\n}\n\n#elif ISPC\n\nstatic int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);\n}\n\nstatic int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nstatic int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nstatic int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nstatic int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nstatic int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nstatic int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nstatic int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nstatic inline float fdiv32(float x, float y) {\n  return x / y;\n}\n\nstatic inline float fadd32(float x, float y) {\n  return x + y;\n}\n\nstatic inline float fsub32(float x, float y) {\n  return x - y;\n}\n\nstatic inline float fmul32(float x, float y) {\n  return x * y;\n}\n\nstatic inline bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nstatic inline bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nstatic inline float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nstatic inline float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nstatic inline float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nstatic inline float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nstatic inline float uitofp_i8_f32(uint8",
                                     "_t x) {\n  return (float) x;\n}\n\nstatic inline float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nstatic inline float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nstatic inline float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nstatic inline float fabs32(float x) {\n  return fabs(x);\n}\n\nstatic inline float fmax32(float x, float y) {\n  return fmax(x, y);\n}\n\nstatic inline float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nstatic inline float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nstatic inline float fabs32(float x) {\n  return abs(x);\n}\n\nstatic inline float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nstatic inline float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nstatic inline float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nstatic inline float fabs32(float x) {\n  return fabsf(x);\n}\n\nstatic inline float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nstatic inline float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nstatic inline float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nstatic inline bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nstatic inline bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nstatic inline bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nstatic inline bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nstatic inline int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nstatic inline int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nstatic inline int32_", "t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nstatic inline int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nstatic inline uint8_t fptoui_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nstatic inline uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nstatic inline uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nstatic inline uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nstatic inline bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nstatic inline float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nstatic inline float futrts_log32(float x) {\n  return log(x);\n}\n\nstatic inline float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nstatic inline float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nstatic inline float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nstatic inline float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nstatic inline float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nstatic inline float futrts_exp32(float x) {\n  return exp(x);\n}\n\nstatic inline float futrts_cos32(float x) {\n  return cos(x);\n}\n\nstatic inline float futrts_sin32(float x) {\n  return sin(x);\n}\n\nstatic inline float futrts_tan32(float x) {\n  return tan(x);\n}\n\nstatic inline float futrts_acos32(float x) {\n  return acos(x);\n}\n\nstatic inline float futrts_asin32(float x) {\n  return asin(x);\n}\n\nstatic inline float futrts_atan32(float x) {\n  return atan(x);\n}\n\nstatic inline float futrts_cosh32(float x) {\n  retu", "rn cosh(x);\n}\n\nstatic inline float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nstatic inline float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nstatic inline float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nstatic inline float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nstatic inline float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nstatic inline float futrts_atan2_32(float x, float y) {\n  return atan2(x, y);\n}\n\nstatic inline float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nstatic inline float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nstatic inline float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nstatic inline float futrts_erf32(float x) {\n  return erf(x);\n}\n\nstatic inline float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nstatic inline float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nstatic inline float futrts_round32(float x) {\n  return rint(x);\n}\n\nstatic inline float futrts_floor32(float x) {\n  return floor(x);\n}\n\nstatic inline float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nstatic inline float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nstatic inline float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nstatic inline float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nstatic inline float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nstatic inline float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nstatic inline float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nstatic inline float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nstatic inline float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nstatic inline float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked unif",
                                     "orm float cbrtf(uniform float);\nstatic inline float futrts_cbrt32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nstatic inline float futrts_exp32(float x) {\n  return exp(x);\n}\n\nstatic inline float futrts_cos32(float x) {\n  return cos(x);\n}\n\nstatic inline float futrts_sin32(float x) {\n  return sin(x);\n}\n\nstatic inline float futrts_tan32(float x) {\n  return tan(x);\n}\n\nstatic inline float futrts_acos32(float x) {\n  return acos(x);\n}\n\nstatic inline float futrts_asin32(float x) {\n  return asin(x);\n}\n\nstatic inline float futrts_atan32(float x) {\n  return atan(x);\n}\n\nstatic inline float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nstatic inline float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nstatic inline float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nstatic inline float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nstatic inline float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nstatic inline float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nstatic inline float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nstatic inline float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\ne", "xtern \"C\" unmasked uniform float tgammaf(uniform float x);\nstatic inline float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nstatic inline float futrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nstatic inline float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nstatic inline float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nstatic inline float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nstatic inline float futrts_round32(float x) {\n  return round(x);\n}\n\nstatic inline float futrts_floor32(float x) {\n  return floor(x);\n}\n\nstatic inline float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nstatic inline float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nstatic inline float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nstatic inline float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nstatic inline float futrts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nstatic inline float futrts_log32(float x) {\n  return logf(x);\n}\n\nstatic inline float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nstatic inline float futrts_log10_32(floa", "t x) {\n  return log10f(x);\n}\n\nstatic inline float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nstatic inline float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nstatic inline float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nstatic inline float futrts_exp32(float x) {\n  return expf(x);\n}\n\nstatic inline float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nstatic inline float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nstatic inline float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nstatic inline float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nstatic inline float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nstatic inline float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nstatic inline float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nstatic inline float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nstatic inline float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nstatic inline float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nstatic inline float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nstatic inline float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nstatic inline float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nstatic inline float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nstatic inline float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nstatic inline float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nstatic inline float futrts_erf32(float x) {\n  return erff(x);\n}\n\nstatic inline float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nstatic inline float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nstatic inline float futrts_round32(float x) {\n  return rintf(x);\n}\n\nstatic inline float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nstatic inline float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nstatic inline float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nstatic inline float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n",
                                     "\nstatic inline float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nstatic inline float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nstatic inline int32_t futrts_to_bits32(float x) {\n  return intbits(x);\n}\n\nstatic inline float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nstatic inline int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nstatic inline float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nstatic inline float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\n#if ISPC\nstatic inline bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nstatic inline bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nstatic inline double fdiv64(double x, double y) {\n  return x / y;\n}\n\nstatic inline double fadd64(double x, double y) {\n  return x + y;\n}\n\nstatic inline double fsub64(double x, double y) {\n  return x - y;\n}\n\nstatic inline double fmul64(double x, double y) {\n  return x * y;\n}\n\nstatic inline bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nstatic inline bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nstatic inline double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nstatic inline double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nstatic inline double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nstatic inline double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nstatic inline double fabs64(double x) {\n  return abs(x);\n}\n\nstatic inlin", "e double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nstatic inline double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nstatic inline double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nstatic inline double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nstatic inline double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nstatic inline double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nstatic inline double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nstatic inline double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nstatic inline double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nstatic inline double futrts_exp64(double x) {\n  return exp(x);\n}\n\nstatic inline double futrts_cos64(double x) {\n  return cos(x);\n}\n\nstatic inline double futrts_sin64(double x) {\n  return sin(x);\n}\n\nstatic inline double futrts_tan64(double x) {\n  return tan(x);\n}\n\nstatic inline double futrts_acos64(double x) {\n  return acos(x);\n}\n\nstatic inline double futrts_asin64(double x) {\n  return asin(x);\n}\n\nstatic inline double futrts_atan64(double x) {\n  return atan(x);\n}\n\nstatic inline double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nstatic inline double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nstatic inline double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nstatic inline double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x", "-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nstatic inline double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nstatic inline double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nstatic inline double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nstatic inline double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nstatic inline double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nstatic inline double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nstatic inline double futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nstatic inline double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nstatic inline double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nstatic inline double futrts_round64(double x) {\n  return round(x);\n}\n\nstatic inline double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nstatic inline float futrt",
                                     "s_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nstatic inline double futrts_floor64(double x) {\n  return floor(x);\n}\n\nstatic inline bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nstatic inline int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nstatic inline int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nstatic inline int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nstatic inline int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nstatic inline uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nstatic inline uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nstatic inline uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nstatic inline uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nstatic inline bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nstatic inline double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nstatic inline int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nstatic inline double futrts_from_", "bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i);\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nstatic inline double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nstatic inline double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nstatic inline double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nstatic inline double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nstatic inline float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nstatic inline double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nstatic inline float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nstatic inline double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#else\n\nstatic inline double fdiv64(double x, double y) {\n  return x / y;\n}\n\nstatic inline double fadd64(double x, double y) {\n  return x + y;\n}\n\nstatic inline double fsub64(double x, double y) {\n  return x - y;\n}\n\nstatic inline double fmul64(double x, double y) {\n  return x * y;\n}\n\nstatic inline bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nstatic inline bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nstatic inline double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nstatic inline double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nstatic inline double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nstatic inline double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nstatic inline double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nstatic inline double fabs64(double x) {\n  return fabs(x);\n}\n\nstatic inline double fmax64(double x, double y) {\n", "  return fmax(x, y);\n}\n\nstatic inline double fmin64(double x, double y) {\n  return fmin(x, y);\n}\n\nstatic inline double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nstatic inline double futrts_log64(double x) {\n  return log(x);\n}\n\nstatic inline double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nstatic inline double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nstatic inline double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nstatic inline double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nstatic inline double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nstatic inline double futrts_exp64(double x) {\n  return exp(x);\n}\n\nstatic inline double futrts_cos64(double x) {\n  return cos(x);\n}\n\nstatic inline double futrts_sin64(double x) {\n  return sin(x);\n}\n\nstatic inline double futrts_tan64(double x) {\n  return tan(x);\n}\n\nstatic inline double futrts_acos64(double x) {\n  return acos(x);\n}\n\nstatic inline double futrts_asin64(double x) {\n  return asin(x);\n}\n\nstatic inline double futrts_atan64(double x) {\n  return atan(x);\n}\n\nstatic inline double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nstatic inline double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nstatic inline double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nstatic inline double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nstatic inline double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nstatic inline double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nstatic inline double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nstatic inline double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nstatic inline double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nstatic inline double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nstatic inline double futrts_erf64(double x) {\n  return erf(x);\n}\n\nstatic inline double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nstatic inline double futrts_fma64(double a, double b, double c) {\n  return fma(a, b, c);\n}",
                                     "\n\nstatic inline double futrts_round64(double x) {\n  return rint(x);\n}\n\nstatic inline double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nstatic inline float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nstatic inline double futrts_floor64(double x) {\n  return floor(x);\n}\n\nstatic inline bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nstatic inline bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nstatic inline int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nstatic inline int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nstatic inline int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nstatic inline int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nstatic inline uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nstatic inline uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nstatic inline uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nstatic inline uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nstatic inline bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nstatic inline double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nstatic inline int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nstatic inline double futrts_from_bits64(int", "64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nstatic inline double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nstatic inline double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nstatic inline double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nstatic inline double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nstatic inline float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nstatic inline double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nstatic inline float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nstatic inline double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// Some of these functions convert to single precision because ha", "lf\n// precision versions are not available.\n\nstatic inline f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nstatic inline f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nstatic inline f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nstatic inline bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nstatic inline bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nstatic inline f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nstatic inline f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nstatic inline int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nstatic inline int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nstatic inline int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nstatic inline int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nstatic inline uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nstatic inline uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nstatic inline uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nstatic inline uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nstatic inline bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nstatic inline f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nstatic inline bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nstatic inline f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nstatic inline f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nstatic inline f16 fmin16(f16 x, f16 y) {\n  return fmin(x, y);\n}\n\nstatic inline f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nstatic inline f16",
                                     " fabs16(f16 x) {\n  return abs(x);\n}\n\nstatic inline f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nstatic inline f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nstatic inline f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n#else // Assuming CUDA.\n\nstatic inline f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nstatic inline f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nstatic inline f16 fmin16(f16 x, f16 y) {\n  return fminf(x, y);\n}\n\nstatic inline f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nstatic inline bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nstatic inline bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nstatic inline bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nstatic inline f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nstatic inline f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nstatic inline f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nstatic inline f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nstatic inline f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nstatic inline f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nstatic inline f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nstatic inline f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nstatic inline f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nstatic inline f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nstatic inline f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nstatic inline f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nstatic inline f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nstatic inline f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nstatic inline f16 futrts_sinh16(f16 x) {\n  return sinh(x);\n}\n\nstatic inline f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nstatic inline f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nstatic inline ", "f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nstatic inline f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nstatic inline f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nstatic inline f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nstatic inline f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nstatic inline f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nstatic inline f16 futrts_erf16(f16 x) {\n  return erf(x);\n}\n\nstatic inline f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nstatic inline f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nstatic inline f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nstatic inline f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nstatic inline f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nstatic inline f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nstatic inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nstatic inline f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nstatic inline f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nstatic inline f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nstatic inline f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nstatic inline f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nstatic inline f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nstatic inline f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nstatic inline f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nstatic inline f16 futrts_cos16(f16 x) {\n  return (float16)cos((float)x);\n}\n\nstatic inline f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nstatic inline f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nstatic inline f16 futrts_acos16(f16 x) {\n  ", "return (float16)acos((float)x);\n}\n\nstatic inline f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nstatic inline f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nstatic inline f16 futrts_cosh16(f16 x) {\n  return (exp(x)+exp(-x)) / 2.0f16;\n}\n\nstatic inline f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nstatic inline f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nstatic inline f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nstatic inline f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nstatic inline f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nstatic inline f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nstatic inline f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nstatic inline f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nstatic inline f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nstatic inline f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nstatic inline f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n}\n\nstatic inline f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nstatic inline f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nstatic inline f16 futrts_round16(f16 x) {\n  return (float",
                                     "16)round((float)x);\n}\n\nstatic inline f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nstatic inline f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nstatic inline f16 futrts_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nstatic inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nstatic inline f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nstatic inline f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nstatic inline f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nstatic inline f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nstatic inline f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nstatic inline f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nstatic inline f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nstatic inline f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nstatic inline f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nstatic inline f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nstatic inline f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nstatic inline f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nstatic inline f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nstatic inline f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nstatic inline f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nstatic inline f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nstatic inline f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nstatic inline f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nstatic inline f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nstatic inline f16 futrts_asinh16(f16 x) {\n  return asinhf(x);\n}\n\nstatic inline f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nstatic inline f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nstatic inline f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nstatic inline f16 futrts_gamma16(f16 x) {\n  return tgammaf(x);\n}\n\nstatic in", "line f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nstatic inline f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nstatic inline f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nstatic inline f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nstatic inline f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nstatic inline f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nstatic inline f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nstatic inline f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nstatic inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nstatic inline f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nstatic inline f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nstatic inline int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nstatic inline f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nstatic inline int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nstatic inline f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nstatic inline int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nstatic inline f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No native f16 - emulate.\n\nstatic inline f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nstatic inline f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nstatic inline f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nstatic inline f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nstatic inline bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n", "}\n\nstatic inline bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nstatic inline f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nstatic inline f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nstatic inline f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nstatic inline f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nstatic inline f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nstatic inline f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nstatic inline f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nstatic inline f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nstatic inline f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nstatic inline f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nstatic inline f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nstatic inline f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nstatic inline f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nstatic inline f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nstatic inline f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nstatic inline f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nstatic inline f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nstatic inline f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nstatic inline f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nstatic inline f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nstatic inline f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}\n\nstatic inline f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nstatic inline f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nstatic inline f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nstatic inline f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nstatic inline f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nstatic inline f16 futrts_round16(f16 x) {\n  r",
                                     "eturn futrts_round32(x);\n}\n\nstatic inline f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nstatic inline f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nstatic inline f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nstatic inline f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nstatic inline f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nstatic inline f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nstatic inline int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nstatic inline f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nstatic inline int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nstatic inline f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nstatic inline f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nstatic inline float fpconv_f16_f16(f16 x) {\n  return x;\n}\n\nstatic inline float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nstatic inline f16 fpconv_f32_f16(float x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nstatic inline double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nstatic inline f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nstatic inline f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\ninline int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CU", "DA\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\ninline int32_t atomic_xchg_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\ninline int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                         int32_t cmp, int32_t val) {\n#ifdef FUTHARK_CUDA\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\ninline int32_t atomic_cmpxchg_i32_local(volatile __local int32_t *p,\n                                        int32_t cmp, int32_t val) {\n#ifdef FUTHARK_CUDA\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\ninline int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\ninline int32_t atomic_add_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\ninline float atomic_fadd_f32_global(volatile __global float *p, float x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_global((volatile __global int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\ninline float atomic_fadd_f32_local(volatile __local float *p, float x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_local((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\ninline int32_t atomic_s", "max_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\ninline int32_t atomic_smax_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\ninline int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\ninline int32_t atomic_smin_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\ninline uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\ninline uint32_t atomic_umax_i32_local(volatile __local uint32_t *p, uint32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\ninline uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\ninline uint32_t atomic_umin_i32_local(volatile __local uint32_t *p, uint32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\ninline int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\ninline int32_t atomic_and_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\ninline int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\ninline int32_t atomic_or_i32_local(volatile",
                                     " __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\ninline int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\ninline int32_t atomic_xor_i32_local(volatile __local int32_t *p, int32_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\ninline int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\ninline int64_t atomic_xchg_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\ninline int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                         int64_t cmp, int64_t val) {\n#ifdef FUTHARK_CUDA\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\ninline int64_t atomic_cmpxchg_i64_local(volatile __local int64_t *p,\n                                        int64_t cmp, int64_t val) {\n#ifdef FUTHARK_CUDA\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\ninline int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\ninline int64_t atomic_add_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\ninline double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  union { int64_t i; double f", "; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\ninline double atomic_fadd_f64_local(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  union { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_local((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\ninline int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((int64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\ninline int64_t atomic_smax_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((int64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\ninline int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((int64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\ninline int64_t atomic_smin_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((int64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\ninline uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\ninline uint64_t atomic_umax_i64_local(volatile __local uint64_t *p, uint64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\ninline uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\ninline uint64_t atomic_umin_i64_local(volatile __local u", "int64_t *p, uint64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\ninline int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAnd((int64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\ninline int64_t atomic_and_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicAnd((int64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\ninline int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicOr((int64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\ninline int64_t atomic_or_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicOr((int64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\ninline int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicXor((int64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\ninline int64_t atomic_xor_i64_local(volatile __local int64_t *p, int64_t x) {\n#ifdef FUTHARK_CUDA\n  return atomicXor((int64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n// End of atomics.h\n\n\n\n__kernel void builtinzhreplicate_boolzireplicate_18797(int64_t num_elems_18793, unsigned char val_18794_bits, int64_t replicate_n_18796, int64_t virt_num_groups_18802, int64_t num_groups_18803, __global unsigned char *mem_18792)\n{\n    bool val_18794 = val_18794_bits;\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    int32_t replicate_ltid_18798;\n    int64_t group_sizze_18800;\n    int32_t replicate_gid_18799;\n    \n    replicate_ltid_18798 = get_local_id(0);\n    group_sizze_18800 = get_local_size(0);\n    replicate_gid_18799 = get_group_id(0);\n    \n    int32_t replicate_gtid_18797 = replicate_gid_18799 * group_sizze_18800 + replicate_ltid_18798;\n    int32_t phys_group_id_18804;\n    \n    phys_group_id_18804 = get_group_id(0);\n    \n    int32_t iterations",
                                     "_18805 = sdiv_up32(sext_i64_i32(virt_num_groups_18802) - phys_group_id_18804, sext_i64_i32(num_groups_18803));\n    \n    for (int32_t i_18806 = 0; i_18806 < iterations_18805; i_18806++) {\n        int32_t virt_group_id_18807 = phys_group_id_18804 + i_18806 * sext_i64_i32(num_groups_18803);\n        int64_t global_tid_18808 = sext_i32_i64(virt_group_id_18807) * sext_i32_i64(group_sizze_18800) + sext_i32_i64(replicate_ltid_18798);\n        int64_t slice_18810 = num_elems_18793;\n        int64_t rep_i_18809 = global_tid_18808;\n        int64_t remnant_18811 = global_tid_18808 - rep_i_18809;\n        \n        if (slt64(global_tid_18808, replicate_n_18796)) {\n            ((__global bool *) mem_18792)[rep_i_18809] = val_18794;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_0:\n    return;\n}\n__kernel void builtinzhreplicate_i16zireplicate_18757(int64_t num_elems_18753, int16_t val_18754, int64_t replicate_n_18756, int64_t virt_num_groups_18762, int64_t num_groups_18763, __global unsigned char *mem_18752)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    int32_t replicate_ltid_18758;\n    int64_t group_sizze_18760;\n    int32_t replicate_gid_18759;\n    \n    replicate_ltid_18758 = get_local_id(0);\n    group_sizze_18760 = get_local_size(0);\n    replicate_gid_18759 = get_group_id(0);\n    \n    int32_t replicate_gtid_18757 = replicate_gid_18759 * group_sizze_18760 + replicate_ltid_18758;\n    int32_t phys_group_id_18764;\n    \n    phys_group_id_18764 = get_group_id(0);\n    \n    int32_t iterations_18765 = sdiv_up32(sext_i64_i32(virt_num_groups_18762) - phys_group_id_18764, sext_i64_i32(num_groups_18763));\n    \n    for (int32_t i_18766 = 0; i_18766 < iterations_18765; i_18766++) {\n        int32_t virt_group_id_18767 = phys_group_id_18764 + i_18766 * sext_i64_i32(num_groups_18763);\n        int64_t global_tid_18768 = sext_i32_i64(virt_group_id_18767) * sext_i32_i64(group_sizze_18760) + sext_i32_i64(replicat", "e_ltid_18758);\n        int64_t slice_18770 = num_elems_18753;\n        int64_t rep_i_18769 = global_tid_18768;\n        int64_t remnant_18771 = global_tid_18768 - rep_i_18769;\n        \n        if (slt64(global_tid_18768, replicate_n_18756)) {\n            ((__global int16_t *) mem_18752)[rep_i_18769] = val_18754;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_0:\n    return;\n}\n__kernel void builtinzhreplicate_i32zireplicate_19064(int64_t num_elems_19060, int32_t val_19061, int64_t replicate_n_19063, int64_t virt_num_groups_19069, int64_t num_groups_19070, __global unsigned char *mem_19059)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    int32_t replicate_ltid_19065;\n    int64_t group_sizze_19067;\n    int32_t replicate_gid_19066;\n    \n    replicate_ltid_19065 = get_local_id(0);\n    group_sizze_19067 = get_local_size(0);\n    replicate_gid_19066 = get_group_id(0);\n    \n    int32_t replicate_gtid_19064 = replicate_gid_19066 * group_sizze_19067 + replicate_ltid_19065;\n    int32_t phys_group_id_19071;\n    \n    phys_group_id_19071 = get_group_id(0);\n    \n    int32_t iterations_19072 = sdiv_up32(sext_i64_i32(virt_num_groups_19069) - phys_group_id_19071, sext_i64_i32(num_groups_19070));\n    \n    for (int32_t i_19073 = 0; i_19073 < iterations_19072; i_19073++) {\n        int32_t virt_group_id_19074 = phys_group_id_19071 + i_19073 * sext_i64_i32(num_groups_19070);\n        int64_t global_tid_19075 = sext_i32_i64(virt_group_id_19074) * sext_i32_i64(group_sizze_19067) + sext_i32_i64(replicate_ltid_19065);\n        int64_t slice_19077 = num_elems_19060;\n        int64_t rep_i_19076 = global_tid_19075;\n        int64_t remnant_19078 = global_tid_19075 - rep_i_19076;\n        \n        if (slt64(global_tid_19075, replicate_n_19063)) {\n            ((__global int32_t *) mem_19059)[rep_i_19076] = val_19061;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_0:\n    ret", "urn;\n}\n__kernel void builtinzhreplicate_i64zireplicate_18777(int64_t num_elems_18773, int64_t val_18774, int64_t replicate_n_18776, int64_t virt_num_groups_18782, int64_t num_groups_18783, __global unsigned char *mem_18772)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    int32_t replicate_ltid_18778;\n    int64_t group_sizze_18780;\n    int32_t replicate_gid_18779;\n    \n    replicate_ltid_18778 = get_local_id(0);\n    group_sizze_18780 = get_local_size(0);\n    replicate_gid_18779 = get_group_id(0);\n    \n    int32_t replicate_gtid_18777 = replicate_gid_18779 * group_sizze_18780 + replicate_ltid_18778;\n    int32_t phys_group_id_18784;\n    \n    phys_group_id_18784 = get_group_id(0);\n    \n    int32_t iterations_18785 = sdiv_up32(sext_i64_i32(virt_num_groups_18782) - phys_group_id_18784, sext_i64_i32(num_groups_18783));\n    \n    for (int32_t i_18786 = 0; i_18786 < iterations_18785; i_18786++) {\n        int32_t virt_group_id_18787 = phys_group_id_18784 + i_18786 * sext_i64_i32(num_groups_18783);\n        int64_t global_tid_18788 = sext_i32_i64(virt_group_id_18787) * sext_i32_i64(group_sizze_18780) + sext_i32_i64(replicate_ltid_18778);\n        int64_t slice_18790 = num_elems_18773;\n        int64_t rep_i_18789 = global_tid_18788;\n        int64_t remnant_18791 = global_tid_18788 - rep_i_18789;\n        \n        if (slt64(global_tid_18788, replicate_n_18776)) {\n            ((__global int64_t *) mem_18772)[rep_i_18789] = val_18774;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_bool(const int block_dim0, const int block_dim1, const int block_dim2, uint block_9_backing_offset_0, int32_t destoffset_1, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6, int32_t mulx_7, int32_t muly_8, __global unsigned char *destmem_0, __global unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 = &shared_mem[block",
                                     "_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_41;\n    \n    get_group_id_0_41 = get_group_id(0);\n    \n    int32_t get_group_id_1_42;\n    \n    get_group_id_1_42 = get_group_id(1);\n    \n    int32_t get_group_id_2_43;\n    \n    get_group_id_2_43 = get_group_id(2);\n    \n    int32_t get_local_sizze_0_40;\n    \n    get_local_sizze_0_40 = get_local_size(0);\n    \n    int32_t get_global_id_0_37 = get_group_id_0_41 * get_local_sizze_0_40 + get_local_id_0_38;\n    int32_t our_array_offset_30 = get_group_id_2_43 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = destoffset_1 + our_array_offset_30;\n    int32_t idata_offset_34 = srcoffset_3 + our_array_offset_30;\n    int32_t x_index_31 = get_global_id_0_37;\n    int32_t y_index_32 = get_group_id_1_42 * 32 + get_local_id_1_39;\n    bool val_45;\n    \n    if (slt32(x_index_31, x_elems_5)) {\n        for (int32_t j_44 = 0; j_44 < 4; j_44++) {\n            int32_t index_in_35 = (y_index_32 + j_44 * 8) * x_elems_5 + x_index_31;\n            \n            if (slt32(y_index_32 + j_44 * 8, y_elems_6)) {\n                val_45 = ((__global bool *) srcmem_2)[sext_i32_i64(idata_offset_34 + index_in_35)];\n                ((__local bool *) block_9)[sext_i32_i64((get_local_id_1_39 + j_44 * 8) * 33 + get_local_id_0_38)] = val_45;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_42 * 32 + get_local_id_0_38;\n    y_index_32 = get_group_id_0_41 * 32 + get_local_id_1_39;\n    if (slt32(x_index_31, y_elems_6)) {\n        for (int32_t j_44 = 0; j_44 < 4; j_44++) {\n            int32_t index_out_36 = (y_index_32 + j_44 * 8) * y_elems_6 + x_index_31;\n            \n            if (slt32(y_index_32 + j_44 * 8, x_elems_5)) {\n                val_45 = ((__", "local bool *) block_9)[sext_i32_i64(get_local_id_0_38 * 33 + get_local_id_1_39 + j_44 * 8)];\n                ((__global bool *) destmem_0)[sext_i32_i64(odata_offset_33 + index_out_36)] = val_45;\n            }\n        }\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_bool_low_height(const int block_dim0, const int block_dim1, const int block_dim2, uint block_9_backing_offset_0, int32_t destoffset_1, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6, int32_t mulx_7, int32_t muly_8, __global unsigned char *destmem_0, __global unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 = &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_41;\n    \n    get_group_id_0_41 = get_group_id(0);\n    \n    int32_t get_group_id_1_42;\n    \n    get_group_id_1_42 = get_group_id(1);\n    \n    int32_t get_group_id_2_43;\n    \n    get_group_id_2_43 = get_group_id(2);\n    \n    int32_t get_local_sizze_0_40;\n    \n    get_local_sizze_0_40 = get_local_size(0);\n    \n    int32_t get_global_id_0_37 = get_group_id_0_41 * get_local_sizze_0_40 + get_local_id_0_38;\n    int32_t our_array_offset_30 = get_group_id_2_43 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = destoffset_1 + our_array_offset_30;\n    int32_t idata_offset_34 = srcoffset_3 + our_array_offset_30;\n    int32_t x_index_31 = get_group_id_0_41 * 16 * mulx_7 + get_local_id_0_38 + srem32(get_local_id_1_39, mulx_7) * 16;\n    int32_t y_index_32 = get_group_id_1_42 * 16 + squot32(get_local_id_1_39, mulx_7);\n    bool val_45;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    \n    if (slt32(x_index_31, x_elems_5) && slt32(y_index_32, y_elems_6)) {\n        val_45 = ((__global bool *) s", "rcmem_2)[sext_i32_i64(idata_offset_34 + index_in_35)];\n        ((__local bool *) block_9)[sext_i32_i64(get_local_id_1_39 * 17 + get_local_id_0_38)] = val_45;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_42 * 16 + squot32(get_local_id_0_38, mulx_7);\n    y_index_32 = get_group_id_0_41 * 16 * mulx_7 + get_local_id_1_39 + srem32(get_local_id_0_38, mulx_7) * 16;\n    \n    int32_t index_out_36 = y_index_32 * y_elems_6 + x_index_31;\n    \n    if (slt32(x_index_31, y_elems_6) && slt32(y_index_32, x_elems_5)) {\n        val_45 = ((__local bool *) block_9)[sext_i32_i64(get_local_id_0_38 * 17 + get_local_id_1_39)];\n        ((__global bool *) destmem_0)[sext_i32_i64(odata_offset_33 + index_out_36)] = val_45;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_bool_low_width(const int block_dim0, const int block_dim1, const int block_dim2, uint block_9_backing_offset_0, int32_t destoffset_1, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6, int32_t mulx_7, int32_t muly_8, __global unsigned char *destmem_0, __global unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 = &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_41;\n    \n    get_group_id_0_41 = get_group_id(0);\n    \n    int32_t get_group_id_1_42;\n    \n    get_group_id_1_42 = get_group_id(1);\n    \n    int32_t get_group_id_2_43;\n    \n    get_group_id_2_43 = get_group_id(2);\n    \n    int32_t get_local_sizze_0_40;\n    \n    get_local_sizze_0_40 = get_local_size(0);\n    \n    int32_t get_global_id_0_37 = get_group_id_0_41 * get_local_sizze_0_40 + get_local_id_0_38;\n    int32_t our_array_offset_30 = get_group_id_2_43 * x_elems_5 * y_elems_6;\n    int32_t odata_of",
                                     "fset_33 = destoffset_1 + our_array_offset_30;\n    int32_t idata_offset_34 = srcoffset_3 + our_array_offset_30;\n    int32_t x_index_31 = get_group_id_0_41 * 16 + squot32(get_local_id_0_38, muly_8);\n    int32_t y_index_32 = get_group_id_1_42 * 16 * muly_8 + get_local_id_1_39 + srem32(get_local_id_0_38, muly_8) * 16;\n    bool val_45;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    \n    if (slt32(x_index_31, x_elems_5) && slt32(y_index_32, y_elems_6)) {\n        val_45 = ((__global bool *) srcmem_2)[sext_i32_i64(idata_offset_34 + index_in_35)];\n        ((__local bool *) block_9)[sext_i32_i64(get_local_id_1_39 * 17 + get_local_id_0_38)] = val_45;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_42 * 16 * muly_8 + get_local_id_0_38 + srem32(get_local_id_1_39, muly_8) * 16;\n    y_index_32 = get_group_id_0_41 * 16 + squot32(get_local_id_1_39, muly_8);\n    \n    int32_t index_out_36 = y_index_32 * y_elems_6 + x_index_31;\n    \n    if (slt32(x_index_31, y_elems_6) && slt32(y_index_32, x_elems_5)) {\n        val_45 = ((__local bool *) block_9)[sext_i32_i64(get_local_id_0_38 * 17 + get_local_id_1_39)];\n        ((__global bool *) destmem_0)[sext_i32_i64(odata_offset_33 + index_out_36)] = val_45;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_bool_small(uint block_9_backing_offset_0, int32_t destoffset_1, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6, int32_t mulx_7, int32_t muly_8, __global unsigned char *destmem_0, __global unsigned char *srcmem_2)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile unsigned char *block_9_backing_0 = &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n   ", " \n    int32_t get_group_id_0_41;\n    \n    get_group_id_0_41 = get_group_id(0);\n    \n    int32_t get_group_id_1_42;\n    \n    get_group_id_1_42 = get_group_id(1);\n    \n    int32_t get_group_id_2_43;\n    \n    get_group_id_2_43 = get_group_id(2);\n    \n    int32_t get_local_sizze_0_40;\n    \n    get_local_sizze_0_40 = get_local_size(0);\n    \n    int32_t get_global_id_0_37 = get_group_id_0_41 * get_local_sizze_0_40 + get_local_id_0_38;\n    int32_t our_array_offset_30 = squot32(get_global_id_0_37, y_elems_6 * x_elems_5) * (y_elems_6 * x_elems_5);\n    int32_t x_index_31 = squot32(srem32(get_global_id_0_37, y_elems_6 * x_elems_5), y_elems_6);\n    int32_t y_index_32 = srem32(get_global_id_0_37, y_elems_6);\n    bool val_45;\n    int32_t odata_offset_33 = destoffset_1 + our_array_offset_30;\n    int32_t idata_offset_34 = srcoffset_3 + our_array_offset_30;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    int32_t index_out_36 = x_index_31 * y_elems_6 + y_index_32;\n    \n    if (slt32(get_global_id_0_37, x_elems_5 * y_elems_6 * num_arrays_4)) {\n        val_45 = ((__global bool *) srcmem_2)[sext_i32_i64(idata_offset_34 + index_in_35)];\n        ((__global bool *) destmem_0)[sext_i32_i64(odata_offset_33 + index_out_36)] = val_45;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_i16(const int block_dim0, const int block_dim1, const int block_dim2, uint block_9_backing_offset_0, int32_t destoffset_1, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6, int32_t mulx_7, int32_t muly_8, __global unsigned char *destmem_0, __global unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 = &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_i", "d_0_41;\n    \n    get_group_id_0_41 = get_group_id(0);\n    \n    int32_t get_group_id_1_42;\n    \n    get_group_id_1_42 = get_group_id(1);\n    \n    int32_t get_group_id_2_43;\n    \n    get_group_id_2_43 = get_group_id(2);\n    \n    int32_t get_local_sizze_0_40;\n    \n    get_local_sizze_0_40 = get_local_size(0);\n    \n    int32_t get_global_id_0_37 = get_group_id_0_41 * get_local_sizze_0_40 + get_local_id_0_38;\n    int32_t our_array_offset_30 = get_group_id_2_43 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = squot32(destoffset_1, 2) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 2) + our_array_offset_30;\n    int32_t x_index_31 = get_global_id_0_37;\n    int32_t y_index_32 = get_group_id_1_42 * 32 + get_local_id_1_39;\n    int16_t val_45;\n    \n    if (slt32(x_index_31, x_elems_5)) {\n        for (int32_t j_44 = 0; j_44 < 4; j_44++) {\n            int32_t index_in_35 = (y_index_32 + j_44 * 8) * x_elems_5 + x_index_31;\n            \n            if (slt32(y_index_32 + j_44 * 8, y_elems_6)) {\n                val_45 = ((__global int16_t *) srcmem_2)[sext_i32_i64(idata_offset_34 + index_in_35)];\n                ((__local int16_t *) block_9)[sext_i32_i64((get_local_id_1_39 + j_44 * 8) * 33 + get_local_id_0_38)] = val_45;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_42 * 32 + get_local_id_0_38;\n    y_index_32 = get_group_id_0_41 * 32 + get_local_id_1_39;\n    if (slt32(x_index_31, y_elems_6)) {\n        for (int32_t j_44 = 0; j_44 < 4; j_44++) {\n            int32_t index_out_36 = (y_index_32 + j_44 * 8) * y_elems_6 + x_index_31;\n            \n            if (slt32(y_index_32 + j_44 * 8, x_elems_5)) {\n                val_45 = ((__local int16_t *) block_9)[sext_i32_i64(get_local_id_0_38 * 33 + get_local_id_1_39 + j_44 * 8)];\n                ((__global int16_t *) destmem_0)[sext_i32_i64(odata_offset_33 + index_out_36)] = val_45;\n            }\n        }\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_ma",
                                     "p_transpose_i16_low_height(const int block_dim0, const int block_dim1, const int block_dim2, uint block_9_backing_offset_0, int32_t destoffset_1, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6, int32_t mulx_7, int32_t muly_8, __global unsigned char *destmem_0, __global unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 = &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_41;\n    \n    get_group_id_0_41 = get_group_id(0);\n    \n    int32_t get_group_id_1_42;\n    \n    get_group_id_1_42 = get_group_id(1);\n    \n    int32_t get_group_id_2_43;\n    \n    get_group_id_2_43 = get_group_id(2);\n    \n    int32_t get_local_sizze_0_40;\n    \n    get_local_sizze_0_40 = get_local_size(0);\n    \n    int32_t get_global_id_0_37 = get_group_id_0_41 * get_local_sizze_0_40 + get_local_id_0_38;\n    int32_t our_array_offset_30 = get_group_id_2_43 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = squot32(destoffset_1, 2) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 2) + our_array_offset_30;\n    int32_t x_index_31 = get_group_id_0_41 * 16 * mulx_7 + get_local_id_0_38 + srem32(get_local_id_1_39, mulx_7) * 16;\n    int32_t y_index_32 = get_group_id_1_42 * 16 + squot32(get_local_id_1_39, mulx_7);\n    int16_t val_45;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    \n    if (slt32(x_index_31, x_elems_5) && slt32(y_index_32, y_elems_6)) {\n        val_45 = ((__global int16_t *) srcmem_2)[sext_i32_i64(idata_offset_34 + index_in_35)];\n        ((__local int16_t *) block_9)[sext_i32_i64(get_local_id_1_39 * 17 + get_local_id_0_38)] = val_45;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_42 * 16 + squ", "ot32(get_local_id_0_38, mulx_7);\n    y_index_32 = get_group_id_0_41 * 16 * mulx_7 + get_local_id_1_39 + srem32(get_local_id_0_38, mulx_7) * 16;\n    \n    int32_t index_out_36 = y_index_32 * y_elems_6 + x_index_31;\n    \n    if (slt32(x_index_31, y_elems_6) && slt32(y_index_32, x_elems_5)) {\n        val_45 = ((__local int16_t *) block_9)[sext_i32_i64(get_local_id_0_38 * 17 + get_local_id_1_39)];\n        ((__global int16_t *) destmem_0)[sext_i32_i64(odata_offset_33 + index_out_36)] = val_45;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_i16_low_width(const int block_dim0, const int block_dim1, const int block_dim2, uint block_9_backing_offset_0, int32_t destoffset_1, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6, int32_t mulx_7, int32_t muly_8, __global unsigned char *destmem_0, __global unsigned char *srcmem_2)\n{\n    volatile unsigned char *block_9_backing_0 = &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_41;\n    \n    get_group_id_0_41 = get_group_id(0);\n    \n    int32_t get_group_id_1_42;\n    \n    get_group_id_1_42 = get_group_id(1);\n    \n    int32_t get_group_id_2_43;\n    \n    get_group_id_2_43 = get_group_id(2);\n    \n    int32_t get_local_sizze_0_40;\n    \n    get_local_sizze_0_40 = get_local_size(0);\n    \n    int32_t get_global_id_0_37 = get_group_id_0_41 * get_local_sizze_0_40 + get_local_id_0_38;\n    int32_t our_array_offset_30 = get_group_id_2_43 * x_elems_5 * y_elems_6;\n    int32_t odata_offset_33 = squot32(destoffset_1, 2) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 2) + our_array_offset_30;\n    int32_t x_index_31 = get_group_id_0_41 * 16 + squot32(get_local_id_0_38, muly_8);\n    int32_t y_ind", "ex_32 = get_group_id_1_42 * 16 * muly_8 + get_local_id_1_39 + srem32(get_local_id_0_38, muly_8) * 16;\n    int16_t val_45;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    \n    if (slt32(x_index_31, x_elems_5) && slt32(y_index_32, y_elems_6)) {\n        val_45 = ((__global int16_t *) srcmem_2)[sext_i32_i64(idata_offset_34 + index_in_35)];\n        ((__local int16_t *) block_9)[sext_i32_i64(get_local_id_1_39 * 17 + get_local_id_0_38)] = val_45;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    x_index_31 = get_group_id_1_42 * 16 * muly_8 + get_local_id_0_38 + srem32(get_local_id_1_39, muly_8) * 16;\n    y_index_32 = get_group_id_0_41 * 16 + squot32(get_local_id_1_39, muly_8);\n    \n    int32_t index_out_36 = y_index_32 * y_elems_6 + x_index_31;\n    \n    if (slt32(x_index_31, y_elems_6) && slt32(y_index_32, x_elems_5)) {\n        val_45 = ((__local int16_t *) block_9)[sext_i32_i64(get_local_id_0_38 * 17 + get_local_id_1_39)];\n        ((__global int16_t *) destmem_0)[sext_i32_i64(odata_offset_33 + index_out_36)] = val_45;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpu_map_transpose_i16_small(uint block_9_backing_offset_0, int32_t destoffset_1, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6, int32_t mulx_7, int32_t muly_8, __global unsigned char *destmem_0, __global unsigned char *srcmem_2)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile unsigned char *block_9_backing_0 = &shared_mem[block_9_backing_offset_0];\n    __local unsigned char *block_9;\n    \n    block_9 = (__local unsigned char *) block_9_backing_0;\n    \n    int32_t get_local_id_0_38;\n    \n    get_local_id_0_38 = get_local_id(0);\n    \n    int32_t get_local_id_1_39;\n    \n    get_local_id_1_39 = get_local_id(1);\n    \n    int32_t get_group_id_0_41;\n    \n    get_group_id_0_41 = get_group_id(0);\n    \n    int32_t get_group_id_1_42;\n    \n    get_group_id_1_42 = get_group_id(1);\n    \n    int32_t get_group_id_2_43;\n   ",
                                     " \n    get_group_id_2_43 = get_group_id(2);\n    \n    int32_t get_local_sizze_0_40;\n    \n    get_local_sizze_0_40 = get_local_size(0);\n    \n    int32_t get_global_id_0_37 = get_group_id_0_41 * get_local_sizze_0_40 + get_local_id_0_38;\n    int32_t our_array_offset_30 = squot32(get_global_id_0_37, y_elems_6 * x_elems_5) * (y_elems_6 * x_elems_5);\n    int32_t x_index_31 = squot32(srem32(get_global_id_0_37, y_elems_6 * x_elems_5), y_elems_6);\n    int32_t y_index_32 = srem32(get_global_id_0_37, y_elems_6);\n    int16_t val_45;\n    int32_t odata_offset_33 = squot32(destoffset_1, 2) + our_array_offset_30;\n    int32_t idata_offset_34 = squot32(srcoffset_3, 2) + our_array_offset_30;\n    int32_t index_in_35 = y_index_32 * x_elems_5 + x_index_31;\n    int32_t index_out_36 = x_index_31 * y_elems_6 + y_index_32;\n    \n    if (slt32(get_global_id_0_37, x_elems_5 * y_elems_6 * num_arrays_4)) {\n        val_45 = ((__global int16_t *) srcmem_2)[sext_i32_i64(idata_offset_34 + index_in_35)];\n        ((__global int16_t *) destmem_0)[sext_i32_i64(odata_offset_33 + index_out_36)] = val_45;\n    }\n    \n  error_0:\n    return;\n}\n__kernel void gpuseq_18858(__global int *global_failure, __global unsigned char *mem_param_18367, __global unsigned char *mem_18394)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18860;\n    int64_t group_sizze_18863;\n    int32_t wave_sizze_18862;\n    int32_t group_tid_18861;\n    \n    local_tid_18860 = get_local_id(0);\n    group_sizze_18863 = get_local_size(0);\n    wave_sizze_18862 = LOCKSTEP_WIDTH;\n    group_tid_18861 = get_group_id(0);\n    \n    int32_t global_tid_18859 = group_tid_18861 * group_sizze_18863 + local_tid_18860;\n    int32_t tid_18858 = global_tid_18859;\n    int64_t i6_18097 = ((__global int64_t *) mem_param_18367)[(int64_t) 0];\n    int64_t arg_18098 = mul64((int64_t) 128, i6_18097);\n    \n    ((__global int64_t *) mem_18394)[(int64_t) 0] ", "= arg_18098;\n    \n  error_0:\n    return;\n}\n__kernel void gpuseq_19173(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, __global unsigned char *mem_param_18367, __global unsigned char *ext_mem_18526, __global unsigned char *ext_mem_18527, __global unsigned char *mem_18530, __global unsigned char *mem_18532, __global unsigned char *mem_18534, __global unsigned char *mem_18536, __global unsigned char *mem_18538, __global unsigned char *mem_18540, __global unsigned char *mem_18542, __global unsigned char *mem_18544)\n{\n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_19175;\n    int64_t group_sizze_19178;\n    int32_t wave_sizze_19177;\n    int32_t group_tid_19176;\n    \n    local_tid_19175 = get_local_id(0);\n    group_sizze_19178 = get_local_size(0);\n    wave_sizze_19177 = LOCKSTEP_WIDTH;\n    group_tid_19176 = get_group_id(0);\n    \n    int32_t global_tid_19174 = group_tid_19176 * group_sizze_19178 + local_tid_19175;\n    int32_t tid_19173 = global_tid_19174;\n    int64_t defunc_0_reduce_res_18106 = ((__global int64_t *) mem_18530)[(int64_t) 0];\n    bool cond_18109 = defunc_0_reduce_res_18106 == (int64_t) 268435456;\n    int64_t findidx_res_18113;\n    \n    if (cond_18109 == 1) {\n        findidx_res_18113 = (int64_t) -1;\n    } else {\n        findidx_res_18113 = defunc_0_reduce_res_18106;\n    }\n    \n    bool eq_x_zz_18116 = (int64_t) -1 == defunc_0_reduce_res_18106;\n    bool not_p_18119 = !cond_18109;\n    bool p_and_eq_x_y_18123 = eq_x_zz_18116 && not_p_18119;\n    bool cond_18127 = cond_18109 || p_and_eq_x_y_18123;\n    int64_t i6_18130 = ((__global int64_t *) mem_param_18367)[(int64_t) 0];\n    int64_t loopres_18208;\n    bool loopres_18209;\n    int16_t loopres_18210;\n    int16_t loopres_18211;\n    int16_t loopres_18212;\n    int16_t loopres_18213;\n    \n    if (cond_18127 == 1) {\n        int64_t loopres_t_res_18131 = add", "64((int64_t) 1, i6_18130);\n        \n        loopres_18208 = loopres_t_res_18131;\n        loopres_18209 = 0;\n        loopres_18210 = (int16_t) 0;\n        loopres_18211 = (int16_t) 0;\n        loopres_18212 = (int16_t) 0;\n        loopres_18213 = (int16_t) 0;\n    } else {\n        int64_t loopres_f_res_18132 = add64((int64_t) 1, i6_18130);\n        bool x_18134 = sle64((int64_t) 0, findidx_res_18113);\n        bool y_18135 = slt64(findidx_res_18113, (int64_t) 268435456);\n        bool bounds_check_18136 = x_18134 && y_18135;\n        bool index_certs_18137;\n        \n        if (!bounds_check_18136) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 28) == -1) {\n                    global_failure_args[0] = (int64_t) findidx_res_18113;\n                    global_failure_args[1] = (int64_t) (int64_t) 268435456;\n                    ;\n                }\n                return;\n            }\n        }\n        \n        int64_t new_index_18138 = squot64(findidx_res_18113, (int64_t) 2097152);\n        int64_t binop_y_18139 = (int64_t) 2097152 * new_index_18138;\n        int64_t binop_x_18140 = findidx_res_18113 - binop_y_18139;\n        int64_t new_index_18141 = squot64(binop_x_18140, (int64_t) 16384);\n        int64_t binop_y_18142 = (int64_t) 16384 * new_index_18141;\n        int64_t binop_x_18143 = binop_x_18140 - binop_y_18142;\n        int64_t new_index_18144 = squot64(binop_x_18143, (int64_t) 128);\n        int64_t binop_y_18145 = (int64_t) 128 * new_index_18144;\n        int64_t new_index_18146 = binop_x_18143 - binop_y_18145;\n        bool loopres_f_res_18147 = ((__global bool *) ext_mem_18527)[new_index_18138 * (int64_t) 2097152 + new_index_18141 * (int64_t) 16384 + new_index_18144 * (int64_t) 128 + new_index_18146];\n        bool index_certs_18148;\n        \n        if (!bounds_check_18136) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 29) == -1) {\n                    global_failure_args[0] = (int64_t) findidx_res_18113",
                                     ";\n                    global_failure_args[1] = (int64_t) (int64_t) 0;\n                    global_failure_args[2] = (int64_t) (int64_t) 268435456;\n                    global_failure_args[3] = (int64_t) (int64_t) 4;\n                    ;\n                }\n                return;\n            }\n        }\n        \n        int64_t binop_x_18149 = (int64_t) 4 * findidx_res_18113;\n        int64_t new_index_18150 = squot64(binop_x_18149, (int64_t) 8388608);\n        int64_t binop_y_18151 = (int64_t) 8388608 * new_index_18150;\n        int64_t binop_x_18152 = binop_x_18149 - binop_y_18151;\n        int64_t new_index_18153 = squot64(binop_x_18152, (int64_t) 65536);\n        int64_t binop_y_18154 = (int64_t) 65536 * new_index_18153;\n        int64_t binop_x_18155 = binop_x_18152 - binop_y_18154;\n        int64_t new_index_18156 = squot64(binop_x_18155, (int64_t) 512);\n        int64_t binop_y_18157 = (int64_t) 512 * new_index_18156;\n        int64_t binop_x_18158 = binop_x_18155 - binop_y_18157;\n        int64_t new_index_18159 = squot64(binop_x_18158, (int64_t) 4);\n        int64_t binop_y_18160 = (int64_t) 4 * new_index_18159;\n        int64_t new_index_18161 = binop_x_18158 - binop_y_18160;\n        int16_t loopres_f_res_18162 = ((__global int16_t *) ext_mem_18526)[new_index_18150 * (int64_t) 8388608 + new_index_18153 * (int64_t) 65536 + new_index_18156 * (int64_t) 512 + new_index_18159 * (int64_t) 4 + new_index_18161];\n        bool index_certs_18163;\n        \n        if (!bounds_check_18136) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 30) == -1) {\n                    global_failure_args[0] = (int64_t) findidx_res_18113;\n                    global_failure_args[1] = (int64_t) (int64_t) 1;\n                    global_failure_args[2] = (int64_t) (int64_t) 268435456;\n                    global_failure_args[3] = (int64_t) (int64_t) 4;\n                    ;\n                }\n                return;\n            }\n        }\n        \n        int64_t binop_x_1", "8164 = (int64_t) 1 + binop_x_18149;\n        int64_t new_index_18165 = squot64(binop_x_18164, (int64_t) 8388608);\n        int64_t binop_y_18166 = (int64_t) 8388608 * new_index_18165;\n        int64_t binop_x_18167 = binop_x_18164 - binop_y_18166;\n        int64_t new_index_18168 = squot64(binop_x_18167, (int64_t) 65536);\n        int64_t binop_y_18169 = (int64_t) 65536 * new_index_18168;\n        int64_t binop_x_18170 = binop_x_18167 - binop_y_18169;\n        int64_t new_index_18171 = squot64(binop_x_18170, (int64_t) 512);\n        int64_t binop_y_18172 = (int64_t) 512 * new_index_18171;\n        int64_t binop_x_18173 = binop_x_18170 - binop_y_18172;\n        int64_t new_index_18174 = squot64(binop_x_18173, (int64_t) 4);\n        int64_t binop_y_18175 = (int64_t) 4 * new_index_18174;\n        int64_t new_index_18176 = binop_x_18173 - binop_y_18175;\n        int16_t loopres_f_res_18177 = ((__global int16_t *) ext_mem_18526)[new_index_18165 * (int64_t) 8388608 + new_index_18168 * (int64_t) 65536 + new_index_18171 * (int64_t) 512 + new_index_18174 * (int64_t) 4 + new_index_18176];\n        bool index_certs_18178;\n        \n        if (!bounds_check_18136) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 31) == -1) {\n                    global_failure_args[0] = (int64_t) findidx_res_18113;\n                    global_failure_args[1] = (int64_t) (int64_t) 2;\n                    global_failure_args[2] = (int64_t) (int64_t) 268435456;\n                    global_failure_args[3] = (int64_t) (int64_t) 4;\n                    ;\n                }\n                return;\n            }\n        }\n        \n        int64_t binop_x_18179 = (int64_t) 2 + binop_x_18149;\n        int64_t new_index_18180 = squot64(binop_x_18179, (int64_t) 8388608);\n        int64_t binop_y_18181 = (int64_t) 8388608 * new_index_18180;\n        int64_t binop_x_18182 = binop_x_18179 - binop_y_18181;\n        int64_t new_index_18183 = squot64(binop_x_18182, (int64_t) 65536);\n        int64_t bino", "p_y_18184 = (int64_t) 65536 * new_index_18183;\n        int64_t binop_x_18185 = binop_x_18182 - binop_y_18184;\n        int64_t new_index_18186 = squot64(binop_x_18185, (int64_t) 512);\n        int64_t binop_y_18187 = (int64_t) 512 * new_index_18186;\n        int64_t binop_x_18188 = binop_x_18185 - binop_y_18187;\n        int64_t new_index_18189 = squot64(binop_x_18188, (int64_t) 4);\n        int64_t binop_y_18190 = (int64_t) 4 * new_index_18189;\n        int64_t new_index_18191 = binop_x_18188 - binop_y_18190;\n        int16_t loopres_f_res_18192 = ((__global int16_t *) ext_mem_18526)[new_index_18180 * (int64_t) 8388608 + new_index_18183 * (int64_t) 65536 + new_index_18186 * (int64_t) 512 + new_index_18189 * (int64_t) 4 + new_index_18191];\n        bool index_certs_18193;\n        \n        if (!bounds_check_18136) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 32) == -1) {\n                    global_failure_args[0] = (int64_t) findidx_res_18113;\n                    global_failure_args[1] = (int64_t) (int64_t) 3;\n                    global_failure_args[2] = (int64_t) (int64_t) 268435456;\n                    global_failure_args[3] = (int64_t) (int64_t) 4;\n                    ;\n                }\n                return;\n            }\n        }\n        \n        int64_t binop_x_18194 = (int64_t) 3 + binop_x_18149;\n        int64_t new_index_18195 = squot64(binop_x_18194, (int64_t) 8388608);\n        int64_t binop_y_18196 = (int64_t) 8388608 * new_index_18195;\n        int64_t binop_x_18197 = binop_x_18194 - binop_y_18196;\n        int64_t new_index_18198 = squot64(binop_x_18197, (int64_t) 65536);\n        int64_t binop_y_18199 = (int64_t) 65536 * new_index_18198;\n        int64_t binop_x_18200 = binop_x_18197 - binop_y_18199;\n        int64_t new_index_18201 = squot64(binop_x_18200, (int64_t) 512);\n        int64_t binop_y_18202 = (int64_t) 512 * new_index_18201;\n        int64_t binop_x_18203 = binop_x_18200 - binop_y_18202;\n        int64_t new_index_182",
                                     "04 = squot64(binop_x_18203, (int64_t) 4);\n        int64_t binop_y_18205 = (int64_t) 4 * new_index_18204;\n        int64_t new_index_18206 = binop_x_18203 - binop_y_18205;\n        int16_t loopres_f_res_18207 = ((__global int16_t *) ext_mem_18526)[new_index_18195 * (int64_t) 8388608 + new_index_18198 * (int64_t) 65536 + new_index_18201 * (int64_t) 512 + new_index_18204 * (int64_t) 4 + new_index_18206];\n        \n        loopres_18208 = loopres_f_res_18132;\n        loopres_18209 = loopres_f_res_18147;\n        loopres_18210 = loopres_f_res_18162;\n        loopres_18211 = loopres_f_res_18177;\n        loopres_18212 = loopres_f_res_18192;\n        loopres_18213 = loopres_f_res_18207;\n    }\n    \n    bool cond_18221 = slt64(loopres_18208, (int64_t) 8);\n    bool loop_cond_t_res_18224 = loopres_18209 == 0;\n    bool x_18228 = cond_18221 && loop_cond_t_res_18224;\n    \n    ((__global int64_t *) mem_18532)[(int64_t) 0] = loopres_18208;\n    ((__global bool *) mem_18534)[(int64_t) 0] = loopres_18209;\n    ((__global int16_t *) mem_18536)[(int64_t) 0] = loopres_18210;\n    ((__global int16_t *) mem_18538)[(int64_t) 0] = loopres_18211;\n    ((__global int16_t *) mem_18540)[(int64_t) 0] = loopres_18212;\n    ((__global int16_t *) mem_18542)[(int64_t) 0] = loopres_18213;\n    ((__global bool *) mem_18544)[(int64_t) 0] = x_18228;\n    \n  error_0:\n    return;\n}\n__kernel void segmap_14640(__global int *global_failure, __global unsigned char *mem_18281, __global unsigned char *mem_18286)\n{\n    #define segmap_group_sizze_14634 (segmap_group_sizze_14423)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18681;\n    int64_t group_sizze_18684;\n    int32_t wave_sizze_18683;\n    int32_t group_tid_18682;\n    \n    local_tid_18681 = get_local_id(0);\n    group_sizze_18684 = get_local_size(0);\n    wave_sizze_18683 = LOCKSTEP_WIDTH;\n    group_tid_18682 = get_group_id(0);\n    \n    int32_t glob", "al_tid_18680 = group_tid_18682 * group_sizze_18684 + local_tid_18681;\n    int32_t phys_tid_14640 = global_tid_18680;\n    int64_t global_tid_18685 = sext_i32_i64(group_tid_18682) * segmap_group_sizze_14634 + sext_i32_i64(local_tid_18681);\n    int64_t slice_18686 = (int64_t) 2;\n    int64_t slice_18687 = (int64_t) 16 * slice_18686;\n    int64_t slice_18688 = (int64_t) 16 * slice_18687;\n    int64_t gtid_14637 = squot64(global_tid_18685, slice_18687);\n    int64_t remnant_18689 = global_tid_18685 - gtid_14637 * slice_18687;\n    int64_t gtid_14638 = squot64(remnant_18689, slice_18686);\n    int64_t remnant_18690 = remnant_18689 - gtid_14638 * slice_18686;\n    int64_t gtid_14639 = remnant_18690;\n    int64_t remnant_18691 = remnant_18690 - gtid_14639;\n    \n    if ((slt64(gtid_14637, (int64_t) 16) && slt64(gtid_14638, (int64_t) 16)) && slt64(gtid_14639, (int64_t) 2)) {\n        int8_t x_14641 = ((__global int8_t *) mem_18281)[gtid_14639];\n        bool u8_res_14642 = itob_i8_bool(x_14641);\n        \n        ((__global bool *) mem_18286)[gtid_14637 * (int64_t) 32 + gtid_14638 * (int64_t) 2 + gtid_14639] = u8_res_14642;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_14634\n}\n__kernel void segmap_14661(__global int *global_failure, __global unsigned char *mem_18281, __global unsigned char *mem_18289)\n{\n    #define segmap_group_sizze_14654 (segmap_group_sizze_14337)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18694;\n    int64_t group_sizze_18697;\n    int32_t wave_sizze_18696;\n    int32_t group_tid_18695;\n    \n    local_tid_18694 = get_local_id(0);\n    group_sizze_18697 = get_local_size(0);\n    wave_sizze_18696 = LOCKSTEP_WIDTH;\n    group_tid_18695 = get_group_id(0);\n    \n    int32_t global_tid_18693 = group_tid_18695 * group_sizze_18697 + local_tid_18694;\n    int32_t phys_tid_14661 = global_tid_18693;\n    int64_t global_tid_18698 = sext_i32_i", "64(group_tid_18695) * segmap_group_sizze_14654 + sext_i32_i64(local_tid_18694);\n    int64_t slice_18699 = (int64_t) 2;\n    int64_t slice_18700 = (int64_t) 2 * slice_18699;\n    int64_t slice_18701 = (int64_t) 16 * slice_18700;\n    int64_t slice_18702 = (int64_t) 16 * slice_18701;\n    int64_t gtid_14657 = squot64(global_tid_18698, slice_18701);\n    int64_t remnant_18703 = global_tid_18698 - gtid_14657 * slice_18701;\n    int64_t gtid_14658 = squot64(remnant_18703, slice_18700);\n    int64_t remnant_18704 = remnant_18703 - gtid_14658 * slice_18700;\n    int64_t gtid_14659 = squot64(remnant_18704, slice_18699);\n    int64_t remnant_18705 = remnant_18704 - gtid_14659 * slice_18699;\n    int64_t gtid_14660 = remnant_18705;\n    int64_t remnant_18706 = remnant_18705 - gtid_14660;\n    \n    if (((slt64(gtid_14657, (int64_t) 16) && slt64(gtid_14658, (int64_t) 16)) && slt64(gtid_14659, (int64_t) 2)) && slt64(gtid_14660, (int64_t) 2)) {\n        int8_t x_14662 = ((__global int8_t *) mem_18281)[gtid_14660];\n        bool u8_res_14663 = itob_i8_bool(x_14662);\n        \n        ((__global bool *) mem_18289)[gtid_14657 * (int64_t) 64 + gtid_14658 * (int64_t) 4 + gtid_14659 * (int64_t) 2 + gtid_14660] = u8_res_14663;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_14654\n}\n__kernel void segmap_14684(__global int *global_failure, __global unsigned char *mem_18283, __global unsigned char *mem_18286, __global unsigned char *mem_18289, __global unsigned char *mem_18292)\n{\n    #define segmap_group_sizze_14676 (segmap_group_sizze_14275)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18709;\n    int64_t group_sizze_18712;\n    int32_t wave_sizze_18711;\n    int32_t group_tid_18710;\n    \n    local_tid_18709 = get_local_id(0);\n    group_sizze_18712 = get_local_size(0);\n    wave_sizze_18711 = LOCKSTEP_WIDTH;\n    group_tid_18710 = get_group_id(0);\n    \n    int32_t gl",
                                     "obal_tid_18708 = group_tid_18710 * group_sizze_18712 + local_tid_18709;\n    int32_t phys_tid_14684 = global_tid_18708;\n    int64_t global_tid_18713 = sext_i32_i64(group_tid_18710) * segmap_group_sizze_14676 + sext_i32_i64(local_tid_18709);\n    int64_t slice_18714 = (int64_t) 16;\n    int64_t slice_18715 = (int64_t) 2 * slice_18714;\n    int64_t slice_18716 = (int64_t) 2 * slice_18715;\n    int64_t slice_18717 = (int64_t) 16 * slice_18716;\n    int64_t slice_18718 = (int64_t) 16 * slice_18717;\n    int64_t gtid_14679 = squot64(global_tid_18713, slice_18717);\n    int64_t remnant_18719 = global_tid_18713 - gtid_14679 * slice_18717;\n    int64_t gtid_14680 = squot64(remnant_18719, slice_18716);\n    int64_t remnant_18720 = remnant_18719 - gtid_14680 * slice_18716;\n    int64_t gtid_14681 = squot64(remnant_18720, slice_18715);\n    int64_t remnant_18721 = remnant_18720 - gtid_14681 * slice_18715;\n    int64_t gtid_14682 = squot64(remnant_18721, slice_18714);\n    int64_t remnant_18722 = remnant_18721 - gtid_14682 * slice_18714;\n    int64_t gtid_14683 = remnant_18722;\n    int64_t remnant_18723 = remnant_18722 - gtid_14683;\n    \n    if ((((slt64(gtid_14679, (int64_t) 16) && slt64(gtid_14680, (int64_t) 16)) && slt64(gtid_14681, (int64_t) 2)) && slt64(gtid_14682, (int64_t) 2)) && slt64(gtid_14683, (int64_t) 16)) {\n        int8_t x_14685 = ((__global int8_t *) mem_18283)[gtid_14679];\n        int8_t x_14686 = ((__global int8_t *) mem_18283)[gtid_14680];\n        int8_t x_14689 = ((__global int8_t *) mem_18283)[gtid_14683];\n        bool cond_14690 = ult8(x_14689, x_14685);\n        int8_t comperator_res_14691;\n        \n        if (cond_14690 == 1) {\n            comperator_res_14691 = (int8_t) 0;\n        } else {\n            bool u8_res_14687 = ((__global bool *) mem_18286)[gtid_14679 * (int64_t) 32 + gtid_14680 * (int64_t) 2 + gtid_14681];\n            int8_t comperator_res_f_res_14692;\n            \n            if (u8_res_14687 == 1) {\n                int8_t comperator_res_f_res_t_res_14693 ", "= sub8(x_14689, x_14685);\n                \n                comperator_res_f_res_14692 = comperator_res_f_res_t_res_14693;\n            } else {\n                comperator_res_f_res_14692 = x_14689;\n            }\n            comperator_res_14691 = comperator_res_f_res_14692;\n        }\n        \n        bool cond_14694 = ult8(x_14686, x_14689);\n        int8_t comperator_res_14695;\n        \n        if (cond_14694 == 1) {\n            comperator_res_14695 = (int8_t) 0;\n        } else {\n            bool u8_res_14688 = ((__global bool *) mem_18289)[gtid_14679 * (int64_t) 64 + gtid_14680 * (int64_t) 4 + gtid_14681 * (int64_t) 2 + gtid_14682];\n            int8_t comperator_res_f_res_14696;\n            \n            if (u8_res_14688 == 1) {\n                int8_t comperator_res_f_res_t_res_14697 = sub8(x_14686, x_14689);\n                \n                comperator_res_f_res_14696 = comperator_res_f_res_t_res_14697;\n            } else {\n                comperator_res_f_res_14696 = x_14686;\n            }\n            comperator_res_14695 = comperator_res_f_res_14696;\n        }\n        \n        bool cond_14698 = ult8(comperator_res_14695, comperator_res_14691);\n        int8_t layer_res_14699;\n        \n        if (cond_14698 == 1) {\n            layer_res_14699 = comperator_res_14691;\n        } else {\n            layer_res_14699 = comperator_res_14695;\n        }\n        ((__global int8_t *) mem_18292)[gtid_14679 * (int64_t) 1024 + gtid_14680 * (int64_t) 64 + gtid_14681 * (int64_t) 32 + gtid_14682 * (int64_t) 16 + gtid_14683] = layer_res_14699;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_14676\n}\n__kernel void segmap_14713(__global int *global_failure, int64_t num_groups_14706, int32_t virt_num_groups_18725, __global unsigned char *mem_18281, __global unsigned char *mem_18283, __global unsigned char *mem_18296)\n{\n    #define segmap_group_sizze_14705 (segmap_group_sizze_14231)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = ", "2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_18727;\n    int64_t group_sizze_18730;\n    int32_t wave_sizze_18729;\n    int32_t group_tid_18728;\n    \n    local_tid_18727 = get_local_id(0);\n    group_sizze_18730 = get_local_size(0);\n    wave_sizze_18729 = LOCKSTEP_WIDTH;\n    group_tid_18728 = get_group_id(0);\n    \n    int32_t global_tid_18726 = group_tid_18728 * group_sizze_18730 + local_tid_18727;\n    int32_t phys_tid_14713 = global_tid_18726;\n    int32_t phys_group_id_18731;\n    \n    phys_group_id_18731 = get_group_id(0);\n    \n    int32_t iterations_18732 = sdiv_up32(virt_num_groups_18725 - phys_group_id_18731, sext_i64_i32(num_groups_14706));\n    \n    for (int32_t i_18733 = 0; i_18733 < iterations_18732; i_18733++) {\n        int32_t virt_group_id_18734 = phys_group_id_18731 + i_18733 * sext_i64_i32(num_groups_14706);\n        int64_t global_tid_18735 = sext_i32_i64(virt_group_id_18734) * segmap_group_sizze_14705 + sext_i32_i64(local_tid_18727);\n        int64_t slice_18736 = (int64_t) 2;\n        int64_t slice_18737 = (int64_t) 2 * slice_18736;\n        int64_t slice_18738 = (int64_t) 16 * slice_18737;\n        int64_t slice_18739 = (int64_t) 16 * slice_18738;\n        int64_t gtid_14709 = squot64(global_tid_18735, slice_18738);\n        int64_t remnant_18740 = global_tid_18735 - gtid_14709 * slice_18738;\n        int64_t gtid_14710 = squot64(remnant_18740, slice_18737);\n        int64_t remnant_18741 = remnant_18740 - gtid_14710 * slice_18737;\n        int64_t gtid_14711 = squot64(remnant_18741, slice_18736);\n        int64_t remnant_18742 = remnant_18741 - gtid_14711 * slice_18736;\n        int64_t gtid_14712 = remnant_18742;\n        int64_t remnant_18743 = remnant_18742 - gtid_14712;\n        \n        if (((slt64(gtid_14709, (int64_t) 16) && slt64(gtid_14710, (int64_t) 16)) && slt64(gtid_14711, (int64_t) 2)) && slt64(gtid_14712, (int64_t) 2)) {\n            int8_t x_14714 = ((__global int8_t *) mem_18283)[gtid_14709];\n            int8_t x_147",
                                     "15 = ((__global int8_t *) mem_18283)[gtid_14710];\n            int8_t x_14716 = ((__global int8_t *) mem_18281)[gtid_14711];\n            int8_t x_14717 = ((__global int8_t *) mem_18281)[gtid_14712];\n            int8_t mem_18294[(int64_t) 4];\n            \n            mem_18294[(int64_t) 0] = x_14714;\n            mem_18294[(int64_t) 1] = x_14715;\n            mem_18294[(int64_t) 2] = x_14716;\n            mem_18294[(int64_t) 3] = x_14717;\n            for (int64_t i_18744 = 0; i_18744 < (int64_t) 4; i_18744++) {\n                int8_t tmp_18745 = mem_18294[i_18744];\n                \n                ((__global int8_t *) mem_18296)[gtid_14709 * (int64_t) 256 + gtid_14710 * (int64_t) 16 + gtid_14711 * (int64_t) 8 + gtid_14712 * (int64_t) 4 + i_18744] = tmp_18745;\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_14705\n}\n__kernel void segmap_14886(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_12396, int64_t arg_12814, int64_t arg_12818, int64_t num_groups_14881, int32_t virt_num_groups_18864, __global unsigned char *mem_18283, __global unsigned char *mem_18292, __global unsigned char *mem_18394, __global unsigned char *mem_18518, __global unsigned char *mem_18519)\n{\n    #define segmap_group_sizze_14880 (segmap_group_sizze_14754)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_18866;\n    int64_t group_sizze_18869;\n    int32_t wave_sizze_18868;\n    int32_t group_tid_18867;\n    \n    local_tid_18866 = get_local_id(0);\n    group_sizze_18869 = get_local_size(0);\n    wave_sizze_18868 = LOCKSTEP_WIDTH;\n    group_tid_18867 = ge", "t_group_id(0);\n    \n    int32_t global_tid_18865 = group_tid_18867 * group_sizze_18869 + local_tid_18866;\n    int32_t phys_tid_14886 = global_tid_18865;\n    int32_t phys_group_id_18870;\n    \n    phys_group_id_18870 = get_group_id(0);\n    \n    int32_t iterations_18871 = sdiv_up32(virt_num_groups_18864 - phys_group_id_18870, sext_i64_i32(num_groups_14881));\n    \n    for (int32_t i_18872 = 0; i_18872 < iterations_18871; i_18872++) {\n        int32_t virt_group_id_18873 = phys_group_id_18870 + i_18872 * sext_i64_i32(num_groups_14881);\n        int64_t global_tid_18874 = sext_i32_i64(virt_group_id_18873) * segmap_group_sizze_14880 + sext_i32_i64(local_tid_18866);\n        int64_t slice_18875 = (int64_t) 128;\n        int64_t gtid_14885 = global_tid_18874;\n        int64_t remnant_18876 = global_tid_18874 - gtid_14885;\n        \n        if (slt64(gtid_14885, (int64_t) 128)) {\n            int64_t arg_18100 = ((__global int64_t *) mem_18394)[(int64_t) 0];\n            int64_t defunc_0_f_res_14888 = add64(arg_12396, gtid_14885);\n            int16_t i64_res_14889 = sext_i64_i16(defunc_0_f_res_14888);\n            bool x_14890 = sle64((int64_t) 0, defunc_0_f_res_14888);\n            bool y_14891 = slt64(defunc_0_f_res_14888, (int64_t) 1024);\n            bool bounds_check_14892 = x_14890 && y_14891;\n            int64_t binop_x_14893 = (int64_t) 16 * defunc_0_f_res_14888;\n            bool mem_18487[(int64_t) 128 * (int64_t) 128 * (int64_t) 128];\n            int16_t mem_18488[(int64_t) 128 * (int64_t) 128 * (int64_t) 128 * (int64_t) 4];\n            int16_t mem_18501[(int64_t) 4];\n            \n            for (int64_t i_17989 = 0; i_17989 < (int64_t) 128; i_17989++) {\n                int64_t index_primexp_18039 = add64(arg_12814, i_17989);\n                int16_t i64_res_14897 = sext_i64_i16(index_primexp_18039);\n                bool x_14898 = sle64((int64_t) 0, index_primexp_18039);\n                bool y_14899 = slt64(index_primexp_18039, (int64_t) 1024);\n                bool bounds_chec", "k_14900 = x_14898 && y_14899;\n                int64_t binop_x_14901 = (int64_t) 16 * index_primexp_18039;\n                \n                for (int64_t i_17996 = 0; i_17996 < (int64_t) 128; i_17996++) {\n                    int64_t index_primexp_18038 = add64(arg_12818, i_17996);\n                    int16_t i64_res_14905 = sext_i64_i16(index_primexp_18038);\n                    bool x_14906 = sle64((int64_t) 0, index_primexp_18038);\n                    bool y_14907 = slt64(index_primexp_18038, (int64_t) 1024);\n                    bool bounds_check_14908 = x_14906 && y_14907;\n                    int64_t binop_x_14909 = (int64_t) 16 * index_primexp_18038;\n                    \n                    for (int64_t i_18003 = 0; i_18003 < (int64_t) 128; i_18003++) {\n                        int64_t index_primexp_18037 = add64(i_18003, arg_18100);\n                        bool x_14913 = sle64((int64_t) 0, index_primexp_18037);\n                        bool y_14914 = slt64(index_primexp_18037, (int64_t) 1024);\n                        bool bounds_check_14915 = x_14913 && y_14914;\n                        int64_t binop_x_14916 = (int64_t) 16 * index_primexp_18037;\n                        bool all_equal_14917;\n                        bool redout_18006 = 1;\n                        \n                        for (int64_t i_18007 = 0; i_18007 < (int64_t) 16; i_18007++) {\n                            int8_t x_14921 = ((__global int8_t *) mem_18283)[i_18007];\n                            int64_t u8_res_14922 = zext_i8_i64(x_14921);\n                            bool x_14923 = sle64((int64_t) 0, u8_res_14922);\n                            bool y_14924 = slt64(u8_res_14922, (int64_t) 16);\n                            bool bounds_check_14925 = x_14923 && y_14924;\n                            bool index_ok_14926 = bounds_check_14915 && bounds_check_14925;\n                            bool index_certs_14927;\n                            \n                            if (!index_ok_14926) {\n                   ",
                                     "             {\n                                    if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                                        global_failure_args[0] = (int64_t) index_primexp_18037;\n                                        global_failure_args[1] = (int64_t) u8_res_14922;\n                                        global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                        global_failure_args[3] = (int64_t) (int64_t) 16;\n                                        ;\n                                    }\n                                    local_failure = 1;\n                                    goto error_0;\n                                }\n                            }\n                            \n                            int64_t binop_x_14928 = binop_x_14916 + u8_res_14922;\n                            int64_t new_index_14929 = squot64(binop_x_14928, (int64_t) 1024);\n                            int64_t binop_y_14930 = (int64_t) 1024 * new_index_14929;\n                            int64_t binop_x_14931 = binop_x_14928 - binop_y_14930;\n                            int64_t new_index_14932 = squot64(binop_x_14931, (int64_t) 64);\n                            int64_t binop_y_14933 = (int64_t) 64 * new_index_14932;\n                            int64_t binop_x_14934 = binop_x_14931 - binop_y_14933;\n                            int64_t new_index_14935 = squot64(binop_x_14934, (int64_t) 32);\n                            int64_t binop_y_14936 = (int64_t) 32 * new_index_14935;\n                            int64_t binop_x_14937 = binop_x_14934 - binop_y_14936;\n                            int64_t new_index_14938 = squot64(binop_x_14937, (int64_t) 16);\n                            int64_t binop_y_14939 = (int64_t) 16 * new_index_14938;\n                            int64_t new_index_14940 = binop_x_14937 - binop_y_14939;\n                            int8_t defunc_0_f_res_14941 = ((__global int8_t *) mem_18292)[new_index_14929 * (int64_t) 10", "24 + new_index_14932 * (int64_t) 64 + new_index_14935 * (int64_t) 32 + new_index_14938 * (int64_t) 16 + new_index_14940];\n                            int64_t u8_res_14942 = zext_i8_i64(defunc_0_f_res_14941);\n                            bool x_14943 = sle64((int64_t) 0, u8_res_14942);\n                            bool y_14944 = slt64(u8_res_14942, (int64_t) 16);\n                            bool bounds_check_14945 = x_14943 && y_14944;\n                            bool index_ok_14946 = bounds_check_14908 && bounds_check_14945;\n                            bool index_certs_14947;\n                            \n                            if (!index_ok_14946) {\n                                {\n                                    if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                                        global_failure_args[0] = (int64_t) index_primexp_18038;\n                                        global_failure_args[1] = (int64_t) u8_res_14942;\n                                        global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                        global_failure_args[3] = (int64_t) (int64_t) 16;\n                                        ;\n                                    }\n                                    local_failure = 1;\n                                    goto error_0;\n                                }\n                            }\n                            \n                            int64_t binop_x_14948 = binop_x_14909 + u8_res_14942;\n                            int64_t new_index_14949 = squot64(binop_x_14948, (int64_t) 1024);\n                            int64_t binop_y_14950 = (int64_t) 1024 * new_index_14949;\n                            int64_t binop_x_14951 = binop_x_14948 - binop_y_14950;\n                            int64_t new_index_14952 = squot64(binop_x_14951, (int64_t) 64);\n                            int64_t binop_y_14953 = (int64_t) 64 * new_index_14952;\n                            int64_t binop_x", "_14954 = binop_x_14951 - binop_y_14953;\n                            int64_t new_index_14955 = squot64(binop_x_14954, (int64_t) 32);\n                            int64_t binop_y_14956 = (int64_t) 32 * new_index_14955;\n                            int64_t binop_x_14957 = binop_x_14954 - binop_y_14956;\n                            int64_t new_index_14958 = squot64(binop_x_14957, (int64_t) 16);\n                            int64_t binop_y_14959 = (int64_t) 16 * new_index_14958;\n                            int64_t new_index_14960 = binop_x_14957 - binop_y_14959;\n                            int8_t defunc_0_f_res_14961 = ((__global int8_t *) mem_18292)[new_index_14949 * (int64_t) 1024 + new_index_14952 * (int64_t) 64 + new_index_14955 * (int64_t) 32 + new_index_14958 * (int64_t) 16 + new_index_14960];\n                            int64_t u8_res_14962 = zext_i8_i64(defunc_0_f_res_14961);\n                            bool x_14963 = sle64((int64_t) 0, u8_res_14962);\n                            bool y_14964 = slt64(u8_res_14962, (int64_t) 16);\n                            bool bounds_check_14965 = x_14963 && y_14964;\n                            bool index_ok_14966 = bounds_check_14900 && bounds_check_14965;\n                            bool index_certs_14967;\n                            \n                            if (!index_ok_14966) {\n                                {\n                                    if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                                        global_failure_args[0] = (int64_t) index_primexp_18039;\n                                        global_failure_args[1] = (int64_t) u8_res_14962;\n                                        global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                        global_failure_args[3] = (int64_t) (int64_t) 16;\n                                        ;\n                                    }\n                                    local_failure = 1;\n                           ",
                                     "         goto error_0;\n                                }\n                            }\n                            \n                            int64_t binop_x_14968 = binop_x_14901 + u8_res_14962;\n                            int64_t new_index_14969 = squot64(binop_x_14968, (int64_t) 1024);\n                            int64_t binop_y_14970 = (int64_t) 1024 * new_index_14969;\n                            int64_t binop_x_14971 = binop_x_14968 - binop_y_14970;\n                            int64_t new_index_14972 = squot64(binop_x_14971, (int64_t) 64);\n                            int64_t binop_y_14973 = (int64_t) 64 * new_index_14972;\n                            int64_t binop_x_14974 = binop_x_14971 - binop_y_14973;\n                            int64_t new_index_14975 = squot64(binop_x_14974, (int64_t) 32);\n                            int64_t binop_y_14976 = (int64_t) 32 * new_index_14975;\n                            int64_t binop_x_14977 = binop_x_14974 - binop_y_14976;\n                            int64_t new_index_14978 = squot64(binop_x_14977, (int64_t) 16);\n                            int64_t binop_y_14979 = (int64_t) 16 * new_index_14978;\n                            int64_t new_index_14980 = binop_x_14977 - binop_y_14979;\n                            int8_t defunc_0_f_res_14981 = ((__global int8_t *) mem_18292)[new_index_14969 * (int64_t) 1024 + new_index_14972 * (int64_t) 64 + new_index_14975 * (int64_t) 32 + new_index_14978 * (int64_t) 16 + new_index_14980];\n                            int64_t u8_res_14982 = zext_i8_i64(defunc_0_f_res_14981);\n                            bool x_14983 = sle64((int64_t) 0, u8_res_14982);\n                            bool y_14984 = slt64(u8_res_14982, (int64_t) 16);\n                            bool bounds_check_14985 = x_14983 && y_14984;\n                            bool index_ok_14986 = bounds_check_14892 && bounds_check_14985;\n                            bool index_certs_14987;\n                            \n                            if", " (!index_ok_14986) {\n                                {\n                                    if (atomic_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                                        global_failure_args[0] = (int64_t) defunc_0_f_res_14888;\n                                        global_failure_args[1] = (int64_t) u8_res_14982;\n                                        global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                        global_failure_args[3] = (int64_t) (int64_t) 16;\n                                        ;\n                                    }\n                                    local_failure = 1;\n                                    goto error_0;\n                                }\n                            }\n                            \n                            int64_t binop_x_14988 = binop_x_14893 + u8_res_14982;\n                            int64_t new_index_14989 = squot64(binop_x_14988, (int64_t) 1024);\n                            int64_t binop_y_14990 = (int64_t) 1024 * new_index_14989;\n                            int64_t binop_x_14991 = binop_x_14988 - binop_y_14990;\n                            int64_t new_index_14992 = squot64(binop_x_14991, (int64_t) 64);\n                            int64_t binop_y_14993 = (int64_t) 64 * new_index_14992;\n                            int64_t binop_x_14994 = binop_x_14991 - binop_y_14993;\n                            int64_t new_index_14995 = squot64(binop_x_14994, (int64_t) 32);\n                            int64_t binop_y_14996 = (int64_t) 32 * new_index_14995;\n                            int64_t binop_x_14997 = binop_x_14994 - binop_y_14996;\n                            int64_t new_index_14998 = squot64(binop_x_14997, (int64_t) 16);\n                            int64_t binop_y_14999 = (int64_t) 16 * new_index_14998;\n                            int64_t new_index_15000 = binop_x_14997 - binop_y_14999;\n                            int8_t defunc_0_f_res_15001 = ((__global int8_t *) ", "mem_18292)[new_index_14989 * (int64_t) 1024 + new_index_14992 * (int64_t) 64 + new_index_14995 * (int64_t) 32 + new_index_14998 * (int64_t) 16 + new_index_15000];\n                            bool binlam_res_15002 = defunc_0_f_res_15001 == x_14921;\n                            bool binlam_res_14920 = binlam_res_15002 && redout_18006;\n                            bool redout_tmp_18883 = binlam_res_14920;\n                            \n                            redout_18006 = redout_tmp_18883;\n                        }\n                        all_equal_14917 = redout_18006;\n                        \n                        int16_t i64_res_15003 = sext_i64_i16(index_primexp_18037);\n                        \n                        mem_18501[(int64_t) 0] = i64_res_14889;\n                        mem_18501[(int64_t) 1] = i64_res_14897;\n                        mem_18501[(int64_t) 2] = i64_res_14905;\n                        mem_18501[(int64_t) 3] = i64_res_15003;\n                        mem_18487[i_17989 * (int64_t) 16384 + i_17996 * (int64_t) 128 + i_18003] = all_equal_14917;\n                        for (int64_t i_18884 = 0; i_18884 < (int64_t) 4; i_18884++) {\n                            int16_t tmp_18885 = mem_18501[i_18884];\n                            \n                            mem_18488[i_17989 * (int64_t) 65536 + i_17996 * (int64_t) 512 + i_18003 * (int64_t) 4 + i_18884] = tmp_18885;\n                        }\n                    }\n                }\n            }\n            for (int64_t i_18886 = 0; i_18886 < (int64_t) 128; i_18886++) {\n                for (int64_t i_18887 = 0; i_18887 < (int64_t) 128; i_18887++) {\n                    for (int64_t i_18888 = 0; i_18888 < (int64_t) 128; i_18888++) {\n                        bool tmp_18889 = mem_18487[i_18886 * (int64_t) 16384 + i_18887 * (int64_t) 128 + i_18888];\n                        \n                        ((__global bool *) mem_18518)[gtid_14885 + (i_18886 * (int64_t) 2097152 + i_18887 * (int64_t) 16384 + i_18888 * (i",
                                     "nt64_t) 128)] = tmp_18889;\n                    }\n                }\n            }\n            for (int64_t i_18890 = 0; i_18890 < (int64_t) 128; i_18890++) {\n                for (int64_t i_18891 = 0; i_18891 < (int64_t) 128; i_18891++) {\n                    for (int64_t i_18892 = 0; i_18892 < (int64_t) 128; i_18892++) {\n                        for (int64_t i_18893 = 0; i_18893 < (int64_t) 4; i_18893++) {\n                            int16_t tmp_18894 = mem_18488[i_18890 * (int64_t) 65536 + i_18891 * (int64_t) 512 + i_18892 * (int64_t) 4 + i_18893];\n                            \n                            ((__global int16_t *) mem_18519)[gtid_14885 + (i_18890 * (int64_t) 8388608 + i_18891 * (int64_t) 65536 + i_18892 * (int64_t) 512 + i_18893 * (int64_t) 128)] = tmp_18894;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_14880\n}\n__kernel void segmap_16611(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_12396, int64_t arg_12814, int64_t arg_12818, int64_t num_groups_16600, int32_t virt_num_groups_18895, __global unsigned char *mem_18283, __global unsigned char *mem_18292, __global unsigned char *mem_18394, __global unsigned char *mem_18476, __global unsigned char *mem_18477)\n{\n    #define segmap_group_sizze_16599 (segmap_group_sizze_15014)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_18897;\n    int64_t group_sizze_18900;\n    int32_t wave_sizze_18899;\n    int32_t group_tid_18898;\n    \n    local_tid_18897 = get_local_id(0);\n    group_sizze_18900 = g", "et_local_size(0);\n    wave_sizze_18899 = LOCKSTEP_WIDTH;\n    group_tid_18898 = get_group_id(0);\n    \n    int32_t global_tid_18896 = group_tid_18898 * group_sizze_18900 + local_tid_18897;\n    int32_t phys_tid_16611 = global_tid_18896;\n    int32_t phys_group_id_18901;\n    \n    phys_group_id_18901 = get_group_id(0);\n    \n    int32_t iterations_18902 = sdiv_up32(virt_num_groups_18895 - phys_group_id_18901, sext_i64_i32(num_groups_16600));\n    \n    for (int32_t i_18903 = 0; i_18903 < iterations_18902; i_18903++) {\n        int32_t virt_group_id_18904 = phys_group_id_18901 + i_18903 * sext_i64_i32(num_groups_16600);\n        int64_t global_tid_18905 = sext_i32_i64(virt_group_id_18904) * segmap_group_sizze_16599 + sext_i32_i64(local_tid_18897);\n        int64_t slice_18906 = (int64_t) 128;\n        int64_t slice_18907 = (int64_t) 128 * slice_18906;\n        int64_t gtid_16609 = squot64(global_tid_18905, slice_18906);\n        int64_t remnant_18908 = global_tid_18905 - gtid_16609 * slice_18906;\n        int64_t gtid_16610 = remnant_18908;\n        int64_t remnant_18909 = remnant_18908 - gtid_16610;\n        \n        if (slt64(gtid_16609, (int64_t) 128) && slt64(gtid_16610, (int64_t) 128)) {\n            int64_t arg_18101 = ((__global int64_t *) mem_18394)[(int64_t) 0];\n            int64_t index_primexp_17257 = add64(arg_12396, gtid_16609);\n            int16_t index_primexp_17254 = sext_i64_i16(index_primexp_17257);\n            bool binop_x_17245 = sle64((int64_t) 0, index_primexp_17257);\n            bool binop_y_17249 = slt64(index_primexp_17257, (int64_t) 1024);\n            bool index_primexp_17250 = binop_x_17245 && binop_y_17249;\n            int64_t index_primexp_17241 = (int64_t) 16 * index_primexp_17257;\n            int64_t index_primexp_17237 = add64(arg_12814, gtid_16610);\n            int16_t i64_res_16617 = sext_i64_i16(index_primexp_17237);\n            bool x_16618 = sle64((int64_t) 0, index_primexp_17237);\n            bool y_16619 = slt64(index_primexp_17237, (int64_t) 1024", ");\n            bool bounds_check_16620 = x_16618 && y_16619;\n            int64_t binop_x_16621 = (int64_t) 16 * index_primexp_17237;\n            bool mem_18459[(int64_t) 128 * (int64_t) 128];\n            int16_t mem_18460[(int64_t) 128 * (int64_t) 128 * (int64_t) 4];\n            int16_t mem_18467[(int64_t) 4];\n            \n            for (int64_t i_18012 = 0; i_18012 < (int64_t) 128; i_18012++) {\n                int64_t index_primexp_18041 = add64(arg_12818, i_18012);\n                int16_t i64_res_16625 = sext_i64_i16(index_primexp_18041);\n                bool x_16626 = sle64((int64_t) 0, index_primexp_18041);\n                bool y_16627 = slt64(index_primexp_18041, (int64_t) 1024);\n                bool bounds_check_16628 = x_16626 && y_16627;\n                int64_t binop_x_16629 = (int64_t) 16 * index_primexp_18041;\n                \n                for (int64_t i_18019 = 0; i_18019 < (int64_t) 128; i_18019++) {\n                    int64_t index_primexp_18040 = add64(i_18019, arg_18101);\n                    bool x_16633 = sle64((int64_t) 0, index_primexp_18040);\n                    bool y_16634 = slt64(index_primexp_18040, (int64_t) 1024);\n                    bool bounds_check_16635 = x_16633 && y_16634;\n                    int64_t binop_x_16636 = (int64_t) 16 * index_primexp_18040;\n                    bool all_equal_16637;\n                    bool redout_18022 = 1;\n                    \n                    for (int64_t i_18023 = 0; i_18023 < (int64_t) 16; i_18023++) {\n                        int8_t x_16641 = ((__global int8_t *) mem_18283)[i_18023];\n                        int64_t u8_res_16642 = zext_i8_i64(x_16641);\n                        bool x_16643 = sle64((int64_t) 0, u8_res_16642);\n                        bool y_16644 = slt64(u8_res_16642, (int64_t) 16);\n                        bool bounds_check_16645 = x_16643 && y_16644;\n                        bool index_ok_16646 = bounds_check_16635 && bounds_check_16645;\n                        bool index_certs_1664",
                                     "7;\n                        \n                        if (!index_ok_16646) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                                    global_failure_args[0] = (int64_t) index_primexp_18040;\n                                    global_failure_args[1] = (int64_t) u8_res_16642;\n                                    global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                    global_failure_args[3] = (int64_t) (int64_t) 16;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        int64_t binop_x_16648 = binop_x_16636 + u8_res_16642;\n                        int64_t new_index_16649 = squot64(binop_x_16648, (int64_t) 1024);\n                        int64_t binop_y_16650 = (int64_t) 1024 * new_index_16649;\n                        int64_t binop_x_16651 = binop_x_16648 - binop_y_16650;\n                        int64_t new_index_16652 = squot64(binop_x_16651, (int64_t) 64);\n                        int64_t binop_y_16653 = (int64_t) 64 * new_index_16652;\n                        int64_t binop_x_16654 = binop_x_16651 - binop_y_16653;\n                        int64_t new_index_16655 = squot64(binop_x_16654, (int64_t) 32);\n                        int64_t binop_y_16656 = (int64_t) 32 * new_index_16655;\n                        int64_t binop_x_16657 = binop_x_16654 - binop_y_16656;\n                        int64_t new_index_16658 = squot64(binop_x_16657, (int64_t) 16);\n                        int64_t binop_y_16659 = (int64_t) 16 * new_index_16658;\n                        int64_t new_index_16660 = binop_x_16657 - binop_y_16659;\n                        int8_t defunc_0_f_res_16661 = ((__global int8_t *) mem_18292)[new_index_16649 * (int64_t) 1024 + new_index", "_16652 * (int64_t) 64 + new_index_16655 * (int64_t) 32 + new_index_16658 * (int64_t) 16 + new_index_16660];\n                        int64_t u8_res_16662 = zext_i8_i64(defunc_0_f_res_16661);\n                        bool x_16663 = sle64((int64_t) 0, u8_res_16662);\n                        bool y_16664 = slt64(u8_res_16662, (int64_t) 16);\n                        bool bounds_check_16665 = x_16663 && y_16664;\n                        bool index_ok_16666 = bounds_check_16628 && bounds_check_16665;\n                        bool index_certs_16667;\n                        \n                        if (!index_ok_16666) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 5) == -1) {\n                                    global_failure_args[0] = (int64_t) index_primexp_18041;\n                                    global_failure_args[1] = (int64_t) u8_res_16662;\n                                    global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                    global_failure_args[3] = (int64_t) (int64_t) 16;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        int64_t binop_x_16668 = binop_x_16629 + u8_res_16662;\n                        int64_t new_index_16669 = squot64(binop_x_16668, (int64_t) 1024);\n                        int64_t binop_y_16670 = (int64_t) 1024 * new_index_16669;\n                        int64_t binop_x_16671 = binop_x_16668 - binop_y_16670;\n                        int64_t new_index_16672 = squot64(binop_x_16671, (int64_t) 64);\n                        int64_t binop_y_16673 = (int64_t) 64 * new_index_16672;\n                        int64_t binop_x_16674 = binop_x_16671 - binop_y_16673;\n                        int64_t new_index_16675 = squot64(binop_x_16674, (int64_t) 32)", ";\n                        int64_t binop_y_16676 = (int64_t) 32 * new_index_16675;\n                        int64_t binop_x_16677 = binop_x_16674 - binop_y_16676;\n                        int64_t new_index_16678 = squot64(binop_x_16677, (int64_t) 16);\n                        int64_t binop_y_16679 = (int64_t) 16 * new_index_16678;\n                        int64_t new_index_16680 = binop_x_16677 - binop_y_16679;\n                        int8_t defunc_0_f_res_16681 = ((__global int8_t *) mem_18292)[new_index_16669 * (int64_t) 1024 + new_index_16672 * (int64_t) 64 + new_index_16675 * (int64_t) 32 + new_index_16678 * (int64_t) 16 + new_index_16680];\n                        int64_t u8_res_16682 = zext_i8_i64(defunc_0_f_res_16681);\n                        bool x_16683 = sle64((int64_t) 0, u8_res_16682);\n                        bool y_16684 = slt64(u8_res_16682, (int64_t) 16);\n                        bool bounds_check_16685 = x_16683 && y_16684;\n                        bool index_ok_16686 = bounds_check_16620 && bounds_check_16685;\n                        bool index_certs_16687;\n                        \n                        if (!index_ok_16686) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                                    global_failure_args[0] = (int64_t) index_primexp_17237;\n                                    global_failure_args[1] = (int64_t) u8_res_16682;\n                                    global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                    global_failure_args[3] = (int64_t) (int64_t) 16;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        int64_t binop_x_16688 = binop_x_16621 + u8_res_16682;\n                        int64_t new_index_16",
                                     "689 = squot64(binop_x_16688, (int64_t) 1024);\n                        int64_t binop_y_16690 = (int64_t) 1024 * new_index_16689;\n                        int64_t binop_x_16691 = binop_x_16688 - binop_y_16690;\n                        int64_t new_index_16692 = squot64(binop_x_16691, (int64_t) 64);\n                        int64_t binop_y_16693 = (int64_t) 64 * new_index_16692;\n                        int64_t binop_x_16694 = binop_x_16691 - binop_y_16693;\n                        int64_t new_index_16695 = squot64(binop_x_16694, (int64_t) 32);\n                        int64_t binop_y_16696 = (int64_t) 32 * new_index_16695;\n                        int64_t binop_x_16697 = binop_x_16694 - binop_y_16696;\n                        int64_t new_index_16698 = squot64(binop_x_16697, (int64_t) 16);\n                        int64_t binop_y_16699 = (int64_t) 16 * new_index_16698;\n                        int64_t new_index_16700 = binop_x_16697 - binop_y_16699;\n                        int8_t defunc_0_f_res_16701 = ((__global int8_t *) mem_18292)[new_index_16689 * (int64_t) 1024 + new_index_16692 * (int64_t) 64 + new_index_16695 * (int64_t) 32 + new_index_16698 * (int64_t) 16 + new_index_16700];\n                        int64_t u8_res_16702 = zext_i8_i64(defunc_0_f_res_16701);\n                        bool x_16703 = sle64((int64_t) 0, u8_res_16702);\n                        bool y_16704 = slt64(u8_res_16702, (int64_t) 16);\n                        bool bounds_check_16705 = x_16703 && y_16704;\n                        bool index_ok_16706 = bounds_check_16705 && index_primexp_17250;\n                        bool index_certs_16707;\n                        \n                        if (!index_ok_16706) {\n                            {\n                                if (atomic_cmpxchg_i32_global(global_failure, -1, 7) == -1) {\n                                    global_failure_args[0] = (int64_t) index_primexp_17257;\n                                    global_failure_args[1] = (int64_t) u8_res_16702;\n   ", "                                 global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                    global_failure_args[3] = (int64_t) (int64_t) 16;\n                                    ;\n                                }\n                                local_failure = 1;\n                                goto error_0;\n                            }\n                        }\n                        \n                        int64_t binop_x_16708 = u8_res_16702 + index_primexp_17241;\n                        int64_t new_index_16709 = squot64(binop_x_16708, (int64_t) 1024);\n                        int64_t binop_y_16710 = (int64_t) 1024 * new_index_16709;\n                        int64_t binop_x_16711 = binop_x_16708 - binop_y_16710;\n                        int64_t new_index_16712 = squot64(binop_x_16711, (int64_t) 64);\n                        int64_t binop_y_16713 = (int64_t) 64 * new_index_16712;\n                        int64_t binop_x_16714 = binop_x_16711 - binop_y_16713;\n                        int64_t new_index_16715 = squot64(binop_x_16714, (int64_t) 32);\n                        int64_t binop_y_16716 = (int64_t) 32 * new_index_16715;\n                        int64_t binop_x_16717 = binop_x_16714 - binop_y_16716;\n                        int64_t new_index_16718 = squot64(binop_x_16717, (int64_t) 16);\n                        int64_t binop_y_16719 = (int64_t) 16 * new_index_16718;\n                        int64_t new_index_16720 = binop_x_16717 - binop_y_16719;\n                        int8_t defunc_0_f_res_16721 = ((__global int8_t *) mem_18292)[new_index_16709 * (int64_t) 1024 + new_index_16712 * (int64_t) 64 + new_index_16715 * (int64_t) 32 + new_index_16718 * (int64_t) 16 + new_index_16720];\n                        bool binlam_res_16722 = defunc_0_f_res_16721 == x_16641;\n                        bool binlam_res_16640 = binlam_res_16722 && redout_18022;\n                        bool redout_tmp_18914 = binlam_res_16640;\n                        \n           ", "             redout_18022 = redout_tmp_18914;\n                    }\n                    all_equal_16637 = redout_18022;\n                    \n                    int16_t i64_res_16723 = sext_i64_i16(index_primexp_18040);\n                    \n                    mem_18467[(int64_t) 0] = index_primexp_17254;\n                    mem_18467[(int64_t) 1] = i64_res_16617;\n                    mem_18467[(int64_t) 2] = i64_res_16625;\n                    mem_18467[(int64_t) 3] = i64_res_16723;\n                    mem_18459[i_18012 * (int64_t) 128 + i_18019] = all_equal_16637;\n                    for (int64_t i_18915 = 0; i_18915 < (int64_t) 4; i_18915++) {\n                        int16_t tmp_18916 = mem_18467[i_18915];\n                        \n                        mem_18460[i_18012 * (int64_t) 512 + i_18019 * (int64_t) 4 + i_18915] = tmp_18916;\n                    }\n                }\n            }\n            for (int64_t i_18917 = 0; i_18917 < (int64_t) 128; i_18917++) {\n                for (int64_t i_18918 = 0; i_18918 < (int64_t) 128; i_18918++) {\n                    bool tmp_18919 = mem_18459[i_18917 * (int64_t) 128 + i_18918];\n                    \n                    ((__global bool *) mem_18476)[gtid_16609 * (int64_t) 128 + gtid_16610 + (i_18917 * (int64_t) 2097152 + i_18918 * (int64_t) 16384)] = tmp_18919;\n                }\n            }\n            for (int64_t i_18920 = 0; i_18920 < (int64_t) 128; i_18920++) {\n                for (int64_t i_18921 = 0; i_18921 < (int64_t) 128; i_18921++) {\n                    for (int64_t i_18922 = 0; i_18922 < (int64_t) 4; i_18922++) {\n                        int16_t tmp_18923 = mem_18460[i_18920 * (int64_t) 512 + i_18921 * (int64_t) 4 + i_18922];\n                        \n                        ((__global int16_t *) mem_18477)[gtid_16609 * (int64_t) 128 + gtid_16610 + (i_18920 * (int64_t) 8388608 + i_18921 * (int64_t) 65536 + i_18922 * (int64_t) 16384)] = tmp_18923;\n                    }\n                }\n            }\n        }\n  ",
                                     "      barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16599\n}\n__kernel void segmap_16758(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t arg_12396, int64_t arg_12814, int64_t arg_12818, int64_t num_groups_16745, int32_t virt_num_groups_18924, __global unsigned char *mem_18283, __global unsigned char *mem_18292, __global unsigned char *mem_18394, __global unsigned char *mem_18448, __global unsigned char *mem_18449)\n{\n    #define segmap_group_sizze_16744 (segmap_group_sizze_15153)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_18926;\n    int64_t group_sizze_18929;\n    int32_t wave_sizze_18928;\n    int32_t group_tid_18927;\n    \n    local_tid_18926 = get_local_id(0);\n    group_sizze_18929 = get_local_size(0);\n    wave_sizze_18928 = LOCKSTEP_WIDTH;\n    group_tid_18927 = get_group_id(0);\n    \n    int32_t global_tid_18925 = group_tid_18927 * group_sizze_18929 + local_tid_18926;\n    int32_t phys_tid_16758 = global_tid_18925;\n    int32_t phys_group_id_18930;\n    \n    phys_group_id_18930 = get_group_id(0);\n    \n    int32_t iterations_18931 = sdiv_up32(virt_num_groups_18924 - phys_group_id_18930, sext_i64_i32(num_groups_16745));\n    \n    for (int32_t i_18932 = 0; i_18932 < iterations_18931; i_18932++) {\n        int32_t virt_group_id_18933 = phys_group_id_18930 + i_18932 * sext_i64_i32(num_groups_16745);\n        int64_t global_tid_18934 = sext_i32_i64(virt_group_id_18933) * segmap_group_sizze_16744 + sext_i32_i64(local_tid_18926);\n        int64_t slice_18935 = (int64_t) 128;\n        int64_t slice_18936 = (int64_t) 128 * slice_18935;\n        int64_t slice_", "18937 = (int64_t) 128 * slice_18936;\n        int64_t gtid_16755 = squot64(global_tid_18934, slice_18936);\n        int64_t remnant_18938 = global_tid_18934 - gtid_16755 * slice_18936;\n        int64_t gtid_16756 = squot64(remnant_18938, slice_18935);\n        int64_t remnant_18939 = remnant_18938 - gtid_16756 * slice_18935;\n        int64_t gtid_16757 = remnant_18939;\n        int64_t remnant_18940 = remnant_18939 - gtid_16757;\n        \n        if ((slt64(gtid_16755, (int64_t) 128) && slt64(gtid_16756, (int64_t) 128)) && slt64(gtid_16757, (int64_t) 128)) {\n            int64_t arg_18102 = ((__global int64_t *) mem_18394)[(int64_t) 0];\n            int64_t index_primexp_17283 = add64(arg_12396, gtid_16755);\n            int16_t index_primexp_17280 = sext_i64_i16(index_primexp_17283);\n            bool binop_x_17271 = sle64((int64_t) 0, index_primexp_17283);\n            bool binop_y_17275 = slt64(index_primexp_17283, (int64_t) 1024);\n            bool index_primexp_17276 = binop_x_17271 && binop_y_17275;\n            int64_t index_primexp_17267 = (int64_t) 16 * index_primexp_17283;\n            int64_t index_primexp_17263 = add64(arg_12814, gtid_16756);\n            int16_t index_primexp_17376 = sext_i64_i16(index_primexp_17263);\n            bool binop_x_17367 = sle64((int64_t) 0, index_primexp_17263);\n            bool binop_y_17371 = slt64(index_primexp_17263, (int64_t) 1024);\n            bool index_primexp_17372 = binop_x_17367 && binop_y_17371;\n            int64_t index_primexp_17363 = (int64_t) 16 * index_primexp_17263;\n            int64_t index_primexp_17260 = add64(arg_12818, gtid_16757);\n            int16_t i64_res_16768 = sext_i64_i16(index_primexp_17260);\n            bool x_16769 = sle64((int64_t) 0, index_primexp_17260);\n            bool y_16770 = slt64(index_primexp_17260, (int64_t) 1024);\n            bool bounds_check_16771 = x_16769 && y_16770;\n            int64_t binop_x_16772 = (int64_t) 16 * index_primexp_17260;\n            bool mem_18441[(int64_t) 128];\n          ", "  int16_t mem_18442[(int64_t) 128 * (int64_t) 4];\n            int16_t mem_18445[(int64_t) 4];\n            \n            for (int64_t i_18028 = 0; i_18028 < (int64_t) 128; i_18028++) {\n                int64_t index_primexp_18042 = add64(i_18028, arg_18102);\n                bool x_16776 = sle64((int64_t) 0, index_primexp_18042);\n                bool y_16777 = slt64(index_primexp_18042, (int64_t) 1024);\n                bool bounds_check_16778 = x_16776 && y_16777;\n                int64_t binop_x_16779 = (int64_t) 16 * index_primexp_18042;\n                bool all_equal_16780;\n                bool redout_18031 = 1;\n                \n                for (int64_t i_18032 = 0; i_18032 < (int64_t) 16; i_18032++) {\n                    int8_t x_16784 = ((__global int8_t *) mem_18283)[i_18032];\n                    int64_t u8_res_16785 = zext_i8_i64(x_16784);\n                    bool x_16786 = sle64((int64_t) 0, u8_res_16785);\n                    bool y_16787 = slt64(u8_res_16785, (int64_t) 16);\n                    bool bounds_check_16788 = x_16786 && y_16787;\n                    bool index_ok_16789 = bounds_check_16778 && bounds_check_16788;\n                    bool index_certs_16790;\n                    \n                    if (!index_ok_16789) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 8) == -1) {\n                                global_failure_args[0] = (int64_t) index_primexp_18042;\n                                global_failure_args[1] = (int64_t) u8_res_16785;\n                                global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                global_failure_args[3] = (int64_t) (int64_t) 16;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int64_t binop_x_16791 = binop_x_16779 + u8_res_16785;\n",
                                     "                    int64_t new_index_16792 = squot64(binop_x_16791, (int64_t) 1024);\n                    int64_t binop_y_16793 = (int64_t) 1024 * new_index_16792;\n                    int64_t binop_x_16794 = binop_x_16791 - binop_y_16793;\n                    int64_t new_index_16795 = squot64(binop_x_16794, (int64_t) 64);\n                    int64_t binop_y_16796 = (int64_t) 64 * new_index_16795;\n                    int64_t binop_x_16797 = binop_x_16794 - binop_y_16796;\n                    int64_t new_index_16798 = squot64(binop_x_16797, (int64_t) 32);\n                    int64_t binop_y_16799 = (int64_t) 32 * new_index_16798;\n                    int64_t binop_x_16800 = binop_x_16797 - binop_y_16799;\n                    int64_t new_index_16801 = squot64(binop_x_16800, (int64_t) 16);\n                    int64_t binop_y_16802 = (int64_t) 16 * new_index_16801;\n                    int64_t new_index_16803 = binop_x_16800 - binop_y_16802;\n                    int8_t defunc_0_f_res_16804 = ((__global int8_t *) mem_18292)[new_index_16792 * (int64_t) 1024 + new_index_16795 * (int64_t) 64 + new_index_16798 * (int64_t) 32 + new_index_16801 * (int64_t) 16 + new_index_16803];\n                    int64_t u8_res_16805 = zext_i8_i64(defunc_0_f_res_16804);\n                    bool x_16806 = sle64((int64_t) 0, u8_res_16805);\n                    bool y_16807 = slt64(u8_res_16805, (int64_t) 16);\n                    bool bounds_check_16808 = x_16806 && y_16807;\n                    bool index_ok_16809 = bounds_check_16771 && bounds_check_16808;\n                    bool index_certs_16810;\n                    \n                    if (!index_ok_16809) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 9) == -1) {\n                                global_failure_args[0] = (int64_t) index_primexp_17260;\n                                global_failure_args[1] = (int64_t) u8_res_16805;\n                                global_failure_args[2] = (in", "t64_t) (int64_t) 1024;\n                                global_failure_args[3] = (int64_t) (int64_t) 16;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int64_t binop_x_16811 = binop_x_16772 + u8_res_16805;\n                    int64_t new_index_16812 = squot64(binop_x_16811, (int64_t) 1024);\n                    int64_t binop_y_16813 = (int64_t) 1024 * new_index_16812;\n                    int64_t binop_x_16814 = binop_x_16811 - binop_y_16813;\n                    int64_t new_index_16815 = squot64(binop_x_16814, (int64_t) 64);\n                    int64_t binop_y_16816 = (int64_t) 64 * new_index_16815;\n                    int64_t binop_x_16817 = binop_x_16814 - binop_y_16816;\n                    int64_t new_index_16818 = squot64(binop_x_16817, (int64_t) 32);\n                    int64_t binop_y_16819 = (int64_t) 32 * new_index_16818;\n                    int64_t binop_x_16820 = binop_x_16817 - binop_y_16819;\n                    int64_t new_index_16821 = squot64(binop_x_16820, (int64_t) 16);\n                    int64_t binop_y_16822 = (int64_t) 16 * new_index_16821;\n                    int64_t new_index_16823 = binop_x_16820 - binop_y_16822;\n                    int8_t defunc_0_f_res_16824 = ((__global int8_t *) mem_18292)[new_index_16812 * (int64_t) 1024 + new_index_16815 * (int64_t) 64 + new_index_16818 * (int64_t) 32 + new_index_16821 * (int64_t) 16 + new_index_16823];\n                    int64_t u8_res_16825 = zext_i8_i64(defunc_0_f_res_16824);\n                    bool x_16826 = sle64((int64_t) 0, u8_res_16825);\n                    bool y_16827 = slt64(u8_res_16825, (int64_t) 16);\n                    bool bounds_check_16828 = x_16826 && y_16827;\n                    bool index_ok_16829 = bounds_check_16828 && index_primexp_17372;\n                    bool index_certs_16830;\n        ", "            \n                    if (!index_ok_16829) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 10) == -1) {\n                                global_failure_args[0] = (int64_t) index_primexp_17263;\n                                global_failure_args[1] = (int64_t) u8_res_16825;\n                                global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                global_failure_args[3] = (int64_t) (int64_t) 16;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int64_t binop_x_16831 = u8_res_16825 + index_primexp_17363;\n                    int64_t new_index_16832 = squot64(binop_x_16831, (int64_t) 1024);\n                    int64_t binop_y_16833 = (int64_t) 1024 * new_index_16832;\n                    int64_t binop_x_16834 = binop_x_16831 - binop_y_16833;\n                    int64_t new_index_16835 = squot64(binop_x_16834, (int64_t) 64);\n                    int64_t binop_y_16836 = (int64_t) 64 * new_index_16835;\n                    int64_t binop_x_16837 = binop_x_16834 - binop_y_16836;\n                    int64_t new_index_16838 = squot64(binop_x_16837, (int64_t) 32);\n                    int64_t binop_y_16839 = (int64_t) 32 * new_index_16838;\n                    int64_t binop_x_16840 = binop_x_16837 - binop_y_16839;\n                    int64_t new_index_16841 = squot64(binop_x_16840, (int64_t) 16);\n                    int64_t binop_y_16842 = (int64_t) 16 * new_index_16841;\n                    int64_t new_index_16843 = binop_x_16840 - binop_y_16842;\n                    int8_t defunc_0_f_res_16844 = ((__global int8_t *) mem_18292)[new_index_16832 * (int64_t) 1024 + new_index_16835 * (int64_t) 64 + new_index_16838 * (int64_t) 32 + new_index_16841 * (int64_t) 16 + new_index_16843];\n            ",
                                     "        int64_t u8_res_16845 = zext_i8_i64(defunc_0_f_res_16844);\n                    bool x_16846 = sle64((int64_t) 0, u8_res_16845);\n                    bool y_16847 = slt64(u8_res_16845, (int64_t) 16);\n                    bool bounds_check_16848 = x_16846 && y_16847;\n                    bool index_ok_16849 = bounds_check_16848 && index_primexp_17276;\n                    bool index_certs_16850;\n                    \n                    if (!index_ok_16849) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 11) == -1) {\n                                global_failure_args[0] = (int64_t) index_primexp_17283;\n                                global_failure_args[1] = (int64_t) u8_res_16845;\n                                global_failure_args[2] = (int64_t) (int64_t) 1024;\n                                global_failure_args[3] = (int64_t) (int64_t) 16;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int64_t binop_x_16851 = u8_res_16845 + index_primexp_17267;\n                    int64_t new_index_16852 = squot64(binop_x_16851, (int64_t) 1024);\n                    int64_t binop_y_16853 = (int64_t) 1024 * new_index_16852;\n                    int64_t binop_x_16854 = binop_x_16851 - binop_y_16853;\n                    int64_t new_index_16855 = squot64(binop_x_16854, (int64_t) 64);\n                    int64_t binop_y_16856 = (int64_t) 64 * new_index_16855;\n                    int64_t binop_x_16857 = binop_x_16854 - binop_y_16856;\n                    int64_t new_index_16858 = squot64(binop_x_16857, (int64_t) 32);\n                    int64_t binop_y_16859 = (int64_t) 32 * new_index_16858;\n                    int64_t binop_x_16860 = binop_x_16857 - binop_y_16859;\n                    int64_t new_index_16861 = squot64(binop_x_16860, (int64", "_t) 16);\n                    int64_t binop_y_16862 = (int64_t) 16 * new_index_16861;\n                    int64_t new_index_16863 = binop_x_16860 - binop_y_16862;\n                    int8_t defunc_0_f_res_16864 = ((__global int8_t *) mem_18292)[new_index_16852 * (int64_t) 1024 + new_index_16855 * (int64_t) 64 + new_index_16858 * (int64_t) 32 + new_index_16861 * (int64_t) 16 + new_index_16863];\n                    bool binlam_res_16865 = defunc_0_f_res_16864 == x_16784;\n                    bool binlam_res_16783 = binlam_res_16865 && redout_18031;\n                    bool redout_tmp_18943 = binlam_res_16783;\n                    \n                    redout_18031 = redout_tmp_18943;\n                }\n                all_equal_16780 = redout_18031;\n                \n                int16_t i64_res_16866 = sext_i64_i16(index_primexp_18042);\n                \n                mem_18445[(int64_t) 0] = index_primexp_17280;\n                mem_18445[(int64_t) 1] = index_primexp_17376;\n                mem_18445[(int64_t) 2] = i64_res_16768;\n                mem_18445[(int64_t) 3] = i64_res_16866;\n                mem_18441[i_18028] = all_equal_16780;\n                for (int64_t i_18944 = 0; i_18944 < (int64_t) 4; i_18944++) {\n                    int16_t tmp_18945 = mem_18445[i_18944];\n                    \n                    mem_18442[i_18028 * (int64_t) 4 + i_18944] = tmp_18945;\n                }\n            }\n            for (int64_t i_18946 = 0; i_18946 < (int64_t) 128; i_18946++) {\n                bool tmp_18947 = mem_18441[i_18946];\n                \n                ((__global bool *) mem_18448)[gtid_16755 * (int64_t) 16384 + gtid_16756 * (int64_t) 128 + gtid_16757 + i_18946 * (int64_t) 2097152] = tmp_18947;\n            }\n            for (int64_t i_18948 = 0; i_18948 < (int64_t) 128; i_18948++) {\n                for (int64_t i_18949 = 0; i_18949 < (int64_t) 4; i_18949++) {\n                    int16_t tmp_18950 = mem_18442[i_18948 * (int64_t) 4 + i_18949];\n                    \n ", "                   ((__global int16_t *) mem_18449)[gtid_16755 * (int64_t) 16384 + gtid_16756 * (int64_t) 128 + gtid_16757 + (i_18948 * (int64_t) 8388608 + i_18949 * (int64_t) 2097152)] = tmp_18950;\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_16744\n}\n__kernel void segmap_17166(__global int *global_failure, int64_t arg_12396, int64_t arg_12814, int64_t arg_12818, int64_t num_groups_17159, int32_t virt_num_groups_19118, __global unsigned char *mem_18394, __global unsigned char *mem_18400)\n{\n    #define segmap_group_sizze_17158 (segmap_group_sizze_15426)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_19120;\n    int64_t group_sizze_19123;\n    int32_t wave_sizze_19122;\n    int32_t group_tid_19121;\n    \n    local_tid_19120 = get_local_id(0);\n    group_sizze_19123 = get_local_size(0);\n    wave_sizze_19122 = LOCKSTEP_WIDTH;\n    group_tid_19121 = get_group_id(0);\n    \n    int32_t global_tid_19119 = group_tid_19121 * group_sizze_19123 + local_tid_19120;\n    int32_t phys_tid_17166 = global_tid_19119;\n    int32_t phys_group_id_19124;\n    \n    phys_group_id_19124 = get_group_id(0);\n    \n    int32_t iterations_19125 = sdiv_up32(virt_num_groups_19118 - phys_group_id_19124, sext_i64_i32(num_groups_17159));\n    \n    for (int32_t i_19126 = 0; i_19126 < iterations_19125; i_19126++) {\n        int32_t virt_group_id_19127 = phys_group_id_19124 + i_19126 * sext_i64_i32(num_groups_17159);\n        int64_t global_tid_19128 = sext_i32_i64(virt_group_id_19127) * segmap_group_sizze_17158 + sext_i32_i64(local_tid_19120);\n        int64_t slice_19129 = (int64_t) 128;\n        int64_t slice_19130 = (int64_t) 128 * slice_19129;\n        int64_t slice_19131 = (int64_t) 128 * slice_19130;\n        int64_t slice_19132 = (int64_t) 128 * slice_19131;\n        int6",
                                     "4_t gtid_17162 = squot64(global_tid_19128, slice_19131);\n        int64_t remnant_19133 = global_tid_19128 - gtid_17162 * slice_19131;\n        int64_t gtid_17163 = squot64(remnant_19133, slice_19130);\n        int64_t remnant_19134 = remnant_19133 - gtid_17163 * slice_19130;\n        int64_t gtid_17164 = squot64(remnant_19134, slice_19129);\n        int64_t remnant_19135 = remnant_19134 - gtid_17164 * slice_19129;\n        int64_t gtid_17165 = remnant_19135;\n        int64_t remnant_19136 = remnant_19135 - gtid_17165;\n        \n        if (((slt64(gtid_17162, (int64_t) 128) && slt64(gtid_17163, (int64_t) 128)) && slt64(gtid_17164, (int64_t) 128)) && slt64(gtid_17165, (int64_t) 128)) {\n            int64_t arg_18105 = ((__global int64_t *) mem_18394)[(int64_t) 0];\n            int64_t convop_x_17318 = add64(arg_12396, gtid_17162);\n            int16_t index_primexp_17319 = sext_i64_i16(convop_x_17318);\n            int64_t convop_x_17417 = add64(arg_12814, gtid_17163);\n            int16_t index_primexp_17418 = sext_i64_i16(convop_x_17417);\n            int64_t convop_x_17413 = add64(arg_12818, gtid_17164);\n            int16_t index_primexp_17414 = sext_i64_i16(convop_x_17413);\n            int64_t index_primexp_17315 = add64(gtid_17165, arg_18105);\n            int16_t i64_res_17171 = sext_i64_i16(index_primexp_17315);\n            int16_t mem_18399[(int64_t) 4];\n            \n            mem_18399[(int64_t) 0] = index_primexp_17319;\n            mem_18399[(int64_t) 1] = index_primexp_17418;\n            mem_18399[(int64_t) 2] = index_primexp_17414;\n            mem_18399[(int64_t) 3] = i64_res_17171;\n            for (int64_t i_19137 = 0; i_19137 < (int64_t) 4; i_19137++) {\n                int16_t tmp_19138 = mem_18399[i_19137];\n                \n                ((__global int16_t *) mem_18400)[gtid_17162 * (int64_t) 2097152 + gtid_17163 * (int64_t) 16384 + gtid_17164 * (int64_t) 128 + gtid_17165 + i_19137 * (int64_t) 268435456] = tmp_19138;\n            }\n        }\n        barrier(CLK_G", "LOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_17158\n}\n__kernel void segmap_intragroup_17459(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, uint color_18669_backing_offset_0, int64_t arg_12396, int64_t arg_12814, int64_t arg_12818, __global unsigned char *mem_18283, __global unsigned char *mem_18292, __global unsigned char *mem_18394, __global unsigned char *mem_18432, __global unsigned char *mem_18434)\n{\n    #define tile_sizze_17461 (tile_sizze_17460)\n    #define ldim_17462 (sdiv_up_safe64((int64_t) 128, tile_sizze_17460))\n    #define num_whole_tiles_17493 (squot_safe64((int64_t) 16, tile_sizze_17460))\n    #define residual_input_17822 (srem_safe64((int64_t) 16, tile_sizze_17460))\n    #define cond_17823 (srem_safe64((int64_t) 16, tile_sizze_17460) == (int64_t) 0)\n    #define binop_x_17833 (tile_sizze_17460 * squot_safe64((int64_t) 16, tile_sizze_17460))\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile unsigned char *color_18669_backing_0 = &shared_mem[color_18669_backing_offset_0];\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_18954;\n    int64_t group_sizze_18957;\n    int32_t wave_sizze_18956;\n    int32_t group_tid_18955;\n    \n    local_tid_18954 = get_local_id(0);\n    group_sizze_18957 = get_local_size(0);\n    wave_sizze_18956 = LOCKSTEP_WIDTH;\n    group_tid_18955 = get_group_id(0);\n    \n    int32_t global_tid_18953 = group_tid_18955 * group_sizze_18957 + local_tid_18954;\n    int32_t gid_flat_17459 = group_tid_18955;\n    int64_t slice_18959 = tile_sizze_17461;\n    int64_t ltid_pre_18958 = sext_i32_i64(local_tid_18954);\n    int64_t remnant_18960 = sext_i32_i64(local_tid_18954) - ltid_pre_18958;\n ", "   int64_t slice_18961 = ldim_17462;\n    int64_t slice_18962 = (int64_t) 128 * slice_18961;\n    int64_t slice_18963 = (int64_t) 128 * slice_18962;\n    int64_t slice_18964 = (int64_t) 128 * slice_18963;\n    int64_t gtid_16902 = squot64(sext_i32_i64(group_tid_18955), slice_18963);\n    int64_t remnant_18965 = sext_i32_i64(group_tid_18955) - gtid_16902 * slice_18963;\n    int64_t gtid_16903 = squot64(remnant_18965, slice_18962);\n    int64_t remnant_18966 = remnant_18965 - gtid_16903 * slice_18962;\n    int64_t gtid_16904 = squot64(remnant_18966, slice_18961);\n    int64_t remnant_18967 = remnant_18966 - gtid_16904 * slice_18961;\n    int64_t gid_17458 = remnant_18967;\n    int64_t remnant_18968 = remnant_18967 - gid_17458;\n    __local unsigned char *color_18669;\n    \n    color_18669 = (__local unsigned char *) color_18669_backing_0;\n    \n    int64_t arg_18103 = ((__global int64_t *) mem_18394)[(int64_t) 0];\n    int64_t index_primexp_17312 = add64(arg_12396, gtid_16902);\n    bool binop_x_17300 = sle64((int64_t) 0, index_primexp_17312);\n    bool binop_y_17304 = slt64(index_primexp_17312, (int64_t) 1024);\n    bool index_primexp_17305 = binop_x_17300 && binop_y_17304;\n    int64_t index_primexp_17296 = (int64_t) 16 * index_primexp_17312;\n    int64_t index_primexp_17292 = add64(arg_12814, gtid_16903);\n    bool binop_x_17401 = sle64((int64_t) 0, index_primexp_17292);\n    bool binop_y_17405 = slt64(index_primexp_17292, (int64_t) 1024);\n    bool index_primexp_17406 = binop_x_17401 && binop_y_17405;\n    int64_t index_primexp_17397 = (int64_t) 16 * index_primexp_17292;\n    int64_t index_primexp_17289 = add64(arg_12818, gtid_16904);\n    bool binop_x_17384 = sle64((int64_t) 0, index_primexp_17289);\n    bool binop_y_17388 = slt64(index_primexp_17289, (int64_t) 1024);\n    bool index_primexp_17389 = binop_x_17384 && binop_y_17388;\n    int64_t index_primexp_17380 = (int64_t) 16 * index_primexp_17289;\n    int64_t binop_x_17476 = gid_17458 * tile_sizze_17461;\n    bool mem_18403[1];\n    int64_t",
                                     " mem_18405[1];\n    int64_t mem_18407[1];\n    int32_t ltid_flat_17467 = local_tid_18954;\n    int64_t ltid_17466 = sext_i32_i64(sext_i64_i32(ltid_pre_18958));\n    int64_t gtid_17477 = ltid_17466 + binop_x_17476;\n    bool cond_17478 = slt64(gtid_17477, (int64_t) 128);\n    bool pre_17479;\n    int64_t pre_17480;\n    int64_t pre_17481;\n    \n    if (cond_17478 == 1) {\n        int64_t index_primexp_17482 = add64(gtid_17477, arg_18103);\n        bool x_17483 = sle64((int64_t) 0, index_primexp_17482);\n        bool y_17484 = slt64(index_primexp_17482, (int64_t) 1024);\n        bool bounds_check_17485 = x_17483 && y_17484;\n        int64_t binop_x_17486 = (int64_t) 16 * index_primexp_17482;\n        \n        pre_17479 = bounds_check_17485;\n        pre_17480 = binop_x_17486;\n        pre_17481 = index_primexp_17482;\n    } else {\n        pre_17479 = 0;\n        pre_17480 = (int64_t) 0;\n        pre_17481 = (int64_t) 0;\n    }\n    mem_18403[(int64_t) 0] = pre_17479;\n    mem_18405[(int64_t) 0] = pre_17480;\n    mem_18407[(int64_t) 0] = pre_17481;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    bool mem_18409[1];\n    int32_t ltid_flat_17495 = local_tid_18954;\n    int64_t ltid_17494 = sext_i32_i64(sext_i64_i32(ltid_pre_18958));\n    \n    mem_18409[(int64_t) 0] = 1;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    bool mem_in_18665[1];\n    bool mem_18415[1];\n    bool tmp_18969 = mem_18409[(int64_t) 0];\n    \n    mem_in_18665[(int64_t) 0] = tmp_18969;\n    \n    bool ext_mem_18416[1];\n    bool ext_mem_unused_18666[1];\n    bool mem_param_18410[1];\n    bool mem_param_out_18667[1];\n    \n    for (int32_t i_1 = 0; i_1 < 1; i_1++)\n        mem_param_18410[i_1] = mem_in_18665[i_1];\n    for (int32_t i_2 = 0; i_2 < 1; i_2++)\n        mem_param_out_18667[i_2] = mem_18415[i_2];\n    for (int64_t tile_id_17501 = 0; tile_id_17501 < num_whole_tiles_17493; tile_id_17501++) {\n        int64_t binop_x_17628 = tile_sizze_17461 * tile_id_17501;\n        int32_t ltid_flat_17627 = local_tid_18954;\n        int64_t ltid_17626 = sext_i32", "_i64(sext_i64_i32(ltid_pre_18958));\n        int64_t j_17629 = ltid_17626 + binop_x_17628;\n        bool cond_17635 = slt64(j_17629, (int64_t) 16);\n        int8_t pre1d_17636;\n        \n        if (cond_17635 == 1) {\n            int8_t tile_elem_17637 = ((__global int8_t *) mem_18283)[j_17629];\n            \n            pre1d_17636 = tile_elem_17637;\n        } else {\n            pre1d_17636 = (int8_t) 0;\n        }\n        ((__local int8_t *) color_18669)[ltid_17626] = pre1d_17636;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        int32_t ltid_flat_17641 = local_tid_18954;\n        int64_t ltid_17640 = sext_i32_i64(sext_i64_i32(ltid_pre_18958));\n        int64_t gtid_17643 = binop_x_17476 + ltid_17640;\n        bool acc_17647 = mem_param_18410[(int64_t) 0];\n        bool cond_17648 = slt64(gtid_17643, (int64_t) 128);\n        bool acc_17649;\n        \n        if (cond_17648 == 1) {\n            bool bounds_check_17644 = mem_18403[(int64_t) 0];\n            int64_t binop_x_17645 = mem_18405[(int64_t) 0];\n            int64_t index_primexp_17646 = mem_18407[(int64_t) 0];\n            bool x_17650;\n            bool redout_18033 = acc_17647;\n            \n            for (int64_t i_18034 = 0; i_18034 < tile_sizze_17461; i_18034++) {\n                int8_t x_17654 = ((__local int8_t *) color_18669)[i_18034];\n                int64_t u8_res_17655 = zext_i8_i64(x_17654);\n                bool x_17656 = sle64((int64_t) 0, u8_res_17655);\n                bool y_17657 = slt64(u8_res_17655, (int64_t) 16);\n                bool bounds_check_17658 = x_17656 && y_17657;\n                bool index_ok_17659 = bounds_check_17644 && bounds_check_17658;\n                bool index_certs_17660;\n                \n                if (!index_ok_17659) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 12) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17646;\n                            global_failure_args[1] = (int64_t) ", "u8_res_17655;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_3;\n                    }\n                }\n                \n                int64_t binop_x_17661 = binop_x_17645 + u8_res_17655;\n                int64_t new_index_17662 = squot64(binop_x_17661, (int64_t) 1024);\n                int64_t binop_y_17663 = (int64_t) 1024 * new_index_17662;\n                int64_t binop_x_17664 = binop_x_17661 - binop_y_17663;\n                int64_t new_index_17665 = squot64(binop_x_17664, (int64_t) 64);\n                int64_t binop_y_17666 = (int64_t) 64 * new_index_17665;\n                int64_t binop_x_17667 = binop_x_17664 - binop_y_17666;\n                int64_t new_index_17668 = squot64(binop_x_17667, (int64_t) 32);\n                int64_t binop_y_17669 = (int64_t) 32 * new_index_17668;\n                int64_t binop_x_17670 = binop_x_17667 - binop_y_17669;\n                int64_t new_index_17671 = squot64(binop_x_17670, (int64_t) 16);\n                int64_t binop_y_17672 = (int64_t) 16 * new_index_17671;\n                int64_t new_index_17673 = binop_x_17670 - binop_y_17672;\n                int8_t defunc_0_f_res_17674 = ((__global int8_t *) mem_18292)[new_index_17662 * (int64_t) 1024 + new_index_17665 * (int64_t) 64 + new_index_17668 * (int64_t) 32 + new_index_17671 * (int64_t) 16 + new_index_17673];\n                int64_t u8_res_17675 = zext_i8_i64(defunc_0_f_res_17674);\n                bool x_17676 = sle64((int64_t) 0, u8_res_17675);\n                bool y_17677 = slt64(u8_res_17675, (int64_t) 16);\n                bool bounds_check_17678 = x_17676 && y_17677;\n                bool index_ok_17679 = index_primexp_17389 && bounds_check_17678;\n                bool index_certs_17680;\n                \n                if (!index_ok_176",
                                     "79) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 13) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17289;\n                            global_failure_args[1] = (int64_t) u8_res_17675;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_3;\n                    }\n                }\n                \n                int64_t binop_x_17681 = index_primexp_17380 + u8_res_17675;\n                int64_t new_index_17682 = squot64(binop_x_17681, (int64_t) 1024);\n                int64_t binop_y_17683 = (int64_t) 1024 * new_index_17682;\n                int64_t binop_x_17684 = binop_x_17681 - binop_y_17683;\n                int64_t new_index_17685 = squot64(binop_x_17684, (int64_t) 64);\n                int64_t binop_y_17686 = (int64_t) 64 * new_index_17685;\n                int64_t binop_x_17687 = binop_x_17684 - binop_y_17686;\n                int64_t new_index_17688 = squot64(binop_x_17687, (int64_t) 32);\n                int64_t binop_y_17689 = (int64_t) 32 * new_index_17688;\n                int64_t binop_x_17690 = binop_x_17687 - binop_y_17689;\n                int64_t new_index_17691 = squot64(binop_x_17690, (int64_t) 16);\n                int64_t binop_y_17692 = (int64_t) 16 * new_index_17691;\n                int64_t new_index_17693 = binop_x_17690 - binop_y_17692;\n                int8_t defunc_0_f_res_17694 = ((__global int8_t *) mem_18292)[new_index_17682 * (int64_t) 1024 + new_index_17685 * (int64_t) 64 + new_index_17688 * (int64_t) 32 + new_index_17691 * (int64_t) 16 + new_index_17693];\n                int64_t u8_res_17695 = zext_i8_i64(defunc_0_f_res_17694);\n                bool x_17696 = sle64((int64_t) 0, u8_res_17695);\n                bool y_17697 = ", "slt64(u8_res_17695, (int64_t) 16);\n                bool bounds_check_17698 = x_17696 && y_17697;\n                bool index_ok_17699 = index_primexp_17406 && bounds_check_17698;\n                bool index_certs_17700;\n                \n                if (!index_ok_17699) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 14) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17292;\n                            global_failure_args[1] = (int64_t) u8_res_17695;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_3;\n                    }\n                }\n                \n                int64_t binop_x_17701 = index_primexp_17397 + u8_res_17695;\n                int64_t new_index_17702 = squot64(binop_x_17701, (int64_t) 1024);\n                int64_t binop_y_17703 = (int64_t) 1024 * new_index_17702;\n                int64_t binop_x_17704 = binop_x_17701 - binop_y_17703;\n                int64_t new_index_17705 = squot64(binop_x_17704, (int64_t) 64);\n                int64_t binop_y_17706 = (int64_t) 64 * new_index_17705;\n                int64_t binop_x_17707 = binop_x_17704 - binop_y_17706;\n                int64_t new_index_17708 = squot64(binop_x_17707, (int64_t) 32);\n                int64_t binop_y_17709 = (int64_t) 32 * new_index_17708;\n                int64_t binop_x_17710 = binop_x_17707 - binop_y_17709;\n                int64_t new_index_17711 = squot64(binop_x_17710, (int64_t) 16);\n                int64_t binop_y_17712 = (int64_t) 16 * new_index_17711;\n                int64_t new_index_17713 = binop_x_17710 - binop_y_17712;\n                int8_t defunc_0_f_res_17714 = ((__global int8_t *) mem_18292)[new_index_17702 * (int64_t) 1024 + new_index_17705 * (", "int64_t) 64 + new_index_17708 * (int64_t) 32 + new_index_17711 * (int64_t) 16 + new_index_17713];\n                int64_t u8_res_17715 = zext_i8_i64(defunc_0_f_res_17714);\n                bool x_17716 = sle64((int64_t) 0, u8_res_17715);\n                bool y_17717 = slt64(u8_res_17715, (int64_t) 16);\n                bool bounds_check_17718 = x_17716 && y_17717;\n                bool index_ok_17719 = index_primexp_17305 && bounds_check_17718;\n                bool index_certs_17720;\n                \n                if (!index_ok_17719) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 15) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17312;\n                            global_failure_args[1] = (int64_t) u8_res_17715;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_3;\n                    }\n                }\n                \n                int64_t binop_x_17721 = index_primexp_17296 + u8_res_17715;\n                int64_t new_index_17722 = squot64(binop_x_17721, (int64_t) 1024);\n                int64_t binop_y_17723 = (int64_t) 1024 * new_index_17722;\n                int64_t binop_x_17724 = binop_x_17721 - binop_y_17723;\n                int64_t new_index_17725 = squot64(binop_x_17724, (int64_t) 64);\n                int64_t binop_y_17726 = (int64_t) 64 * new_index_17725;\n                int64_t binop_x_17727 = binop_x_17724 - binop_y_17726;\n                int64_t new_index_17728 = squot64(binop_x_17727, (int64_t) 32);\n                int64_t binop_y_17729 = (int64_t) 32 * new_index_17728;\n                int64_t binop_x_17730 = binop_x_17727 - binop_y_17729;\n                int64_t new_index_17731 = squot64(binop_x_17730, (int64_t) 16);\n         ",
                                     "       int64_t binop_y_17732 = (int64_t) 16 * new_index_17731;\n                int64_t new_index_17733 = binop_x_17730 - binop_y_17732;\n                int8_t defunc_0_f_res_17734 = ((__global int8_t *) mem_18292)[new_index_17722 * (int64_t) 1024 + new_index_17725 * (int64_t) 64 + new_index_17728 * (int64_t) 32 + new_index_17731 * (int64_t) 16 + new_index_17733];\n                bool binlam_res_17735 = defunc_0_f_res_17734 == x_17654;\n                bool binlam_res_17653 = binlam_res_17735 && redout_18033;\n                bool redout_tmp_18973 = binlam_res_17653;\n                \n                redout_18033 = redout_tmp_18973;\n            }\n            x_17650 = redout_18033;\n            acc_17649 = x_17650;\n        } else {\n            acc_17649 = acc_17647;\n        }\n        mem_param_out_18667[(int64_t) 0] = acc_17649;\n        \n      error_3:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        bool mem_param_tmp_18970[1];\n        \n        for (int32_t i_3 = 0; i_3 < 1; i_3++)\n            mem_param_tmp_18970[i_3] = mem_param_out_18667[i_3];\n        \n        bool mem_param_out_tmp_18971[1];\n        \n        for (int32_t i_4 = 0; i_4 < 1; i_4++)\n            mem_param_out_tmp_18971[i_4] = mem_param_18410[i_4];\n        for (int32_t i_5 = 0; i_5 < 1; i_5++)\n            mem_param_18410[i_5] = mem_param_tmp_18970[i_5];\n        for (int32_t i_6 = 0; i_6 < 1; i_6++)\n            mem_param_out_18667[i_6] = mem_param_out_tmp_18971[i_6];\n    }\n    for (int32_t i_7 = 0; i_7 < 1; i_7++)\n        ext_mem_18416[i_7] = mem_param_18410[i_7];\n    for (int32_t i_8 = 0; i_8 < 1; i_8++)\n        ext_mem_unused_18666[i_8] = mem_param_out_18667[i_8];\n    \n    bool mem_18653[1];\n    bool mem_18421[1];\n    \n    if (cond_17823 == 1) {\n        bool tmp_18974 = ext_mem_18416[(int64_t) 0];\n        \n        mem_18653[(int64_t) 0] = tmp_18974;\n    } else {\n        int32_t ltid_flat_17825 = local_tid_18954;\n   ", "     int64_t ltid_17824 = sext_i32_i64(sext_i64_i32(ltid_pre_18958));\n        int64_t j_17834 = ltid_17824 + binop_x_17833;\n        bool cond_17840 = slt64(j_17834, (int64_t) 16);\n        int8_t pre1d_17841;\n        \n        if (cond_17840 == 1) {\n            int8_t tile_elem_17842 = ((__global int8_t *) mem_18283)[j_17834];\n            \n            pre1d_17841 = tile_elem_17842;\n        } else {\n            pre1d_17841 = (int8_t) 0;\n        }\n        ((__local int8_t *) color_18669)[ltid_17824] = pre1d_17841;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        int32_t ltid_flat_17847 = local_tid_18954;\n        int64_t ltid_17846 = sext_i32_i64(sext_i64_i32(ltid_pre_18958));\n        int64_t gtid_17854 = binop_x_17476 + ltid_17846;\n        bool acc_17858 = ext_mem_18416[(int64_t) 0];\n        bool cond_17859 = slt64(gtid_17854, (int64_t) 128);\n        bool acc_17860;\n        \n        if (cond_17859 == 1) {\n            bool bounds_check_17855 = mem_18403[(int64_t) 0];\n            int64_t binop_x_17856 = mem_18405[(int64_t) 0];\n            int64_t index_primexp_17857 = mem_18407[(int64_t) 0];\n            bool x_17861;\n            bool redout_18035 = acc_17858;\n            \n            for (int64_t i_18036 = 0; i_18036 < residual_input_17822; i_18036++) {\n                int8_t x_17865 = ((__local int8_t *) color_18669)[i_18036];\n                int64_t u8_res_17866 = zext_i8_i64(x_17865);\n                bool x_17867 = sle64((int64_t) 0, u8_res_17866);\n                bool y_17868 = slt64(u8_res_17866, (int64_t) 16);\n                bool bounds_check_17869 = x_17867 && y_17868;\n                bool index_ok_17870 = bounds_check_17855 && bounds_check_17869;\n                bool index_certs_17871;\n                \n                if (!index_ok_17870) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 16) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17857;\n                           ", " global_failure_args[1] = (int64_t) u8_res_17866;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_5;\n                    }\n                }\n                \n                int64_t binop_x_17872 = binop_x_17856 + u8_res_17866;\n                int64_t new_index_17873 = squot64(binop_x_17872, (int64_t) 1024);\n                int64_t binop_y_17874 = (int64_t) 1024 * new_index_17873;\n                int64_t binop_x_17875 = binop_x_17872 - binop_y_17874;\n                int64_t new_index_17876 = squot64(binop_x_17875, (int64_t) 64);\n                int64_t binop_y_17877 = (int64_t) 64 * new_index_17876;\n                int64_t binop_x_17878 = binop_x_17875 - binop_y_17877;\n                int64_t new_index_17879 = squot64(binop_x_17878, (int64_t) 32);\n                int64_t binop_y_17880 = (int64_t) 32 * new_index_17879;\n                int64_t binop_x_17881 = binop_x_17878 - binop_y_17880;\n                int64_t new_index_17882 = squot64(binop_x_17881, (int64_t) 16);\n                int64_t binop_y_17883 = (int64_t) 16 * new_index_17882;\n                int64_t new_index_17884 = binop_x_17881 - binop_y_17883;\n                int8_t defunc_0_f_res_17885 = ((__global int8_t *) mem_18292)[new_index_17873 * (int64_t) 1024 + new_index_17876 * (int64_t) 64 + new_index_17879 * (int64_t) 32 + new_index_17882 * (int64_t) 16 + new_index_17884];\n                int64_t u8_res_17886 = zext_i8_i64(defunc_0_f_res_17885);\n                bool x_17887 = sle64((int64_t) 0, u8_res_17886);\n                bool y_17888 = slt64(u8_res_17886, (int64_t) 16);\n                bool bounds_check_17889 = x_17887 && y_17888;\n                bool index_ok_17890 = index_primexp_17389 && bounds_check_17889;\n                bool index_certs_17891;\n              ",
                                     "  \n                if (!index_ok_17890) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 17) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17289;\n                            global_failure_args[1] = (int64_t) u8_res_17886;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_5;\n                    }\n                }\n                \n                int64_t binop_x_17892 = index_primexp_17380 + u8_res_17886;\n                int64_t new_index_17893 = squot64(binop_x_17892, (int64_t) 1024);\n                int64_t binop_y_17894 = (int64_t) 1024 * new_index_17893;\n                int64_t binop_x_17895 = binop_x_17892 - binop_y_17894;\n                int64_t new_index_17896 = squot64(binop_x_17895, (int64_t) 64);\n                int64_t binop_y_17897 = (int64_t) 64 * new_index_17896;\n                int64_t binop_x_17898 = binop_x_17895 - binop_y_17897;\n                int64_t new_index_17899 = squot64(binop_x_17898, (int64_t) 32);\n                int64_t binop_y_17900 = (int64_t) 32 * new_index_17899;\n                int64_t binop_x_17901 = binop_x_17898 - binop_y_17900;\n                int64_t new_index_17902 = squot64(binop_x_17901, (int64_t) 16);\n                int64_t binop_y_17903 = (int64_t) 16 * new_index_17902;\n                int64_t new_index_17904 = binop_x_17901 - binop_y_17903;\n                int8_t defunc_0_f_res_17905 = ((__global int8_t *) mem_18292)[new_index_17893 * (int64_t) 1024 + new_index_17896 * (int64_t) 64 + new_index_17899 * (int64_t) 32 + new_index_17902 * (int64_t) 16 + new_index_17904];\n                int64_t u8_res_17906 = zext_i8_i64(defunc_0_f_res_17905);\n                bool x_17907 = sle64((int64_t) 0, u8_res_179", "06);\n                bool y_17908 = slt64(u8_res_17906, (int64_t) 16);\n                bool bounds_check_17909 = x_17907 && y_17908;\n                bool index_ok_17910 = index_primexp_17406 && bounds_check_17909;\n                bool index_certs_17911;\n                \n                if (!index_ok_17910) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 18) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17292;\n                            global_failure_args[1] = (int64_t) u8_res_17906;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_5;\n                    }\n                }\n                \n                int64_t binop_x_17912 = index_primexp_17397 + u8_res_17906;\n                int64_t new_index_17913 = squot64(binop_x_17912, (int64_t) 1024);\n                int64_t binop_y_17914 = (int64_t) 1024 * new_index_17913;\n                int64_t binop_x_17915 = binop_x_17912 - binop_y_17914;\n                int64_t new_index_17916 = squot64(binop_x_17915, (int64_t) 64);\n                int64_t binop_y_17917 = (int64_t) 64 * new_index_17916;\n                int64_t binop_x_17918 = binop_x_17915 - binop_y_17917;\n                int64_t new_index_17919 = squot64(binop_x_17918, (int64_t) 32);\n                int64_t binop_y_17920 = (int64_t) 32 * new_index_17919;\n                int64_t binop_x_17921 = binop_x_17918 - binop_y_17920;\n                int64_t new_index_17922 = squot64(binop_x_17921, (int64_t) 16);\n                int64_t binop_y_17923 = (int64_t) 16 * new_index_17922;\n                int64_t new_index_17924 = binop_x_17921 - binop_y_17923;\n                int8_t defunc_0_f_res_17925 = ((__global int8_t *) mem_18292)[new_index_17913 * ", "(int64_t) 1024 + new_index_17916 * (int64_t) 64 + new_index_17919 * (int64_t) 32 + new_index_17922 * (int64_t) 16 + new_index_17924];\n                int64_t u8_res_17926 = zext_i8_i64(defunc_0_f_res_17925);\n                bool x_17927 = sle64((int64_t) 0, u8_res_17926);\n                bool y_17928 = slt64(u8_res_17926, (int64_t) 16);\n                bool bounds_check_17929 = x_17927 && y_17928;\n                bool index_ok_17930 = index_primexp_17305 && bounds_check_17929;\n                bool index_certs_17931;\n                \n                if (!index_ok_17930) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 19) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17312;\n                            global_failure_args[1] = (int64_t) u8_res_17926;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_5;\n                    }\n                }\n                \n                int64_t binop_x_17932 = index_primexp_17296 + u8_res_17926;\n                int64_t new_index_17933 = squot64(binop_x_17932, (int64_t) 1024);\n                int64_t binop_y_17934 = (int64_t) 1024 * new_index_17933;\n                int64_t binop_x_17935 = binop_x_17932 - binop_y_17934;\n                int64_t new_index_17936 = squot64(binop_x_17935, (int64_t) 64);\n                int64_t binop_y_17937 = (int64_t) 64 * new_index_17936;\n                int64_t binop_x_17938 = binop_x_17935 - binop_y_17937;\n                int64_t new_index_17939 = squot64(binop_x_17938, (int64_t) 32);\n                int64_t binop_y_17940 = (int64_t) 32 * new_index_17939;\n                int64_t binop_x_17941 = binop_x_17938 - binop_y_17940;\n                int64_t new_index_17942 = squot64(bin",
                                     "op_x_17941, (int64_t) 16);\n                int64_t binop_y_17943 = (int64_t) 16 * new_index_17942;\n                int64_t new_index_17944 = binop_x_17941 - binop_y_17943;\n                int8_t defunc_0_f_res_17945 = ((__global int8_t *) mem_18292)[new_index_17933 * (int64_t) 1024 + new_index_17936 * (int64_t) 64 + new_index_17939 * (int64_t) 32 + new_index_17942 * (int64_t) 16 + new_index_17944];\n                bool binlam_res_17946 = defunc_0_f_res_17945 == x_17865;\n                bool binlam_res_17864 = binlam_res_17946 && redout_18035;\n                bool redout_tmp_18975 = binlam_res_17864;\n                \n                redout_18035 = redout_tmp_18975;\n            }\n            x_17861 = redout_18035;\n            acc_17860 = x_17861;\n        } else {\n            acc_17860 = acc_17858;\n        }\n        mem_18421[(int64_t) 0] = acc_17860;\n        \n      error_5:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        bool tmp_18976 = mem_18421[(int64_t) 0];\n        \n        mem_18653[(int64_t) 0] = tmp_18976;\n    }\n    \n    bool mem_18427[1];\n    int16_t mem_18430[(int64_t) 4];\n    int32_t ltid_flat_17950 = local_tid_18954;\n    int64_t ltid_17949 = sext_i32_i64(sext_i64_i32(ltid_pre_18958));\n    int64_t gtid_17958 = binop_x_17476 + ltid_17949;\n    bool all_equal_17959 = mem_18653[(int64_t) 0];\n    bool cond_17960 = slt64(gtid_17958, (int64_t) 128);\n    bool x_17980 = all_equal_17959 && cond_17960;\n    int16_t mem_18656[(int64_t) 4];\n    int16_t mem_18425[(int64_t) 4];\n    \n    if (cond_17960 == 1) {\n        int64_t index_primexp_17965 = mem_18407[(int64_t) 0];\n        int64_t convop_x_17966 = add64(arg_12396, gtid_16902);\n        int16_t index_primexp_17967 = sext_i64_i16(convop_x_17966);\n        int64_t convop_x_17968 = add64(arg_12814, gtid_16903);\n        int16_t index_primexp_17969 = sext_i64_i16(convop_x_17968);\n        int64_t convop_x_17970 = add64(arg_12818, gtid_1", "6904);\n        int16_t index_primexp_17971 = sext_i64_i16(convop_x_17970);\n        int16_t i64_res_17972 = sext_i64_i16(index_primexp_17965);\n        \n        mem_18425[(int64_t) 0] = index_primexp_17967;\n        mem_18425[(int64_t) 1] = index_primexp_17969;\n        mem_18425[(int64_t) 2] = index_primexp_17971;\n        mem_18425[(int64_t) 3] = i64_res_17972;\n        for (int64_t i_18977 = 0; i_18977 < (int64_t) 4; i_18977++) {\n            int16_t tmp_18978 = mem_18425[i_18977];\n            \n            mem_18656[i_18977] = tmp_18978;\n        }\n    }\n    mem_18427[(int64_t) 0] = x_17980;\n    for (int64_t i_18979 = 0; i_18979 < (int64_t) 4; i_18979++) {\n        int16_t tmp_18980 = mem_18656[i_18979];\n        \n        mem_18430[i_18979] = tmp_18980;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int64_t slice_18985 = tile_sizze_17461;\n    int64_t slice_18986 = slice_18985;\n    int64_t slice_18987 = slice_18986;\n    int64_t slice_18988 = slice_18987;\n    int64_t ltid_18981 = squot64(sext_i32_i64(local_tid_18954), slice_18987);\n    int64_t remnant_18989 = sext_i32_i64(local_tid_18954) - ltid_18981 * slice_18987;\n    int64_t ltid_18982 = squot64(remnant_18989, slice_18986);\n    int64_t remnant_18990 = remnant_18989 - ltid_18982 * slice_18986;\n    int64_t ltid_18983 = squot64(remnant_18990, slice_18985);\n    int64_t remnant_18991 = remnant_18990 - ltid_18983 * slice_18985;\n    int64_t ltid_18984 = remnant_18991;\n    int64_t remnant_18992 = remnant_18991 - ltid_18984;\n    int64_t thread_out_index_18993 = gtid_16902 + ltid_18981;\n    int64_t thread_out_index_18994 = gtid_16903 + ltid_18982;\n    int64_t thread_out_index_18995 = gtid_16904 + ltid_18983;\n    int64_t thread_out_index_18996 = gid_17458 * tile_sizze_17461 + ltid_18984;\n    \n    if (((slt64(thread_out_index_18993, (int64_t) 128) && slt64(thread_out_index_18994, (int64_t) 128)) && slt64(thread_out_index_18995, (int64_t) 128)) && slt64(thread_out_index_18996, (int64_t) 128)) {\n        bool tmp_18997 = mem_18427[(in", "t64_t) 0];\n        \n        ((__global bool *) mem_18432)[thread_out_index_18993 * (int64_t) 2097152 + thread_out_index_18994 * (int64_t) 16384 + thread_out_index_18995 * (int64_t) 128 + thread_out_index_18996] = tmp_18997;\n    }\n    \n    int64_t slice_19002 = tile_sizze_17461;\n    int64_t slice_19003 = slice_19002;\n    int64_t slice_19004 = slice_19003;\n    int64_t slice_19005 = slice_19004;\n    int64_t ltid_18998 = squot64(sext_i32_i64(local_tid_18954), slice_19004);\n    int64_t remnant_19006 = sext_i32_i64(local_tid_18954) - ltid_18998 * slice_19004;\n    int64_t ltid_18999 = squot64(remnant_19006, slice_19003);\n    int64_t remnant_19007 = remnant_19006 - ltid_18999 * slice_19003;\n    int64_t ltid_19000 = squot64(remnant_19007, slice_19002);\n    int64_t remnant_19008 = remnant_19007 - ltid_19000 * slice_19002;\n    int64_t ltid_19001 = remnant_19008;\n    int64_t remnant_19009 = remnant_19008 - ltid_19001;\n    int64_t thread_out_index_19010 = gtid_16902 + ltid_18998;\n    int64_t thread_out_index_19011 = gtid_16903 + ltid_18999;\n    int64_t thread_out_index_19012 = gtid_16904 + ltid_19000;\n    int64_t thread_out_index_19013 = gid_17458 * tile_sizze_17461 + ltid_19001;\n    \n    if (((slt64(thread_out_index_19010, (int64_t) 128) && slt64(thread_out_index_19011, (int64_t) 128)) && slt64(thread_out_index_19012, (int64_t) 128)) && slt64(thread_out_index_19013, (int64_t) 128)) {\n        for (int64_t i_19014 = 0; i_19014 < (int64_t) 4; i_19014++) {\n            int16_t tmp_19015 = mem_18430[ltid_18998 * ((int64_t) 4 * tile_sizze_17461) + ltid_18999 * ((int64_t) 4 * tile_sizze_17461) + ltid_19000 * ((int64_t) 4 * tile_sizze_17461) + ltid_19001 * (int64_t) 4 + i_19014 - squot64(ltid_18998 * ((int64_t) 4 * tile_sizze_17461) + ltid_18999 * ((int64_t) 4 * tile_sizze_17461) + ltid_19000 * ((int64_t) 4 * tile_sizze_17461) + ltid_19001 * (int64_t) 4 + i_19014, (int64_t) 4) * (int64_t) 4];\n            \n            ((__global int16_t *) mem_18434)[thread_out_index_19010 * (int64_t) 83",
                                     "88608 + thread_out_index_19011 * (int64_t) 65536 + thread_out_index_19012 * (int64_t) 512 + thread_out_index_19013 * (int64_t) 4 + i_19014] = tmp_19015;\n        }\n    }\n    \n  error_7:\n    return;\n    #undef tile_sizze_17461\n    #undef ldim_17462\n    #undef num_whole_tiles_17493\n    #undef residual_input_17822\n    #undef cond_17823\n    #undef binop_x_17833\n}\n__kernel void segred_large_17044(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, uint sync_arr_mem_19086_backing_offset_0, uint red_arr_mem_19084_backing_offset_1, int64_t arg_12396, int64_t arg_12814, int64_t arg_12818, int64_t num_groups_17036, int64_t groups_per_segment_19050, int64_t elements_per_thread_19051, int64_t virt_num_groups_19052, int64_t threads_per_segment_19054, __global unsigned char *mem_18283, __global unsigned char *mem_18292, __global unsigned char *mem_18394, __global unsigned char *mem_18397, __global unsigned char *segred_tmp_mem_19055, __global unsigned char *counters_mem_19057)\n{\n    #define segred_group_sizze_17035 (segred_group_sizze_15459)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile unsigned char *sync_arr_mem_19086_backing_1 = &shared_mem[sync_arr_mem_19086_backing_offset_0];\n    volatile unsigned char *red_arr_mem_19084_backing_0 = &shared_mem[red_arr_mem_19084_backing_offset_1];\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_19080;\n    int64_t group_sizze_19083;\n    int32_t wave_sizze_19082;\n    int32_t group_tid_19081;\n    \n    local_tid_19080 = get_local_id(0);\n    group_sizze_19083 = get_local_size(0);\n    wave_sizze_19082 = LOCKSTEP_WIDTH;\n    group_tid_19081 = get_group_id(0);\n    \n    int32_t global_tid_19079 = group_tid_19081 * group_sizze_19083 + local_ti", "d_19080;\n    int32_t phys_tid_17044 = global_tid_19079;\n    __local unsigned char *red_arr_mem_19084;\n    \n    red_arr_mem_19084 = (__local unsigned char *) red_arr_mem_19084_backing_0;\n    \n    __local unsigned char *sync_arr_mem_19086;\n    \n    sync_arr_mem_19086 = (__local unsigned char *) sync_arr_mem_19086_backing_1;\n    \n    int32_t phys_group_id_19088;\n    \n    phys_group_id_19088 = get_group_id(0);\n    \n    int32_t iterations_19089 = sdiv_up32(sext_i64_i32(virt_num_groups_19052) - phys_group_id_19088, sext_i64_i32(num_groups_17036));\n    \n    for (int32_t i_19090 = 0; i_19090 < iterations_19089; i_19090++) {\n        int32_t virt_group_id_19091 = phys_group_id_19088 + i_19090 * sext_i64_i32(num_groups_17036);\n        int32_t flat_segment_id_19092 = squot32(virt_group_id_19091, sext_i64_i32(groups_per_segment_19050));\n        int64_t global_tid_19093 = srem64(sext_i32_i64(virt_group_id_19091) * segred_group_sizze_17035 + sext_i32_i64(local_tid_19080), segred_group_sizze_17035 * groups_per_segment_19050);\n        int64_t slice_19094 = (int64_t) 128;\n        int64_t slice_19095 = (int64_t) 128 * slice_19094;\n        int64_t slice_19096 = (int64_t) 128 * slice_19095;\n        int64_t slice_19097 = (int64_t) 128 * slice_19096;\n        int64_t gtid_17039 = squot64(sext_i32_i64(flat_segment_id_19092), slice_19096);\n        int64_t remnant_19098 = sext_i32_i64(flat_segment_id_19092) - gtid_17039 * slice_19096;\n        int64_t gtid_17040 = squot64(remnant_19098, slice_19095);\n        int64_t remnant_19099 = remnant_19098 - gtid_17040 * slice_19095;\n        int64_t gtid_17041 = squot64(remnant_19099, slice_19094);\n        int64_t remnant_19100 = remnant_19099 - gtid_17041 * slice_19094;\n        int64_t gtid_17042 = remnant_19100;\n        int64_t remnant_19101 = remnant_19100 - gtid_17042;\n        int64_t gtid_17043;\n        bool x_acc_19102;\n        int64_t chunk_sizze_19103 = smin64(elements_per_thread_19051, sdiv_up64((int64_t) 16 - global_tid_19093, threads_per_segme", "nt_19054));\n        bool x_17045;\n        bool y_17046;\n        \n        // neutral-initialise the accumulators\n        {\n            x_acc_19102 = 1;\n        }\n        for (int64_t i_19107 = 0; i_19107 < chunk_sizze_19103; i_19107++) {\n            gtid_17043 = global_tid_19093 + threads_per_segment_19054 * i_19107;\n            // apply map function\n            {\n                int64_t arg_18104 = ((__global int64_t *) mem_18394)[(int64_t) 0];\n                int64_t index_primexp_17344 = add64(arg_12396, gtid_17039);\n                bool binop_x_17336 = sle64((int64_t) 0, index_primexp_17344);\n                bool binop_y_17340 = slt64(index_primexp_17344, (int64_t) 1024);\n                bool index_primexp_17341 = binop_x_17336 && binop_y_17340;\n                int64_t index_primexp_17332 = (int64_t) 16 * index_primexp_17344;\n                int64_t index_primexp_17328 = add64(arg_12814, gtid_17040);\n                bool binop_x_17452 = sle64((int64_t) 0, index_primexp_17328);\n                bool binop_y_17456 = slt64(index_primexp_17328, (int64_t) 1024);\n                bool index_primexp_17457 = binop_x_17452 && binop_y_17456;\n                int64_t index_primexp_17448 = (int64_t) 16 * index_primexp_17328;\n                int64_t index_primexp_17325 = add64(arg_12818, gtid_17041);\n                bool binop_x_17439 = sle64((int64_t) 0, index_primexp_17325);\n                bool binop_y_17443 = slt64(index_primexp_17325, (int64_t) 1024);\n                bool index_primexp_17444 = binop_x_17439 && binop_y_17443;\n                int64_t index_primexp_17435 = (int64_t) 16 * index_primexp_17325;\n                int64_t index_primexp_17322 = add64(gtid_17042, arg_18104);\n                bool binop_x_17426 = sle64((int64_t) 0, index_primexp_17322);\n                bool binop_y_17430 = slt64(index_primexp_17322, (int64_t) 1024);\n                bool index_primexp_17431 = binop_x_17426 && binop_y_17430;\n                int64_t index_primexp_17422 = (int64_t) 16 * inde",
                                     "x_primexp_17322;\n                int8_t x_17072 = ((__global int8_t *) mem_18283)[gtid_17043];\n                int64_t u8_res_17073 = zext_i8_i64(x_17072);\n                bool x_17074 = sle64((int64_t) 0, u8_res_17073);\n                bool y_17075 = slt64(u8_res_17073, (int64_t) 16);\n                bool bounds_check_17076 = x_17074 && y_17075;\n                bool index_ok_17077 = bounds_check_17076 && index_primexp_17431;\n                bool index_certs_17078;\n                \n                if (!index_ok_17077) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 24) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17322;\n                            global_failure_args[1] = (int64_t) u8_res_17073;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                \n                int64_t binop_x_17079 = u8_res_17073 + index_primexp_17422;\n                int64_t new_index_17080 = squot64(binop_x_17079, (int64_t) 1024);\n                int64_t binop_y_17081 = (int64_t) 1024 * new_index_17080;\n                int64_t binop_x_17082 = binop_x_17079 - binop_y_17081;\n                int64_t new_index_17083 = squot64(binop_x_17082, (int64_t) 64);\n                int64_t binop_y_17084 = (int64_t) 64 * new_index_17083;\n                int64_t binop_x_17085 = binop_x_17082 - binop_y_17084;\n                int64_t new_index_17086 = squot64(binop_x_17085, (int64_t) 32);\n                int64_t binop_y_17087 = (int64_t) 32 * new_index_17086;\n                int64_t binop_x_17088 = binop_x_17085 - binop_y_17087;\n                int64_t new_index_17089 = squot64(binop_x_17088, (int64_t) 16);\n                int64_t b", "inop_y_17090 = (int64_t) 16 * new_index_17089;\n                int64_t new_index_17091 = binop_x_17088 - binop_y_17090;\n                int8_t defunc_0_f_res_17092 = ((__global int8_t *) mem_18292)[new_index_17080 * (int64_t) 1024 + new_index_17083 * (int64_t) 64 + new_index_17086 * (int64_t) 32 + new_index_17089 * (int64_t) 16 + new_index_17091];\n                int64_t u8_res_17093 = zext_i8_i64(defunc_0_f_res_17092);\n                bool x_17094 = sle64((int64_t) 0, u8_res_17093);\n                bool y_17095 = slt64(u8_res_17093, (int64_t) 16);\n                bool bounds_check_17096 = x_17094 && y_17095;\n                bool index_ok_17097 = bounds_check_17096 && index_primexp_17444;\n                bool index_certs_17098;\n                \n                if (!index_ok_17097) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 25) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17325;\n                            global_failure_args[1] = (int64_t) u8_res_17093;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                \n                int64_t binop_x_17099 = u8_res_17093 + index_primexp_17435;\n                int64_t new_index_17100 = squot64(binop_x_17099, (int64_t) 1024);\n                int64_t binop_y_17101 = (int64_t) 1024 * new_index_17100;\n                int64_t binop_x_17102 = binop_x_17099 - binop_y_17101;\n                int64_t new_index_17103 = squot64(binop_x_17102, (int64_t) 64);\n                int64_t binop_y_17104 = (int64_t) 64 * new_index_17103;\n                int64_t binop_x_17105 = binop_x_17102 - binop_y_17104;\n                int64_t new_index_17106 = squot64(binop_x_17", "105, (int64_t) 32);\n                int64_t binop_y_17107 = (int64_t) 32 * new_index_17106;\n                int64_t binop_x_17108 = binop_x_17105 - binop_y_17107;\n                int64_t new_index_17109 = squot64(binop_x_17108, (int64_t) 16);\n                int64_t binop_y_17110 = (int64_t) 16 * new_index_17109;\n                int64_t new_index_17111 = binop_x_17108 - binop_y_17110;\n                int8_t defunc_0_f_res_17112 = ((__global int8_t *) mem_18292)[new_index_17100 * (int64_t) 1024 + new_index_17103 * (int64_t) 64 + new_index_17106 * (int64_t) 32 + new_index_17109 * (int64_t) 16 + new_index_17111];\n                int64_t u8_res_17113 = zext_i8_i64(defunc_0_f_res_17112);\n                bool x_17114 = sle64((int64_t) 0, u8_res_17113);\n                bool y_17115 = slt64(u8_res_17113, (int64_t) 16);\n                bool bounds_check_17116 = x_17114 && y_17115;\n                bool index_ok_17117 = bounds_check_17116 && index_primexp_17457;\n                bool index_certs_17118;\n                \n                if (!index_ok_17117) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 26) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17328;\n                            global_failure_args[1] = (int64_t) u8_res_17113;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                \n                int64_t binop_x_17119 = u8_res_17113 + index_primexp_17448;\n                int64_t new_index_17120 = squot64(binop_x_17119, (int64_t) 1024);\n                int64_t binop_y_17121 = (int64_t) 1024 * new_index_17120;\n                int64_t binop_x_17122 = binop_x_17119 - binop_y_17121;\n               ",
                                     " int64_t new_index_17123 = squot64(binop_x_17122, (int64_t) 64);\n                int64_t binop_y_17124 = (int64_t) 64 * new_index_17123;\n                int64_t binop_x_17125 = binop_x_17122 - binop_y_17124;\n                int64_t new_index_17126 = squot64(binop_x_17125, (int64_t) 32);\n                int64_t binop_y_17127 = (int64_t) 32 * new_index_17126;\n                int64_t binop_x_17128 = binop_x_17125 - binop_y_17127;\n                int64_t new_index_17129 = squot64(binop_x_17128, (int64_t) 16);\n                int64_t binop_y_17130 = (int64_t) 16 * new_index_17129;\n                int64_t new_index_17131 = binop_x_17128 - binop_y_17130;\n                int8_t defunc_0_f_res_17132 = ((__global int8_t *) mem_18292)[new_index_17120 * (int64_t) 1024 + new_index_17123 * (int64_t) 64 + new_index_17126 * (int64_t) 32 + new_index_17129 * (int64_t) 16 + new_index_17131];\n                int64_t u8_res_17133 = zext_i8_i64(defunc_0_f_res_17132);\n                bool x_17134 = sle64((int64_t) 0, u8_res_17133);\n                bool y_17135 = slt64(u8_res_17133, (int64_t) 16);\n                bool bounds_check_17136 = x_17134 && y_17135;\n                bool index_ok_17137 = bounds_check_17136 && index_primexp_17341;\n                bool index_certs_17138;\n                \n                if (!index_ok_17137) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 27) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17344;\n                            global_failure_args[1] = (int64_t) u8_res_17133;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                \n                int64_t binop_x_17139 = u8_res_171", "33 + index_primexp_17332;\n                int64_t new_index_17140 = squot64(binop_x_17139, (int64_t) 1024);\n                int64_t binop_y_17141 = (int64_t) 1024 * new_index_17140;\n                int64_t binop_x_17142 = binop_x_17139 - binop_y_17141;\n                int64_t new_index_17143 = squot64(binop_x_17142, (int64_t) 64);\n                int64_t binop_y_17144 = (int64_t) 64 * new_index_17143;\n                int64_t binop_x_17145 = binop_x_17142 - binop_y_17144;\n                int64_t new_index_17146 = squot64(binop_x_17145, (int64_t) 32);\n                int64_t binop_y_17147 = (int64_t) 32 * new_index_17146;\n                int64_t binop_x_17148 = binop_x_17145 - binop_y_17147;\n                int64_t new_index_17149 = squot64(binop_x_17148, (int64_t) 16);\n                int64_t binop_y_17150 = (int64_t) 16 * new_index_17149;\n                int64_t new_index_17151 = binop_x_17148 - binop_y_17150;\n                int8_t defunc_0_f_res_17152 = ((__global int8_t *) mem_18292)[new_index_17140 * (int64_t) 1024 + new_index_17143 * (int64_t) 64 + new_index_17146 * (int64_t) 32 + new_index_17149 * (int64_t) 16 + new_index_17151];\n                bool binlam_res_17153 = defunc_0_f_res_17152 == x_17072;\n                \n                // save map-out results\n                { }\n                // load accumulator\n                {\n                    x_17045 = x_acc_19102;\n                }\n                // load new values\n                {\n                    y_17046 = binlam_res_17153;\n                }\n                // apply reduction operator\n                {\n                    bool binlam_res_17047 = x_17045 && y_17046;\n                    \n                    // store in accumulator\n                    {\n                        x_acc_19102 = binlam_res_17047;\n                    }\n                }\n            }\n        }\n        // to reduce current chunk, first store our result in memory\n        {\n            x_17045 = x_acc_19102;\n            ((_", "_local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080)] = x_17045;\n        }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        int32_t offset_19108;\n        int32_t skip_waves_19109 = 1;\n        bool x_19104;\n        bool y_19105;\n        \n        offset_19108 = 0;\n        // participating threads read initial accumulator\n        {\n            if (slt32(local_tid_19080, sext_i64_i32(segred_group_sizze_17035))) {\n                x_19104 = ((__local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080 + offset_19108)];\n            }\n        }\n        offset_19108 = 1;\n        while (slt32(offset_19108, wave_sizze_19082)) {\n            if (slt32(local_tid_19080 + offset_19108, sext_i64_i32(segred_group_sizze_17035)) && ((local_tid_19080 - squot32(local_tid_19080, wave_sizze_19082) * wave_sizze_19082) & (2 * offset_19108 - 1)) == 0) {\n                // read array element\n                {\n                    y_19105 = ((volatile __local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080 + offset_19108)];\n                }\n                // apply reduction operation\n                {\n                    bool binlam_res_19106 = x_19104 && y_19105;\n                    \n                    x_19104 = binlam_res_19106;\n                }\n                // write result of operation\n                {\n                    ((volatile __local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080)] = x_19104;\n                }\n            }\n            offset_19108 *= 2;\n        }\n        while (slt32(skip_waves_19109, squot32(sext_i64_i32(segred_group_sizze_17035) + wave_sizze_19082 - 1, wave_sizze_19082))) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            offset_19108 = skip_waves_19109 * wave_sizze_19082;\n            if (slt32(local_tid_19080 + offset_19108, sext_i64_i32(segred_group_sizze_17035)) && ((local_tid_19080 - squot32(local_tid_190",
                                     "80, wave_sizze_19082) * wave_sizze_19082) == 0 && (squot32(local_tid_19080, wave_sizze_19082) & (2 * skip_waves_19109 - 1)) == 0)) {\n                // read array element\n                {\n                    y_19105 = ((__local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080 + offset_19108)];\n                }\n                // apply reduction operation\n                {\n                    bool binlam_res_19106 = x_19104 && y_19105;\n                    \n                    x_19104 = binlam_res_19106;\n                }\n                // write result of operation\n                {\n                    ((__local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080)] = x_19104;\n                }\n            }\n            skip_waves_19109 *= 2;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // first thread saves the result in accumulator\n        {\n            if (sext_i32_i64(local_tid_19080) == (int64_t) 0) {\n                x_acc_19102 = x_19104;\n            }\n        }\n        if (groups_per_segment_19050 == (int64_t) 1) {\n            // first thread in group saves final result to memory\n            {\n                if (local_tid_19080 == 0) {\n                    ((__global bool *) mem_18397)[gtid_17039 * (int64_t) 2097152 + gtid_17040 * (int64_t) 16384 + gtid_17041 * (int64_t) 128 + gtid_17042] = x_acc_19102;\n                }\n            }\n        } else {\n            int32_t old_counter_19110;\n            \n            // first thread in group saves group result to global memory\n            {\n                if (local_tid_19080 == 0) {\n                    ((__global bool *) segred_tmp_mem_19055)[sext_i32_i64(virt_group_id_19091)] = x_acc_19102;\n                    mem_fence_global();\n                    old_counter_19110 = atomic_add_i32_global(&((volatile __global int *) counters_mem_19057)[sext_i32_i64(srem32(flat_segment_id_19092, 10240))], (int) 1);\n                    ((__local bool *) sync_arr_mem_19086)[(int64_t) 0] = old_counter_19110", " == groups_per_segment_19050 - (int64_t) 1;\n                }\n            }\n            barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n            \n            bool is_last_group_19111 = ((__local bool *) sync_arr_mem_19086)[(int64_t) 0];\n            \n            if (is_last_group_19111) {\n                if (local_tid_19080 == 0) {\n                    old_counter_19110 = atomic_add_i32_global(&((volatile __global int *) counters_mem_19057)[sext_i32_i64(srem32(flat_segment_id_19092, 10240))], (int) ((int64_t) 0 - groups_per_segment_19050));\n                }\n                // read in the per-group-results\n                {\n                    int64_t read_per_thread_19112 = sdiv_up64(groups_per_segment_19050, segred_group_sizze_17035);\n                    \n                    x_17045 = 1;\n                    for (int64_t i_19113 = 0; i_19113 < read_per_thread_19112; i_19113++) {\n                        int64_t group_res_id_19114 = sext_i32_i64(local_tid_19080) * read_per_thread_19112 + i_19113;\n                        int64_t index_of_group_res_19115 = sext_i32_i64(flat_segment_id_19092) * groups_per_segment_19050 + group_res_id_19114;\n                        \n                        if (slt64(group_res_id_19114, groups_per_segment_19050)) {\n                            y_17046 = ((__global bool *) segred_tmp_mem_19055)[index_of_group_res_19115];\n                            \n                            bool binlam_res_17047 = x_17045 && y_17046;\n                            \n                            x_17045 = binlam_res_17047;\n                        }\n                    }\n                }\n                ((__local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080)] = x_17045;\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // reduce the per-group results\n                {\n                    int32_t offset_19116;\n                    int32_t skip_waves_19117 = 1;\n                    bool x_19104;\n                    bool y_19105;\n      ", "              \n                    offset_19116 = 0;\n                    // participating threads read initial accumulator\n                    {\n                        if (slt32(local_tid_19080, sext_i64_i32(segred_group_sizze_17035))) {\n                            x_19104 = ((__local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080 + offset_19116)];\n                        }\n                    }\n                    offset_19116 = 1;\n                    while (slt32(offset_19116, wave_sizze_19082)) {\n                        if (slt32(local_tid_19080 + offset_19116, sext_i64_i32(segred_group_sizze_17035)) && ((local_tid_19080 - squot32(local_tid_19080, wave_sizze_19082) * wave_sizze_19082) & (2 * offset_19116 - 1)) == 0) {\n                            // read array element\n                            {\n                                y_19105 = ((volatile __local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080 + offset_19116)];\n                            }\n                            // apply reduction operation\n                            {\n                                bool binlam_res_19106 = x_19104 && y_19105;\n                                \n                                x_19104 = binlam_res_19106;\n                            }\n                            // write result of operation\n                            {\n                                ((volatile __local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080)] = x_19104;\n                            }\n                        }\n                        offset_19116 *= 2;\n                    }\n                    while (slt32(skip_waves_19117, squot32(sext_i64_i32(segred_group_sizze_17035) + wave_sizze_19082 - 1, wave_sizze_19082))) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                        offset_19116 = skip_waves_19117 * wave_sizze_19082;\n                        if (slt32(local_tid_19080 + offset_19116, sext_i64_i32(segred_group_sizze_17035)) && ((local_tid_19080",
                                     " - squot32(local_tid_19080, wave_sizze_19082) * wave_sizze_19082) == 0 && (squot32(local_tid_19080, wave_sizze_19082) & (2 * skip_waves_19117 - 1)) == 0)) {\n                            // read array element\n                            {\n                                y_19105 = ((__local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080 + offset_19116)];\n                            }\n                            // apply reduction operation\n                            {\n                                bool binlam_res_19106 = x_19104 && y_19105;\n                                \n                                x_19104 = binlam_res_19106;\n                            }\n                            // write result of operation\n                            {\n                                ((__local bool *) red_arr_mem_19084)[sext_i32_i64(local_tid_19080)] = x_19104;\n                            }\n                        }\n                        skip_waves_19117 *= 2;\n                    }\n                    // and back to memory with the final result\n                    {\n                        if (local_tid_19080 == 0) {\n                            ((__global bool *) mem_18397)[gtid_17039 * (int64_t) 2097152 + gtid_17040 * (int64_t) 16384 + gtid_17041 * (int64_t) 128 + gtid_17042] = x_19104;\n                        }\n                    }\n                }\n            }\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segred_group_sizze_17035\n}\n__kernel void segred_nonseg_17190(__global int *global_failure, uint red_arr_mem_19155_backing_offset_0, uint sync_arr_mem_19153_backing_offset_1, int64_t num_groups_17185, int64_t num_threads_19147, __global unsigned char *ext_mem_18527, __global unsigned char *mem_18530, __global unsigned char *counters_mem_19143, __global unsigned char *segred_tmp_mem_19145)\n{\n    #define segred_group_sizze_17183 (segred_group_sizze_17182)\n    \n    const int block_dim0 = 0", ";\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile unsigned char *red_arr_mem_19155_backing_1 = &shared_mem[red_arr_mem_19155_backing_offset_0];\n    volatile unsigned char *sync_arr_mem_19153_backing_0 = &shared_mem[sync_arr_mem_19153_backing_offset_1];\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_19149;\n    int64_t group_sizze_19152;\n    int32_t wave_sizze_19151;\n    int32_t group_tid_19150;\n    \n    local_tid_19149 = get_local_id(0);\n    group_sizze_19152 = get_local_size(0);\n    wave_sizze_19151 = LOCKSTEP_WIDTH;\n    group_tid_19150 = get_group_id(0);\n    \n    int32_t global_tid_19148 = group_tid_19150 * group_sizze_19152 + local_tid_19149;\n    int32_t phys_tid_17190 = global_tid_19148;\n    __local unsigned char *sync_arr_mem_19153;\n    \n    sync_arr_mem_19153 = (__local unsigned char *) sync_arr_mem_19153_backing_0;\n    \n    __local unsigned char *red_arr_mem_19155;\n    \n    red_arr_mem_19155 = (__local unsigned char *) red_arr_mem_19155_backing_1;\n    \n    int64_t dummy_17188 = (int64_t) 0;\n    int64_t gtid_17189 = (int64_t) 0;\n    int64_t x_acc_19157;\n    int64_t chunk_sizze_19158 = smin64(sdiv_up64((int64_t) 268435456, sext_i32_i64(sext_i64_i32(segred_group_sizze_17183 * num_groups_17185))), sdiv_up64((int64_t) 268435456 - phys_tid_17190, num_threads_19147));\n    int64_t x_12509;\n    int64_t x_12510;\n    \n    // neutral-initialise the accumulators\n    {\n        x_acc_19157 = (int64_t) 268435456;\n    }\n    for (int64_t i_19162 = 0; i_19162 < chunk_sizze_19158; i_19162++) {\n        gtid_17189 = phys_tid_17190 + num_threads_19147 * i_19162;\n        // apply map function\n        {\n            int64_t new_index_17191 = squot64(gtid_17189, (int64_t) 2097152);\n            int64_t binop_y_17193 = (int64_t) 2097152 * new_index_17191;\n            int64_t binop_x_17194 = gtid_17189 - binop_y_17193;\n            int64_t new_index_17195 = squot64(binop_x_17194, (int64_t) 16384);\n            int64_t binop_y_17203 = (i", "nt64_t) 16384 * new_index_17195;\n            int64_t binop_x_17204 = binop_x_17194 - binop_y_17203;\n            int64_t new_index_17205 = squot64(binop_x_17204, (int64_t) 128);\n            int64_t binop_y_17225 = (int64_t) 128 * new_index_17205;\n            int64_t new_index_17226 = binop_x_17204 - binop_y_17225;\n            bool x_13692 = ((__global bool *) ext_mem_18527)[new_index_17191 * (int64_t) 2097152 + new_index_17195 * (int64_t) 16384 + new_index_17205 * (int64_t) 128 + new_index_17226];\n            bool cond_13694 = x_13692 == 1;\n            int64_t defunc_0_f_res_13695;\n            \n            if (cond_13694 == 1) {\n                defunc_0_f_res_13695 = gtid_17189;\n            } else {\n                defunc_0_f_res_13695 = (int64_t) 268435456;\n            }\n            // save map-out results\n            { }\n            // load accumulator\n            {\n                x_12509 = x_acc_19157;\n            }\n            // load new values\n            {\n                x_12510 = defunc_0_f_res_13695;\n            }\n            // apply reduction operator\n            {\n                int64_t defunc_0_op_res_12511 = smin64(x_12509, x_12510);\n                \n                // store in accumulator\n                {\n                    x_acc_19157 = defunc_0_op_res_12511;\n                }\n            }\n        }\n    }\n    // to reduce current chunk, first store our result in memory\n    {\n        x_12509 = x_acc_19157;\n        ((__local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149)] = x_12509;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t offset_19163;\n    int32_t skip_waves_19164 = 1;\n    int64_t x_19159;\n    int64_t x_19160;\n    \n    offset_19163 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_19149, sext_i64_i32(segred_group_sizze_17183))) {\n            x_19159 = ((__local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149 + offset_19163)];\n        }\n    }\n    offset_19163 = 1;\n ",
                                     "   while (slt32(offset_19163, wave_sizze_19151)) {\n        if (slt32(local_tid_19149 + offset_19163, sext_i64_i32(segred_group_sizze_17183)) && ((local_tid_19149 - squot32(local_tid_19149, wave_sizze_19151) * wave_sizze_19151) & (2 * offset_19163 - 1)) == 0) {\n            // read array element\n            {\n                x_19160 = ((volatile __local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149 + offset_19163)];\n            }\n            // apply reduction operation\n            {\n                int64_t defunc_0_op_res_19161 = smin64(x_19159, x_19160);\n                \n                x_19159 = defunc_0_op_res_19161;\n            }\n            // write result of operation\n            {\n                ((volatile __local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149)] = x_19159;\n            }\n        }\n        offset_19163 *= 2;\n    }\n    while (slt32(skip_waves_19164, squot32(sext_i64_i32(segred_group_sizze_17183) + wave_sizze_19151 - 1, wave_sizze_19151))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_19163 = skip_waves_19164 * wave_sizze_19151;\n        if (slt32(local_tid_19149 + offset_19163, sext_i64_i32(segred_group_sizze_17183)) && ((local_tid_19149 - squot32(local_tid_19149, wave_sizze_19151) * wave_sizze_19151) == 0 && (squot32(local_tid_19149, wave_sizze_19151) & (2 * skip_waves_19164 - 1)) == 0)) {\n            // read array element\n            {\n                x_19160 = ((__local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149 + offset_19163)];\n            }\n            // apply reduction operation\n            {\n                int64_t defunc_0_op_res_19161 = smin64(x_19159, x_19160);\n                \n                x_19159 = defunc_0_op_res_19161;\n            }\n            // write result of operation\n            {\n                ((__local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149)] = x_19159;\n            }\n        }\n        skip_waves_19164 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n  ", "  // first thread saves the result in accumulator\n    {\n        if (sext_i32_i64(local_tid_19149) == (int64_t) 0) {\n            x_acc_19157 = x_19159;\n        }\n    }\n    \n    int32_t old_counter_19165;\n    \n    // first thread in group saves group result to global memory\n    {\n        if (local_tid_19149 == 0) {\n            ((__global int64_t *) segred_tmp_mem_19145)[sext_i32_i64(group_tid_19150)] = x_acc_19157;\n            mem_fence_global();\n            old_counter_19165 = atomic_add_i32_global(&((volatile __global int *) counters_mem_19143)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_19153)[(int64_t) 0] = old_counter_19165 == num_groups_17185 - (int64_t) 1;\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    \n    bool is_last_group_19166 = ((__local bool *) sync_arr_mem_19153)[(int64_t) 0];\n    \n    if (is_last_group_19166) {\n        if (local_tid_19149 == 0) {\n            old_counter_19165 = atomic_add_i32_global(&((volatile __global int *) counters_mem_19143)[(int64_t) 0], (int) ((int64_t) 0 - num_groups_17185));\n        }\n        // read in the per-group-results\n        {\n            int64_t read_per_thread_19167 = sdiv_up64(num_groups_17185, segred_group_sizze_17183);\n            \n            x_12509 = (int64_t) 268435456;\n            for (int64_t i_19168 = 0; i_19168 < read_per_thread_19167; i_19168++) {\n                int64_t group_res_id_19169 = sext_i32_i64(local_tid_19149) * read_per_thread_19167 + i_19168;\n                int64_t index_of_group_res_19170 = group_res_id_19169;\n                \n                if (slt64(group_res_id_19169, num_groups_17185)) {\n                    x_12510 = ((__global int64_t *) segred_tmp_mem_19145)[index_of_group_res_19170];\n                    \n                    int64_t defunc_0_op_res_12511 = smin64(x_12509, x_12510);\n                    \n                    x_12509 = defunc_0_op_res_12511;\n                }\n            }\n        }\n        ((__local int64_t *) red_arr", "_mem_19155)[sext_i32_i64(local_tid_19149)] = x_12509;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-group results\n        {\n            int32_t offset_19171;\n            int32_t skip_waves_19172 = 1;\n            int64_t x_19159;\n            int64_t x_19160;\n            \n            offset_19171 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_19149, sext_i64_i32(segred_group_sizze_17183))) {\n                    x_19159 = ((__local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149 + offset_19171)];\n                }\n            }\n            offset_19171 = 1;\n            while (slt32(offset_19171, wave_sizze_19151)) {\n                if (slt32(local_tid_19149 + offset_19171, sext_i64_i32(segred_group_sizze_17183)) && ((local_tid_19149 - squot32(local_tid_19149, wave_sizze_19151) * wave_sizze_19151) & (2 * offset_19171 - 1)) == 0) {\n                    // read array element\n                    {\n                        x_19160 = ((volatile __local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149 + offset_19171)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t defunc_0_op_res_19161 = smin64(x_19159, x_19160);\n                        \n                        x_19159 = defunc_0_op_res_19161;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149)] = x_19159;\n                    }\n                }\n                offset_19171 *= 2;\n            }\n            while (slt32(skip_waves_19172, squot32(sext_i64_i32(segred_group_sizze_17183) + wave_sizze_19151 - 1, wave_sizze_19151))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_19171 = skip_waves_19172 * wave_sizze_19151;\n                if (slt32(local_tid_19149 + offset_19171, sext_i",
                                     "64_i32(segred_group_sizze_17183)) && ((local_tid_19149 - squot32(local_tid_19149, wave_sizze_19151) * wave_sizze_19151) == 0 && (squot32(local_tid_19149, wave_sizze_19151) & (2 * skip_waves_19172 - 1)) == 0)) {\n                    // read array element\n                    {\n                        x_19160 = ((__local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149 + offset_19171)];\n                    }\n                    // apply reduction operation\n                    {\n                        int64_t defunc_0_op_res_19161 = smin64(x_19159, x_19160);\n                        \n                        x_19159 = defunc_0_op_res_19161;\n                    }\n                    // write result of operation\n                    {\n                        ((__local int64_t *) red_arr_mem_19155)[sext_i32_i64(local_tid_19149)] = x_19159;\n                    }\n                }\n                skip_waves_19172 *= 2;\n            }\n            // and back to memory with the final result\n            {\n                if (local_tid_19149 == 0) {\n                    ((__global int64_t *) mem_18530)[(int64_t) 0] = x_19159;\n                }\n            }\n        }\n    }\n    \n  error_1:\n    return;\n    #undef segred_group_sizze_17183\n}\n__kernel void segred_small_17044(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, uint red_arr_mem_19023_backing_offset_0, int64_t arg_12396, int64_t arg_12814, int64_t arg_12818, int64_t num_groups_17036, int64_t segment_sizze_nonzzero_19016, __global unsigned char *mem_18283, __global unsigned char *mem_18292, __global unsigned char *mem_18394, __global unsigned char *mem_18397)\n{\n    #define segred_group_sizze_17035 (segred_group_sizze_15459)\n    \n    const int block_dim0 = 0;\n    const int block_dim1 = 1;\n    const int block_dim2 = 2;\n    volatile unsigned char *red_arr_mem_19023_backing_0 = &shared_mem[red_arr_mem_19023_backing_offset_0];\n    volatile __local int local_failure;\n    \n    if ", "(failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_19019;\n    int64_t group_sizze_19022;\n    int32_t wave_sizze_19021;\n    int32_t group_tid_19020;\n    \n    local_tid_19019 = get_local_id(0);\n    group_sizze_19022 = get_local_size(0);\n    wave_sizze_19021 = LOCKSTEP_WIDTH;\n    group_tid_19020 = get_group_id(0);\n    \n    int32_t global_tid_19018 = group_tid_19020 * group_sizze_19022 + local_tid_19019;\n    int32_t phys_tid_17044 = global_tid_19018;\n    __local unsigned char *red_arr_mem_19023;\n    \n    red_arr_mem_19023 = (__local unsigned char *) red_arr_mem_19023_backing_0;\n    \n    int32_t phys_group_id_19025;\n    \n    phys_group_id_19025 = get_group_id(0);\n    \n    int32_t iterations_19026 = sdiv_up32(sext_i64_i32(sdiv_up64((int64_t) 268435456, squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016))) - phys_group_id_19025, sext_i64_i32(num_groups_17036));\n    \n    for (int32_t i_19027 = 0; i_19027 < iterations_19026; i_19027++) {\n        int32_t virt_group_id_19028 = phys_group_id_19025 + i_19027 * sext_i64_i32(num_groups_17036);\n        int64_t slice_19029 = (int64_t) 128;\n        int64_t slice_19030 = (int64_t) 128 * slice_19029;\n        int64_t slice_19031 = (int64_t) 128 * slice_19030;\n        int64_t slice_19032 = (int64_t) 128 * slice_19031;\n        int64_t gtid_17039 = squot64(squot64(sext_i32_i64(local_tid_19019), segment_sizze_nonzzero_19016) + sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016), slice_19031);\n        int64_t remnant_19033 = squot64(sext_i32_i64(local_tid_19019), segment_sizze_nonzzero_19016) + sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) - gtid_17039 * slice_19031;\n        int64_t gtid_17040 = squot64(remnant_19033, slice_19030);\n        int64_t remnant_19034 = remnant_19033", " - gtid_17040 * slice_19030;\n        int64_t gtid_17041 = squot64(remnant_19034, slice_19029);\n        int64_t remnant_19035 = remnant_19034 - gtid_17041 * slice_19029;\n        int64_t gtid_17042 = remnant_19035;\n        int64_t remnant_19036 = remnant_19035 - gtid_17042;\n        int64_t gtid_17043 = srem64(sext_i32_i64(local_tid_19019), (int64_t) 16);\n        \n        // apply map function if in bounds\n        {\n            if (slt64((int64_t) 0, (int64_t) 16) && ((((slt64(gtid_17039, (int64_t) 128) && slt64(gtid_17040, (int64_t) 128)) && slt64(gtid_17041, (int64_t) 128)) && slt64(gtid_17042, (int64_t) 128)) && slt64(sext_i32_i64(local_tid_19019), (int64_t) 16 * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016)))) {\n                int64_t arg_18104 = ((__global int64_t *) mem_18394)[(int64_t) 0];\n                int64_t index_primexp_17344 = add64(arg_12396, gtid_17039);\n                bool binop_x_17336 = sle64((int64_t) 0, index_primexp_17344);\n                bool binop_y_17340 = slt64(index_primexp_17344, (int64_t) 1024);\n                bool index_primexp_17341 = binop_x_17336 && binop_y_17340;\n                int64_t index_primexp_17332 = (int64_t) 16 * index_primexp_17344;\n                int64_t index_primexp_17328 = add64(arg_12814, gtid_17040);\n                bool binop_x_17452 = sle64((int64_t) 0, index_primexp_17328);\n                bool binop_y_17456 = slt64(index_primexp_17328, (int64_t) 1024);\n                bool index_primexp_17457 = binop_x_17452 && binop_y_17456;\n                int64_t index_primexp_17448 = (int64_t) 16 * index_primexp_17328;\n                int64_t index_primexp_17325 = add64(arg_12818, gtid_17041);\n                bool binop_x_17439 = sle64((int64_t) 0, index_primexp_17325);\n                bool binop_y_17443 = slt64(index_primexp_17325, (int64_t) 1024);\n                bool index_primexp_17444 = binop_x_17439 && binop_y_17443;\n                int64_t index_primexp_17435 = (int64_t) 16 * index_primexp_17325;\n",
                                     "                int64_t index_primexp_17322 = add64(gtid_17042, arg_18104);\n                bool binop_x_17426 = sle64((int64_t) 0, index_primexp_17322);\n                bool binop_y_17430 = slt64(index_primexp_17322, (int64_t) 1024);\n                bool index_primexp_17431 = binop_x_17426 && binop_y_17430;\n                int64_t index_primexp_17422 = (int64_t) 16 * index_primexp_17322;\n                int8_t x_17072 = ((__global int8_t *) mem_18283)[gtid_17043];\n                int64_t u8_res_17073 = zext_i8_i64(x_17072);\n                bool x_17074 = sle64((int64_t) 0, u8_res_17073);\n                bool y_17075 = slt64(u8_res_17073, (int64_t) 16);\n                bool bounds_check_17076 = x_17074 && y_17075;\n                bool index_ok_17077 = bounds_check_17076 && index_primexp_17431;\n                bool index_certs_17078;\n                \n                if (!index_ok_17077) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 20) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17322;\n                            global_failure_args[1] = (int64_t) u8_res_17073;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                \n                int64_t binop_x_17079 = u8_res_17073 + index_primexp_17422;\n                int64_t new_index_17080 = squot64(binop_x_17079, (int64_t) 1024);\n                int64_t binop_y_17081 = (int64_t) 1024 * new_index_17080;\n                int64_t binop_x_17082 = binop_x_17079 - binop_y_17081;\n                int64_t new_index_17083 = squot64(binop_x_17082, (int64_t) 64);\n                int64_t binop_y_17084 = (int64_t) 64 * new_index_17083;\n                int64_t ", "binop_x_17085 = binop_x_17082 - binop_y_17084;\n                int64_t new_index_17086 = squot64(binop_x_17085, (int64_t) 32);\n                int64_t binop_y_17087 = (int64_t) 32 * new_index_17086;\n                int64_t binop_x_17088 = binop_x_17085 - binop_y_17087;\n                int64_t new_index_17089 = squot64(binop_x_17088, (int64_t) 16);\n                int64_t binop_y_17090 = (int64_t) 16 * new_index_17089;\n                int64_t new_index_17091 = binop_x_17088 - binop_y_17090;\n                int8_t defunc_0_f_res_17092 = ((__global int8_t *) mem_18292)[new_index_17080 * (int64_t) 1024 + new_index_17083 * (int64_t) 64 + new_index_17086 * (int64_t) 32 + new_index_17089 * (int64_t) 16 + new_index_17091];\n                int64_t u8_res_17093 = zext_i8_i64(defunc_0_f_res_17092);\n                bool x_17094 = sle64((int64_t) 0, u8_res_17093);\n                bool y_17095 = slt64(u8_res_17093, (int64_t) 16);\n                bool bounds_check_17096 = x_17094 && y_17095;\n                bool index_ok_17097 = bounds_check_17096 && index_primexp_17444;\n                bool index_certs_17098;\n                \n                if (!index_ok_17097) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 21) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17325;\n                            global_failure_args[1] = (int64_t) u8_res_17093;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                \n                int64_t binop_x_17099 = u8_res_17093 + index_primexp_17435;\n                int64_t new_index_17100 = squot64(binop_x_17099, (int64_t) 1024);\n                int64_t binop_y_17101 = (int64_t) 102", "4 * new_index_17100;\n                int64_t binop_x_17102 = binop_x_17099 - binop_y_17101;\n                int64_t new_index_17103 = squot64(binop_x_17102, (int64_t) 64);\n                int64_t binop_y_17104 = (int64_t) 64 * new_index_17103;\n                int64_t binop_x_17105 = binop_x_17102 - binop_y_17104;\n                int64_t new_index_17106 = squot64(binop_x_17105, (int64_t) 32);\n                int64_t binop_y_17107 = (int64_t) 32 * new_index_17106;\n                int64_t binop_x_17108 = binop_x_17105 - binop_y_17107;\n                int64_t new_index_17109 = squot64(binop_x_17108, (int64_t) 16);\n                int64_t binop_y_17110 = (int64_t) 16 * new_index_17109;\n                int64_t new_index_17111 = binop_x_17108 - binop_y_17110;\n                int8_t defunc_0_f_res_17112 = ((__global int8_t *) mem_18292)[new_index_17100 * (int64_t) 1024 + new_index_17103 * (int64_t) 64 + new_index_17106 * (int64_t) 32 + new_index_17109 * (int64_t) 16 + new_index_17111];\n                int64_t u8_res_17113 = zext_i8_i64(defunc_0_f_res_17112);\n                bool x_17114 = sle64((int64_t) 0, u8_res_17113);\n                bool y_17115 = slt64(u8_res_17113, (int64_t) 16);\n                bool bounds_check_17116 = x_17114 && y_17115;\n                bool index_ok_17117 = bounds_check_17116 && index_primexp_17457;\n                bool index_certs_17118;\n                \n                if (!index_ok_17117) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 22) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17328;\n                            global_failure_args[1] = (int64_t) u8_res_17113;\n                            global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n",
                                     "                    }\n                }\n                \n                int64_t binop_x_17119 = u8_res_17113 + index_primexp_17448;\n                int64_t new_index_17120 = squot64(binop_x_17119, (int64_t) 1024);\n                int64_t binop_y_17121 = (int64_t) 1024 * new_index_17120;\n                int64_t binop_x_17122 = binop_x_17119 - binop_y_17121;\n                int64_t new_index_17123 = squot64(binop_x_17122, (int64_t) 64);\n                int64_t binop_y_17124 = (int64_t) 64 * new_index_17123;\n                int64_t binop_x_17125 = binop_x_17122 - binop_y_17124;\n                int64_t new_index_17126 = squot64(binop_x_17125, (int64_t) 32);\n                int64_t binop_y_17127 = (int64_t) 32 * new_index_17126;\n                int64_t binop_x_17128 = binop_x_17125 - binop_y_17127;\n                int64_t new_index_17129 = squot64(binop_x_17128, (int64_t) 16);\n                int64_t binop_y_17130 = (int64_t) 16 * new_index_17129;\n                int64_t new_index_17131 = binop_x_17128 - binop_y_17130;\n                int8_t defunc_0_f_res_17132 = ((__global int8_t *) mem_18292)[new_index_17120 * (int64_t) 1024 + new_index_17123 * (int64_t) 64 + new_index_17126 * (int64_t) 32 + new_index_17129 * (int64_t) 16 + new_index_17131];\n                int64_t u8_res_17133 = zext_i8_i64(defunc_0_f_res_17132);\n                bool x_17134 = sle64((int64_t) 0, u8_res_17133);\n                bool y_17135 = slt64(u8_res_17133, (int64_t) 16);\n                bool bounds_check_17136 = x_17134 && y_17135;\n                bool index_ok_17137 = bounds_check_17136 && index_primexp_17341;\n                bool index_certs_17138;\n                \n                if (!index_ok_17137) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 23) == -1) {\n                            global_failure_args[0] = (int64_t) index_primexp_17344;\n                            global_failure_args[1] = (int64_t) u8_res_17133;\n                         ", "   global_failure_args[2] = (int64_t) (int64_t) 1024;\n                            global_failure_args[3] = (int64_t) (int64_t) 16;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                \n                int64_t binop_x_17139 = u8_res_17133 + index_primexp_17332;\n                int64_t new_index_17140 = squot64(binop_x_17139, (int64_t) 1024);\n                int64_t binop_y_17141 = (int64_t) 1024 * new_index_17140;\n                int64_t binop_x_17142 = binop_x_17139 - binop_y_17141;\n                int64_t new_index_17143 = squot64(binop_x_17142, (int64_t) 64);\n                int64_t binop_y_17144 = (int64_t) 64 * new_index_17143;\n                int64_t binop_x_17145 = binop_x_17142 - binop_y_17144;\n                int64_t new_index_17146 = squot64(binop_x_17145, (int64_t) 32);\n                int64_t binop_y_17147 = (int64_t) 32 * new_index_17146;\n                int64_t binop_x_17148 = binop_x_17145 - binop_y_17147;\n                int64_t new_index_17149 = squot64(binop_x_17148, (int64_t) 16);\n                int64_t binop_y_17150 = (int64_t) 16 * new_index_17149;\n                int64_t new_index_17151 = binop_x_17148 - binop_y_17150;\n                int8_t defunc_0_f_res_17152 = ((__global int8_t *) mem_18292)[new_index_17140 * (int64_t) 1024 + new_index_17143 * (int64_t) 64 + new_index_17146 * (int64_t) 32 + new_index_17149 * (int64_t) 16 + new_index_17151];\n                bool binlam_res_17153 = defunc_0_f_res_17152 == x_17072;\n                \n                // save map-out results\n                { }\n                // save results to be reduced\n                {\n                    ((__local bool *) red_arr_mem_19023)[sext_i32_i64(local_tid_19019)] = binlam_res_17153;\n                }\n            } else {\n                ((__local bool *) red_arr_mem_19023)[sext_i32_i64(local_tid_19019)] = 1;\n            }\n       ", " }\n        \n      error_0:\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_failure)\n            return;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (slt64((int64_t) 0, (int64_t) 16)) {\n            // perform segmented scan to imitate reduction\n            {\n                bool x_17045;\n                bool y_17046;\n                bool x_19037;\n                bool y_19038;\n                bool ltid_in_bounds_19040 = slt64(sext_i32_i64(local_tid_19019), (int64_t) 16 * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016));\n                int32_t skip_threads_19041;\n                \n                // read input for in-block scan\n                {\n                    if (ltid_in_bounds_19040) {\n                        y_17046 = ((volatile __local bool *) red_arr_mem_19023)[sext_i32_i64(local_tid_19019)];\n                        if ((local_tid_19019 - squot32(local_tid_19019, 32) * 32) == 0) {\n                            x_17045 = y_17046;\n                        }\n                    }\n                }\n                // in-block scan (hopefully no barriers needed)\n                {\n                    skip_threads_19041 = 1;\n                    while (slt32(skip_threads_19041, 32)) {\n                        bool thread_active_19042 = sle32(skip_threads_19041, local_tid_19019 - squot32(local_tid_19019, 32) * 32) && ltid_in_bounds_19040;\n                        \n                        if (thread_active_19042) {\n                            // read operands\n                            {\n                                x_17045 = ((volatile __local bool *) red_arr_mem_19023)[sext_i32_i64(local_tid_19019) - sext_i32_i64(skip_threads_19041)];\n                            }\n                        }\n                        // perform operation\n                        {\n                            bool inactive_19043 = slt64(srem64(sext_i32_i64(local_tid_19019), (int64_t) 16), sext_i32_i64(local_tid_19019) - sext_i32_i64(local_tid_19019 - skip_thread",
                                     "s_19041));\n                            \n                            if (thread_active_19042 && inactive_19043) {\n                                x_17045 = y_17046;\n                            }\n                            if (thread_active_19042) {\n                                if (!inactive_19043) {\n                                    bool binlam_res_17047 = x_17045 && y_17046;\n                                    \n                                    x_17045 = binlam_res_17047;\n                                }\n                            }\n                        }\n                        if (sle32(wave_sizze_19021, skip_threads_19041)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        if (thread_active_19042) {\n                            // write result\n                            {\n                                ((volatile __local bool *) red_arr_mem_19023)[sext_i32_i64(local_tid_19019)] = x_17045;\n                                y_17046 = x_17045;\n                            }\n                        }\n                        if (sle32(wave_sizze_19021, skip_threads_19041)) {\n                            barrier(CLK_LOCAL_MEM_FENCE);\n                        }\n                        skip_threads_19041 *= 2;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // last thread of block 'i' writes its result to offset 'i'\n                {\n                    if ((local_tid_19019 - squot32(local_tid_19019, 32) * 32) == 31 && ltid_in_bounds_19040) {\n                        ((volatile __local bool *) red_arr_mem_19023)[sext_i32_i64(squot32(local_tid_19019, 32))] = x_17045;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n                {\n                    int32_t skip_threads_19044;\n                    \n                   ", " // read input for in-block scan\n                    {\n                        if (squot32(local_tid_19019, 32) == 0 && ltid_in_bounds_19040) {\n                            y_19038 = ((volatile __local bool *) red_arr_mem_19023)[sext_i32_i64(local_tid_19019)];\n                            if ((local_tid_19019 - squot32(local_tid_19019, 32) * 32) == 0) {\n                                x_19037 = y_19038;\n                            }\n                        }\n                    }\n                    // in-block scan (hopefully no barriers needed)\n                    {\n                        skip_threads_19044 = 1;\n                        while (slt32(skip_threads_19044, 32)) {\n                            bool thread_active_19045 = sle32(skip_threads_19044, local_tid_19019 - squot32(local_tid_19019, 32) * 32) && (squot32(local_tid_19019, 32) == 0 && ltid_in_bounds_19040);\n                            \n                            if (thread_active_19045) {\n                                // read operands\n                                {\n                                    x_19037 = ((volatile __local bool *) red_arr_mem_19023)[sext_i32_i64(local_tid_19019) - sext_i32_i64(skip_threads_19044)];\n                                }\n                            }\n                            // perform operation\n                            {\n                                bool inactive_19046 = slt64(srem64(sext_i32_i64(local_tid_19019 * 32 + 32 - 1), (int64_t) 16), sext_i32_i64(local_tid_19019 * 32 + 32 - 1) - sext_i32_i64((local_tid_19019 - skip_threads_19044) * 32 + 32 - 1));\n                                \n                                if (thread_active_19045 && inactive_19046) {\n                                    x_19037 = y_19038;\n                                }\n                                if (thread_active_19045) {\n                                    if (!inactive_19046) {\n                                        bool binlam_res_19039 = x_19037 && y_19038;\n     ", "                                   \n                                        x_19037 = binlam_res_19039;\n                                    }\n                                }\n                            }\n                            if (sle32(wave_sizze_19021, skip_threads_19044)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            if (thread_active_19045) {\n                                // write result\n                                {\n                                    ((volatile __local bool *) red_arr_mem_19023)[sext_i32_i64(local_tid_19019)] = x_19037;\n                                    y_19038 = x_19037;\n                                }\n                            }\n                            if (sle32(wave_sizze_19021, skip_threads_19044)) {\n                                barrier(CLK_LOCAL_MEM_FENCE);\n                            }\n                            skip_threads_19044 *= 2;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                \n                bool no_carry_in_19047 = squot32(local_tid_19019, 32) == 0 || !ltid_in_bounds_19040;\n                \n                // carry-in for every block except the first\n                {\n                    // read operands\n                    {\n                        if (!no_carry_in_19047) {\n                            y_17046 = x_17045;\n                            x_17045 = ((__local bool *) red_arr_mem_19023)[sext_i32_i64(squot32(local_tid_19019, 32)) - (int64_t) 1];\n                        }\n                    }\n                    // perform operation\n                    {\n                        bool inactive_19048 = slt64(srem64(sext_i32_i64(local_tid_19019), (int64_t) 16), sext_i32_i64(local_tid_19019) - sext_i32_i64(squot32(local_tid_19019, 32) * 32 - 1));\n                        \n                        if (!no_carry_in_19047) {\n                          ",
                                     "  if (inactive_19048) {\n                                x_17045 = y_17046;\n                            }\n                        }\n                        if (!no_carry_in_19047) {\n                            if (!inactive_19048) {\n                                bool binlam_res_17047 = x_17045 && y_17046;\n                                \n                                x_17045 = binlam_res_17047;\n                            }\n                        }\n                    }\n                    // write final result\n                    {\n                        if (!no_carry_in_19047) {\n                            ((__local bool *) red_arr_mem_19023)[sext_i32_i64(local_tid_19019)] = x_17045;\n                        }\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n                // restore correct values for first block\n                {\n                    if (squot32(local_tid_19019, 32) == 0 && ltid_in_bounds_19040) {\n                        ((__local bool *) red_arr_mem_19023)[sext_i32_i64(local_tid_19019)] = y_17046;\n                    }\n                }\n                barrier(CLK_LOCAL_MEM_FENCE);\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // save final values of segments\n        {\n            if (slt64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019), (int64_t) 268435456) && slt64(sext_i32_i64(local_tid_19019), squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016))) {\n                bool tmp_19049 = ((__local bool *) red_arr_mem_19023)[(sext_i32_i64(local_tid_19019) + (int64_t) 1) * segment_sizze_nonzzero_19016 - (int64_t) 1];\n                \n                ((__global bool *) mem_18397)[squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019), (int64_t) 2097152) * (int64_t) 2097152 + squot64(sext_i32_i64(virt_group_i", "d_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019) - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019), (int64_t) 2097152) * (int64_t) 2097152, (int64_t) 16384) * (int64_t) 16384 + squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019) - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019), (int64_t) 2097152) * (int64_t) 2097152 - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019) - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019), (int64_t) 2097152) * (int64_t) 2097152, (int64_t) 16384) * (int64_t) 16384, (int64_t) 128) * (int64_t) 128 + (sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019) - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019), (int64_t) 2097152) * (int64_t) 2097152 - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019) - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019), (int64_t) 2097152) * (int64_t) 2097152, (int64_t) 16384) * (int64_t) 16384 - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019) - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019", "), (int64_t) 2097152) * (int64_t) 2097152 - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019) - squot64(sext_i32_i64(virt_group_id_19028) * squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016) + sext_i32_i64(local_tid_19019), (int64_t) 2097152) * (int64_t) 2097152, (int64_t) 16384) * (int64_t) 16384, (int64_t) 128) * (int64_t) 128)] = tmp_19049;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n    #undef segred_group_sizze_17035\n}\n", NULL, NULL};
// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
        return bad;                             \
      } else {                                  \
        free(serror);                           \
      }                                         \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  const char *cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  int num_nvrtc_opts;
  const char **nvrtc_opts;

  const char *preferred_device;
  int preferred_device_num;

  const char *dump_program_to;
  const char *load_program_from;

  const char *dump_ptx_to;
  const char *load_ptx_from;

  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (const char**) malloc(sizeof(const char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->preferred_device_num = 0;
  cfg->preferred_device = "";
  cfg->dump_program_to = NULL;
  cfg->load_program_from = NULL;

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->default_block_size = 256;
  cfg->default_grid_size = 0; // Set properly later.
  cfg->default_tile_size = 32;
  cfg->default_reg_tile_size = 2;
  cfg->default_threshold = 32*1024;

  cfg->default_block_size_changed = 0;
  cfg->default_grid_size_changed = 0;
  cfg->default_tile_size_changed = 0;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  free(cfg->nvrtc_opts);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = opt;
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (const char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(const char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  cfg->preferred_device = s;
  cfg->preferred_device_num = x;
}

void futhark_context_config_dump_program_to(struct futhark_context_config *cfg, const char *path) {
  cfg->dump_program_to = path;
}

void futhark_context_config_load_program_from(struct futhark_context_config *cfg, const char *path) {
  cfg->load_program_from = path;
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  cfg->dump_ptx_to = path;
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  cfg->load_ptx_from = path;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  cfg->default_block_size = size;
  cfg->default_block_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  cfg->default_grid_size = num;
  cfg->default_grid_size_changed = 1;
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->default_tile_size = size;
  cfg->default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->default_reg_tile_size = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_group_size") == 0) {
    cfg->default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_num_groups") == 0) {
    cfg->default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->default_reg_tile_size = new_value;
    return 0;
  }
  return 1;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  int *runs;
  int64_t *runtime;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list cu_free_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  // Uniform above

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;
  struct program* program;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;

  struct free_list free_list;

  size_t max_block_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_shared_memory;
  size_t max_bespoke;

  size_t lockstep_width;

  struct profiling_record *profiling_records;
  int profiling_records_capacity;
  int profiling_records_used;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best, cc_minor_best;
  int cc_major, cc_minor;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(stderr, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(stderr, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(stderr, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static char *concat_fragments(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  struct {
    int major;
    int minor;
    const char *arch_str;
  } static const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_group_size",
                        (int)ctx->max_block_size);
  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_block_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->default_block_size > ctx->max_block_size) {
    if (cfg->default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_block_size, cfg->default_block_size);
    }
    cfg->default_block_size = ctx->max_block_size;
  }
  if (cfg->default_grid_size > ctx->max_grid_size) {
    if (cfg->default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->default_grid_size);
    }
    cfg->default_grid_size = ctx->max_grid_size;
  }
  if (cfg->default_tile_size > ctx->max_tile_size) {
    if (cfg->default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->default_tile_size);
    }
    cfg->default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->default_grid_size_changed) {
    cfg->default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "group_size") == size_class) {
      max_value = ctx->max_block_size;
      default_value = cfg->default_block_size;
    } else if (strstr(size_class, "num_groups") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->default_reg_tile_size;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src_fragments[],
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL, *src = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_program_from == NULL) {
    src = concat_fragments(src_fragments);
  } else {
    src = slurp_file(cfg->load_program_from, NULL);
  }

  if (cfg->load_ptx_from) {
    if (cfg->load_program_from != NULL) {
      fprintf(stderr,
              "WARNING: Using PTX from %s instead of C code from %s\n",
              cfg->load_ptx_from, cfg->load_program_from);
    }
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  if (cfg->dump_program_to != NULL) {
    dump_file(cfg->dump_program_to, src, strlen(src));
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      free(src);
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);

  free(ptx);
  if (src != NULL) {
    free(src);
  }

  return NULL;
}

static char* cuda_setup(struct futhark_context *ctx, const char *src_fragments[],
                        const char *extra_opts[], const char* cache_fname) {
  CUDA_SUCCEED_FATAL(cuInit(0));

  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->cu_free_list);

  ctx->max_shared_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK);
  ctx->max_block_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_block_size);
  ctx->max_threshold = 0;
  ctx->max_bespoke = 0;
  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);

  cuda_size_setup(ctx);
  return cuda_module_setup(ctx, src_fragments, extra_opts, cache_fname);
}

// Count up the runtime all the profiling_records that occured during execution.
// Also clears the buffer of profiling_records.
static cudaError_t cuda_tally_profiling_records(struct futhark_context *ctx) {
  cudaError_t err;
  for (int i = 0; i < ctx->profiling_records_used; i++) {
    struct profiling_record record = ctx->profiling_records[i];

    float ms;
    if ((err = cudaEventElapsedTime(&ms, record.events[0], record.events[1])) != cudaSuccess) {
      return err;
    }

    // CUDA provides milisecond resolution, but we want microseconds.
    *record.runs += 1;
    *record.runtime += ms*1000;

    if ((err = cudaEventDestroy(record.events[0])) != cudaSuccess) {
      return err;
    }
    if ((err = cudaEventDestroy(record.events[1])) != cudaSuccess) {
      return err;
    }

    free(record.events);
  }

  ctx->profiling_records_used = 0;

  return cudaSuccess;
}

// Returns pointer to two events.
static cudaEvent_t* cuda_get_events(struct futhark_context *ctx, int *runs, int64_t *runtime) {
  if (ctx->profiling_records_used == ctx->profiling_records_capacity) {
    ctx->profiling_records_capacity *= 2;
    ctx->profiling_records =
      realloc(ctx->profiling_records,
              ctx->profiling_records_capacity *
              sizeof(struct profiling_record));
  }
  cudaEvent_t *events = calloc(2, sizeof(cudaEvent_t));
  cudaEventCreate(&events[0]);
  cudaEventCreate(&events[1]);
  ctx->profiling_records[ctx->profiling_records_used].events = events;
  ctx->profiling_records[ctx->profiling_records_used].runs = runs;
  ctx->profiling_records[ctx->profiling_records_used].runtime = runtime;
  ctx->profiling_records_used++;
  return events;
}

static CUresult cuda_alloc(struct futhark_context *ctx, FILE *log,
                           size_t min_size, const char *tag,
                           CUdeviceptr *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  if (free_list_find(&ctx->cu_free_list, min_size, tag, size_out, (fl_mem*)mem_out) == 0) {
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      return CUDA_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }

      CUresult res = cuMemFree(*mem_out);
      if (res != CUDA_SUCCESS) {
        return res;
      }
    }
  }

  *size_out = min_size;

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  CUresult res = cuMemAlloc(mem_out, min_size);
  while (res == CUDA_ERROR_OUT_OF_MEMORY) {
    CUdeviceptr mem;
    if (free_list_first(&ctx->cu_free_list, (fl_mem*)&mem) == 0) {
      res = cuMemFree(mem);
      if (res != CUDA_SUCCESS) {
        return res;
      }
    } else {
      break;
    }
    res = cuMemAlloc(mem_out, min_size);
  }

  return res;
}

static CUresult cuda_free(struct futhark_context *ctx,
                          CUdeviceptr mem, size_t size, const char *tag) {
  free_list_insert(&ctx->cu_free_list, size, (fl_mem)mem, tag);
  return CUDA_SUCCESS;
}

static CUresult cuda_free_all(struct futhark_context *ctx) {
  CUdeviceptr mem;
  free_list_pack(&ctx->cu_free_list);
  while (free_list_first(&ctx->cu_free_list, (fl_mem*)&mem) == 0) {
    CUresult res = cuMemFree(mem);
    if (res != CUDA_SUCCESS) {
      return res;
    }
  }

  return CUDA_SUCCESS;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }
  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

int backend_context_setup(struct futhark_context* ctx) {
  ctx->profiling_records_capacity = 200;
  ctx->profiling_records_used = 0;
  ctx->profiling_records =
    malloc(ctx->profiling_records_capacity *
           sizeof(struct profiling_record));
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;

  ctx->error = cuda_setup(ctx, cuda_program, ctx->cfg->nvrtc_opts, ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  set_tuning_params(ctx);
  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  cuMemFree(ctx->global_failure);
  cuMemFree(ctx->global_failure_args);
  CUDA_SUCCEED_FATAL(cuda_free_all(ctx));
  (void)cuda_tally_profiling_records(ctx);
  free(ctx->profiling_records);
  CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
  CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
}

// End of backends/cuda.h.

static char *get_failure_msg(int failure_idx, int64_t args[])
{
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 7:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 8:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 9:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 10:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 11:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 12:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 13:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 14:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 15:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 16:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 17:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 18:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 19:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 20:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 21:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 22:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 23:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 24:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 25:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 26:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 27:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:18:9-43\n   #1  main.fut:19:7-7\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 28:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  main.fut:99:24-41\n", args[0], args[1]);
            break;
        }
        
      case 29:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:99:44-64\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 30:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:99:67-87\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 31:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:99:90-110\n", args[0], args[1], args[2], args[3]);
            break;
        }
        
      case 32:
        {
            return msgprintf("Index [%lld, %lld] out of bounds for array of shape [%lld][%lld].\n-> #0  main.fut:99:113-133\n", args[0], args[1], args[2], args[3]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
static void set_tuning_params(struct futhark_context *ctx)
{
    ctx->tuning_params.builtinzhreplicate_boolzigroup_sizze_18801 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.builtinzhreplicate_i16zigroup_sizze_18761 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.builtinzhreplicate_i32zigroup_sizze_19068 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.builtinzhreplicate_i64zigroup_sizze_18781 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.segmap_group_sizze_14231 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.segmap_group_sizze_14275 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.segmap_group_sizze_14337 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.segmap_group_sizze_14423 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.segmap_group_sizze_14754 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.segmap_group_sizze_15014 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.segmap_group_sizze_15153 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.segmap_group_sizze_15426 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.segmap_num_groups_14233 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.segmap_num_groups_14756 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.segmap_num_groups_15016 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.segmap_num_groups_15155 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.segmap_num_groups_15428 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.segred_group_sizze_15459 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.segred_group_sizze_17182 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.segred_num_groups_15461 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.segred_num_groups_17184 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.suff_outer_par_0 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.suff_outer_par_1 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.suff_outer_par_2 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.suff_outer_par_3 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.tile_sizze_17460 = &ctx->cfg->tuning_params[25];
}
struct program {
    CUfunction builtinzhreplicate_boolzireplicate_18797;
    int64_t builtinzhreplicate_boolzireplicate_18797_total_runtime;
    int builtinzhreplicate_boolzireplicate_18797_runs;
    CUfunction builtinzhreplicate_i16zireplicate_18757;
    int64_t builtinzhreplicate_i16zireplicate_18757_total_runtime;
    int builtinzhreplicate_i16zireplicate_18757_runs;
    CUfunction builtinzhreplicate_i32zireplicate_19064;
    int64_t builtinzhreplicate_i32zireplicate_19064_total_runtime;
    int builtinzhreplicate_i32zireplicate_19064_runs;
    CUfunction builtinzhreplicate_i64zireplicate_18777;
    int64_t builtinzhreplicate_i64zireplicate_18777_total_runtime;
    int builtinzhreplicate_i64zireplicate_18777_runs;
    CUfunction gpu_map_transpose_bool;
    int64_t gpu_map_transpose_bool_total_runtime;
    int gpu_map_transpose_bool_runs;
    CUfunction gpu_map_transpose_bool_low_height;
    int64_t gpu_map_transpose_bool_low_height_total_runtime;
    int gpu_map_transpose_bool_low_height_runs;
    CUfunction gpu_map_transpose_bool_low_width;
    int64_t gpu_map_transpose_bool_low_width_total_runtime;
    int gpu_map_transpose_bool_low_width_runs;
    CUfunction gpu_map_transpose_bool_small;
    int64_t gpu_map_transpose_bool_small_total_runtime;
    int gpu_map_transpose_bool_small_runs;
    CUfunction gpu_map_transpose_i16;
    int64_t gpu_map_transpose_i16_total_runtime;
    int gpu_map_transpose_i16_runs;
    CUfunction gpu_map_transpose_i16_low_height;
    int64_t gpu_map_transpose_i16_low_height_total_runtime;
    int gpu_map_transpose_i16_low_height_runs;
    CUfunction gpu_map_transpose_i16_low_width;
    int64_t gpu_map_transpose_i16_low_width_total_runtime;
    int gpu_map_transpose_i16_low_width_runs;
    CUfunction gpu_map_transpose_i16_small;
    int64_t gpu_map_transpose_i16_small_total_runtime;
    int gpu_map_transpose_i16_small_runs;
    CUfunction gpuseq_18858;
    int64_t gpuseq_18858_total_runtime;
    int gpuseq_18858_runs;
    CUfunction gpuseq_19173;
    int64_t gpuseq_19173_total_runtime;
    int gpuseq_19173_runs;
    CUfunction segmap_14640;
    int64_t segmap_14640_total_runtime;
    int segmap_14640_runs;
    CUfunction segmap_14661;
    int64_t segmap_14661_total_runtime;
    int segmap_14661_runs;
    CUfunction segmap_14684;
    int64_t segmap_14684_total_runtime;
    int segmap_14684_runs;
    CUfunction segmap_14713;
    int64_t segmap_14713_total_runtime;
    int segmap_14713_runs;
    CUfunction segmap_14886;
    int64_t segmap_14886_total_runtime;
    int segmap_14886_runs;
    CUfunction segmap_16611;
    int64_t segmap_16611_total_runtime;
    int segmap_16611_runs;
    CUfunction segmap_16758;
    int64_t segmap_16758_total_runtime;
    int segmap_16758_runs;
    CUfunction segmap_17166;
    int64_t segmap_17166_total_runtime;
    int segmap_17166_runs;
    CUfunction segmap_intragroup_17459;
    int64_t segmap_intragroup_17459_total_runtime;
    int segmap_intragroup_17459_runs;
    CUfunction segred_large_17044;
    int64_t segred_large_17044_total_runtime;
    int segred_large_17044_runs;
    CUfunction segred_nonseg_17190;
    int64_t segred_nonseg_17190_total_runtime;
    int segred_nonseg_17190_runs;
    CUfunction segred_small_17044;
    int64_t segred_small_17044_total_runtime;
    int segred_small_17044_runs;
    int64_t copy_dev_to_dev_total_runtime;
    int copy_dev_to_dev_runs;
    int64_t copy_dev_to_host_total_runtime;
    int copy_dev_to_host_runs;
    int64_t copy_host_to_dev_total_runtime;
    int copy_host_to_dev_runs;
    int64_t copy_scalar_to_dev_total_runtime;
    int copy_scalar_to_dev_runs;
    int64_t copy_scalar_from_dev_total_runtime;
    int copy_scalar_from_dev_runs;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    ctx->program->builtinzhreplicate_boolzireplicate_18797_total_runtime = 0;
    ctx->program->builtinzhreplicate_boolzireplicate_18797_runs = 0;
    ctx->program->builtinzhreplicate_i16zireplicate_18757_total_runtime = 0;
    ctx->program->builtinzhreplicate_i16zireplicate_18757_runs = 0;
    ctx->program->builtinzhreplicate_i32zireplicate_19064_total_runtime = 0;
    ctx->program->builtinzhreplicate_i32zireplicate_19064_runs = 0;
    ctx->program->builtinzhreplicate_i64zireplicate_18777_total_runtime = 0;
    ctx->program->builtinzhreplicate_i64zireplicate_18777_runs = 0;
    ctx->program->gpu_map_transpose_bool_total_runtime = 0;
    ctx->program->gpu_map_transpose_bool_runs = 0;
    ctx->program->gpu_map_transpose_bool_low_height_total_runtime = 0;
    ctx->program->gpu_map_transpose_bool_low_height_runs = 0;
    ctx->program->gpu_map_transpose_bool_low_width_total_runtime = 0;
    ctx->program->gpu_map_transpose_bool_low_width_runs = 0;
    ctx->program->gpu_map_transpose_bool_small_total_runtime = 0;
    ctx->program->gpu_map_transpose_bool_small_runs = 0;
    ctx->program->gpu_map_transpose_i16_total_runtime = 0;
    ctx->program->gpu_map_transpose_i16_runs = 0;
    ctx->program->gpu_map_transpose_i16_low_height_total_runtime = 0;
    ctx->program->gpu_map_transpose_i16_low_height_runs = 0;
    ctx->program->gpu_map_transpose_i16_low_width_total_runtime = 0;
    ctx->program->gpu_map_transpose_i16_low_width_runs = 0;
    ctx->program->gpu_map_transpose_i16_small_total_runtime = 0;
    ctx->program->gpu_map_transpose_i16_small_runs = 0;
    ctx->program->gpuseq_18858_total_runtime = 0;
    ctx->program->gpuseq_18858_runs = 0;
    ctx->program->gpuseq_19173_total_runtime = 0;
    ctx->program->gpuseq_19173_runs = 0;
    ctx->program->segmap_14640_total_runtime = 0;
    ctx->program->segmap_14640_runs = 0;
    ctx->program->segmap_14661_total_runtime = 0;
    ctx->program->segmap_14661_runs = 0;
    ctx->program->segmap_14684_total_runtime = 0;
    ctx->program->segmap_14684_runs = 0;
    ctx->program->segmap_14713_total_runtime = 0;
    ctx->program->segmap_14713_runs = 0;
    ctx->program->segmap_14886_total_runtime = 0;
    ctx->program->segmap_14886_runs = 0;
    ctx->program->segmap_16611_total_runtime = 0;
    ctx->program->segmap_16611_runs = 0;
    ctx->program->segmap_16758_total_runtime = 0;
    ctx->program->segmap_16758_runs = 0;
    ctx->program->segmap_17166_total_runtime = 0;
    ctx->program->segmap_17166_runs = 0;
    ctx->program->segmap_intragroup_17459_total_runtime = 0;
    ctx->program->segmap_intragroup_17459_runs = 0;
    ctx->program->segred_large_17044_total_runtime = 0;
    ctx->program->segred_large_17044_runs = 0;
    ctx->program->segred_nonseg_17190_total_runtime = 0;
    ctx->program->segred_nonseg_17190_runs = 0;
    ctx->program->segred_small_17044_total_runtime = 0;
    ctx->program->segred_small_17044_runs = 0;
    ctx->program->copy_dev_to_dev_total_runtime = 0;
    ctx->program->copy_dev_to_dev_runs = 0;
    ctx->program->copy_dev_to_host_total_runtime = 0;
    ctx->program->copy_dev_to_host_runs = 0;
    ctx->program->copy_host_to_dev_total_runtime = 0;
    ctx->program->copy_host_to_dev_runs = 0;
    ctx->program->copy_scalar_to_dev_total_runtime = 0;
    ctx->program->copy_scalar_to_dev_runs = 0;
    ctx->program->copy_scalar_from_dev_total_runtime = 0;
    ctx->program->copy_scalar_from_dev_runs = 0;
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->builtinzhreplicate_boolzireplicate_18797, ctx->module, "builtinzhreplicate_boolzireplicate_18797"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->builtinzhreplicate_i16zireplicate_18757, ctx->module, "builtinzhreplicate_i16zireplicate_18757"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->builtinzhreplicate_i32zireplicate_19064, ctx->module, "builtinzhreplicate_i32zireplicate_19064"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->builtinzhreplicate_i64zireplicate_18777, ctx->module, "builtinzhreplicate_i64zireplicate_18777"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->gpu_map_transpose_bool, ctx->module, "gpu_map_transpose_bool"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->gpu_map_transpose_bool_low_height, ctx->module, "gpu_map_transpose_bool_low_height"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->gpu_map_transpose_bool_low_width, ctx->module, "gpu_map_transpose_bool_low_width"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->gpu_map_transpose_bool_small, ctx->module, "gpu_map_transpose_bool_small"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->gpu_map_transpose_i16, ctx->module, "gpu_map_transpose_i16"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->gpu_map_transpose_i16_low_height, ctx->module, "gpu_map_transpose_i16_low_height"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->gpu_map_transpose_i16_low_width, ctx->module, "gpu_map_transpose_i16_low_width"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->gpu_map_transpose_i16_small, ctx->module, "gpu_map_transpose_i16_small"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->gpuseq_18858, ctx->module, "gpuseq_18858"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->gpuseq_19173, ctx->module, "gpuseq_19173"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segmap_14640, ctx->module, "segmap_14640"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segmap_14661, ctx->module, "segmap_14661"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segmap_14684, ctx->module, "segmap_14684"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segmap_14713, ctx->module, "segmap_14713"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segmap_14886, ctx->module, "segmap_14886"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segmap_16611, ctx->module, "segmap_16611"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segmap_16758, ctx->module, "segmap_16758"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segmap_17166, ctx->module, "segmap_17166"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segmap_intragroup_17459, ctx->module, "segmap_intragroup_17459"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segred_large_17044, ctx->module, "segred_large_17044"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segred_nonseg_17190, ctx->module, "segred_nonseg_17190"));
    CUDA_SUCCEED_FATAL(cuModuleGetFunction(&ctx->program->segred_small_17044, ctx->module, "segred_small_17044"));
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    { }
    free(ctx->program);
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            CUDA_SUCCEED_OR_RETURN(cuda_free(ctx, block->mem, block->size, desc));
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (then allocated: %lld bytes)", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device + size);
    if (ctx->cur_mem_usage_device > ctx->peak_mem_usage_device) {
        ctx->peak_mem_usage_device = ctx->cur_mem_usage_device;
        if (ctx->detail_memory)
            fprintf(ctx->log, " (new peak).\n");
    } else if (ctx->detail_memory)
        fprintf(ctx->log, ".\n");
    ctx->error = CUDA_SUCCEED_NONFATAL(cuda_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size));
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        ctx->cur_mem_usage_device += size;
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (then allocated: %lld bytes)", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default + size);
    if (ctx->cur_mem_usage_default > ctx->peak_mem_usage_default) {
        ctx->peak_mem_usage_default = ctx->cur_mem_usage_default;
        if (ctx->detail_memory)
            fprintf(ctx->log, " (new peak).\n");
    } else if (ctx->detail_memory)
        fprintf(ctx->log, ".\n");
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        ctx->cur_mem_usage_default += size;
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag)
{
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag)
{
    cfg->profiling = flag;
}
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag)
{
    cfg->logging = flag;
}
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f)
{
    cfg->cache_fname = f;
}
int futhark_get_tuning_param_count(void)
{
    return num_tuning_params;
}
const char *futhark_get_tuning_param_name(int i)
{
    return tuning_param_names[i];
}
const char *futhark_get_tuning_param_class(int i)
{
    return tuning_param_classes[i];
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder(&builder, "Peak memory usage for space 'device': %lld bytes.\n", (long long) ctx->peak_mem_usage_device);
    { }
    if (ctx->profiling) {
        CUDA_SUCCEED_FATAL(cuda_tally_profiling_records(ctx));
        str_builder(&builder, "copy_dev_to_dev                        ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->copy_dev_to_dev_runs, (long) ctx->program->copy_dev_to_dev_total_runtime / (ctx->program->copy_dev_to_dev_runs != 0 ? ctx->program->copy_dev_to_dev_runs : 1), (long) ctx->program->copy_dev_to_dev_total_runtime);
        ctx->total_runtime += ctx->program->copy_dev_to_dev_total_runtime;
        ctx->total_runs += ctx->program->copy_dev_to_dev_runs;
        str_builder(&builder, "copy_dev_to_host                       ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->copy_dev_to_host_runs, (long) ctx->program->copy_dev_to_host_total_runtime / (ctx->program->copy_dev_to_host_runs != 0 ? ctx->program->copy_dev_to_host_runs : 1), (long) ctx->program->copy_dev_to_host_total_runtime);
        ctx->total_runtime += ctx->program->copy_dev_to_host_total_runtime;
        ctx->total_runs += ctx->program->copy_dev_to_host_runs;
        str_builder(&builder, "copy_host_to_dev                       ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->copy_host_to_dev_runs, (long) ctx->program->copy_host_to_dev_total_runtime / (ctx->program->copy_host_to_dev_runs != 0 ? ctx->program->copy_host_to_dev_runs : 1), (long) ctx->program->copy_host_to_dev_total_runtime);
        ctx->total_runtime += ctx->program->copy_host_to_dev_total_runtime;
        ctx->total_runs += ctx->program->copy_host_to_dev_runs;
        str_builder(&builder, "copy_scalar_to_dev                     ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->copy_scalar_to_dev_runs, (long) ctx->program->copy_scalar_to_dev_total_runtime / (ctx->program->copy_scalar_to_dev_runs != 0 ? ctx->program->copy_scalar_to_dev_runs : 1), (long) ctx->program->copy_scalar_to_dev_total_runtime);
        ctx->total_runtime += ctx->program->copy_scalar_to_dev_total_runtime;
        ctx->total_runs += ctx->program->copy_scalar_to_dev_runs;
        str_builder(&builder, "copy_scalar_from_dev                   ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->copy_scalar_from_dev_runs, (long) ctx->program->copy_scalar_from_dev_total_runtime / (ctx->program->copy_scalar_from_dev_runs != 0 ? ctx->program->copy_scalar_from_dev_runs : 1), (long) ctx->program->copy_scalar_from_dev_total_runtime);
        ctx->total_runtime += ctx->program->copy_scalar_from_dev_total_runtime;
        ctx->total_runs += ctx->program->copy_scalar_from_dev_runs;
        str_builder(&builder, "builtin#replicate_bool.replicate_18797 ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->builtinzhreplicate_boolzireplicate_18797_runs, (long) ctx->program->builtinzhreplicate_boolzireplicate_18797_total_runtime / (ctx->program->builtinzhreplicate_boolzireplicate_18797_runs != 0 ? ctx->program->builtinzhreplicate_boolzireplicate_18797_runs : 1), (long) ctx->program->builtinzhreplicate_boolzireplicate_18797_total_runtime);
        ctx->total_runtime += ctx->program->builtinzhreplicate_boolzireplicate_18797_total_runtime;
        ctx->total_runs += ctx->program->builtinzhreplicate_boolzireplicate_18797_runs;
        str_builder(&builder, "builtin#replicate_i16.replicate_18757  ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->builtinzhreplicate_i16zireplicate_18757_runs, (long) ctx->program->builtinzhreplicate_i16zireplicate_18757_total_runtime / (ctx->program->builtinzhreplicate_i16zireplicate_18757_runs != 0 ? ctx->program->builtinzhreplicate_i16zireplicate_18757_runs : 1), (long) ctx->program->builtinzhreplicate_i16zireplicate_18757_total_runtime);
        ctx->total_runtime += ctx->program->builtinzhreplicate_i16zireplicate_18757_total_runtime;
        ctx->total_runs += ctx->program->builtinzhreplicate_i16zireplicate_18757_runs;
        str_builder(&builder, "builtin#replicate_i32.replicate_19064  ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->builtinzhreplicate_i32zireplicate_19064_runs, (long) ctx->program->builtinzhreplicate_i32zireplicate_19064_total_runtime / (ctx->program->builtinzhreplicate_i32zireplicate_19064_runs != 0 ? ctx->program->builtinzhreplicate_i32zireplicate_19064_runs : 1), (long) ctx->program->builtinzhreplicate_i32zireplicate_19064_total_runtime);
        ctx->total_runtime += ctx->program->builtinzhreplicate_i32zireplicate_19064_total_runtime;
        ctx->total_runs += ctx->program->builtinzhreplicate_i32zireplicate_19064_runs;
        str_builder(&builder, "builtin#replicate_i64.replicate_18777  ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->builtinzhreplicate_i64zireplicate_18777_runs, (long) ctx->program->builtinzhreplicate_i64zireplicate_18777_total_runtime / (ctx->program->builtinzhreplicate_i64zireplicate_18777_runs != 0 ? ctx->program->builtinzhreplicate_i64zireplicate_18777_runs : 1), (long) ctx->program->builtinzhreplicate_i64zireplicate_18777_total_runtime);
        ctx->total_runtime += ctx->program->builtinzhreplicate_i64zireplicate_18777_total_runtime;
        ctx->total_runs += ctx->program->builtinzhreplicate_i64zireplicate_18777_runs;
        str_builder(&builder, "gpu_map_transpose_bool                 ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->gpu_map_transpose_bool_runs, (long) ctx->program->gpu_map_transpose_bool_total_runtime / (ctx->program->gpu_map_transpose_bool_runs != 0 ? ctx->program->gpu_map_transpose_bool_runs : 1), (long) ctx->program->gpu_map_transpose_bool_total_runtime);
        ctx->total_runtime += ctx->program->gpu_map_transpose_bool_total_runtime;
        ctx->total_runs += ctx->program->gpu_map_transpose_bool_runs;
        str_builder(&builder, "gpu_map_transpose_bool_low_height      ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->gpu_map_transpose_bool_low_height_runs, (long) ctx->program->gpu_map_transpose_bool_low_height_total_runtime / (ctx->program->gpu_map_transpose_bool_low_height_runs != 0 ? ctx->program->gpu_map_transpose_bool_low_height_runs : 1), (long) ctx->program->gpu_map_transpose_bool_low_height_total_runtime);
        ctx->total_runtime += ctx->program->gpu_map_transpose_bool_low_height_total_runtime;
        ctx->total_runs += ctx->program->gpu_map_transpose_bool_low_height_runs;
        str_builder(&builder, "gpu_map_transpose_bool_low_width       ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->gpu_map_transpose_bool_low_width_runs, (long) ctx->program->gpu_map_transpose_bool_low_width_total_runtime / (ctx->program->gpu_map_transpose_bool_low_width_runs != 0 ? ctx->program->gpu_map_transpose_bool_low_width_runs : 1), (long) ctx->program->gpu_map_transpose_bool_low_width_total_runtime);
        ctx->total_runtime += ctx->program->gpu_map_transpose_bool_low_width_total_runtime;
        ctx->total_runs += ctx->program->gpu_map_transpose_bool_low_width_runs;
        str_builder(&builder, "gpu_map_transpose_bool_small           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->gpu_map_transpose_bool_small_runs, (long) ctx->program->gpu_map_transpose_bool_small_total_runtime / (ctx->program->gpu_map_transpose_bool_small_runs != 0 ? ctx->program->gpu_map_transpose_bool_small_runs : 1), (long) ctx->program->gpu_map_transpose_bool_small_total_runtime);
        ctx->total_runtime += ctx->program->gpu_map_transpose_bool_small_total_runtime;
        ctx->total_runs += ctx->program->gpu_map_transpose_bool_small_runs;
        str_builder(&builder, "gpu_map_transpose_i16                  ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->gpu_map_transpose_i16_runs, (long) ctx->program->gpu_map_transpose_i16_total_runtime / (ctx->program->gpu_map_transpose_i16_runs != 0 ? ctx->program->gpu_map_transpose_i16_runs : 1), (long) ctx->program->gpu_map_transpose_i16_total_runtime);
        ctx->total_runtime += ctx->program->gpu_map_transpose_i16_total_runtime;
        ctx->total_runs += ctx->program->gpu_map_transpose_i16_runs;
        str_builder(&builder, "gpu_map_transpose_i16_low_height       ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->gpu_map_transpose_i16_low_height_runs, (long) ctx->program->gpu_map_transpose_i16_low_height_total_runtime / (ctx->program->gpu_map_transpose_i16_low_height_runs != 0 ? ctx->program->gpu_map_transpose_i16_low_height_runs : 1), (long) ctx->program->gpu_map_transpose_i16_low_height_total_runtime);
        ctx->total_runtime += ctx->program->gpu_map_transpose_i16_low_height_total_runtime;
        ctx->total_runs += ctx->program->gpu_map_transpose_i16_low_height_runs;
        str_builder(&builder, "gpu_map_transpose_i16_low_width        ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->gpu_map_transpose_i16_low_width_runs, (long) ctx->program->gpu_map_transpose_i16_low_width_total_runtime / (ctx->program->gpu_map_transpose_i16_low_width_runs != 0 ? ctx->program->gpu_map_transpose_i16_low_width_runs : 1), (long) ctx->program->gpu_map_transpose_i16_low_width_total_runtime);
        ctx->total_runtime += ctx->program->gpu_map_transpose_i16_low_width_total_runtime;
        ctx->total_runs += ctx->program->gpu_map_transpose_i16_low_width_runs;
        str_builder(&builder, "gpu_map_transpose_i16_small            ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->gpu_map_transpose_i16_small_runs, (long) ctx->program->gpu_map_transpose_i16_small_total_runtime / (ctx->program->gpu_map_transpose_i16_small_runs != 0 ? ctx->program->gpu_map_transpose_i16_small_runs : 1), (long) ctx->program->gpu_map_transpose_i16_small_total_runtime);
        ctx->total_runtime += ctx->program->gpu_map_transpose_i16_small_total_runtime;
        ctx->total_runs += ctx->program->gpu_map_transpose_i16_small_runs;
        str_builder(&builder, "gpuseq_18858                           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->gpuseq_18858_runs, (long) ctx->program->gpuseq_18858_total_runtime / (ctx->program->gpuseq_18858_runs != 0 ? ctx->program->gpuseq_18858_runs : 1), (long) ctx->program->gpuseq_18858_total_runtime);
        ctx->total_runtime += ctx->program->gpuseq_18858_total_runtime;
        ctx->total_runs += ctx->program->gpuseq_18858_runs;
        str_builder(&builder, "gpuseq_19173                           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->gpuseq_19173_runs, (long) ctx->program->gpuseq_19173_total_runtime / (ctx->program->gpuseq_19173_runs != 0 ? ctx->program->gpuseq_19173_runs : 1), (long) ctx->program->gpuseq_19173_total_runtime);
        ctx->total_runtime += ctx->program->gpuseq_19173_total_runtime;
        ctx->total_runs += ctx->program->gpuseq_19173_runs;
        str_builder(&builder, "segmap_14640                           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segmap_14640_runs, (long) ctx->program->segmap_14640_total_runtime / (ctx->program->segmap_14640_runs != 0 ? ctx->program->segmap_14640_runs : 1), (long) ctx->program->segmap_14640_total_runtime);
        ctx->total_runtime += ctx->program->segmap_14640_total_runtime;
        ctx->total_runs += ctx->program->segmap_14640_runs;
        str_builder(&builder, "segmap_14661                           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segmap_14661_runs, (long) ctx->program->segmap_14661_total_runtime / (ctx->program->segmap_14661_runs != 0 ? ctx->program->segmap_14661_runs : 1), (long) ctx->program->segmap_14661_total_runtime);
        ctx->total_runtime += ctx->program->segmap_14661_total_runtime;
        ctx->total_runs += ctx->program->segmap_14661_runs;
        str_builder(&builder, "segmap_14684                           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segmap_14684_runs, (long) ctx->program->segmap_14684_total_runtime / (ctx->program->segmap_14684_runs != 0 ? ctx->program->segmap_14684_runs : 1), (long) ctx->program->segmap_14684_total_runtime);
        ctx->total_runtime += ctx->program->segmap_14684_total_runtime;
        ctx->total_runs += ctx->program->segmap_14684_runs;
        str_builder(&builder, "segmap_14713                           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segmap_14713_runs, (long) ctx->program->segmap_14713_total_runtime / (ctx->program->segmap_14713_runs != 0 ? ctx->program->segmap_14713_runs : 1), (long) ctx->program->segmap_14713_total_runtime);
        ctx->total_runtime += ctx->program->segmap_14713_total_runtime;
        ctx->total_runs += ctx->program->segmap_14713_runs;
        str_builder(&builder, "segmap_14886                           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segmap_14886_runs, (long) ctx->program->segmap_14886_total_runtime / (ctx->program->segmap_14886_runs != 0 ? ctx->program->segmap_14886_runs : 1), (long) ctx->program->segmap_14886_total_runtime);
        ctx->total_runtime += ctx->program->segmap_14886_total_runtime;
        ctx->total_runs += ctx->program->segmap_14886_runs;
        str_builder(&builder, "segmap_16611                           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segmap_16611_runs, (long) ctx->program->segmap_16611_total_runtime / (ctx->program->segmap_16611_runs != 0 ? ctx->program->segmap_16611_runs : 1), (long) ctx->program->segmap_16611_total_runtime);
        ctx->total_runtime += ctx->program->segmap_16611_total_runtime;
        ctx->total_runs += ctx->program->segmap_16611_runs;
        str_builder(&builder, "segmap_16758                           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segmap_16758_runs, (long) ctx->program->segmap_16758_total_runtime / (ctx->program->segmap_16758_runs != 0 ? ctx->program->segmap_16758_runs : 1), (long) ctx->program->segmap_16758_total_runtime);
        ctx->total_runtime += ctx->program->segmap_16758_total_runtime;
        ctx->total_runs += ctx->program->segmap_16758_runs;
        str_builder(&builder, "segmap_17166                           ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segmap_17166_runs, (long) ctx->program->segmap_17166_total_runtime / (ctx->program->segmap_17166_runs != 0 ? ctx->program->segmap_17166_runs : 1), (long) ctx->program->segmap_17166_total_runtime);
        ctx->total_runtime += ctx->program->segmap_17166_total_runtime;
        ctx->total_runs += ctx->program->segmap_17166_runs;
        str_builder(&builder, "segmap_intragroup_17459                ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segmap_intragroup_17459_runs, (long) ctx->program->segmap_intragroup_17459_total_runtime / (ctx->program->segmap_intragroup_17459_runs != 0 ? ctx->program->segmap_intragroup_17459_runs : 1), (long) ctx->program->segmap_intragroup_17459_total_runtime);
        ctx->total_runtime += ctx->program->segmap_intragroup_17459_total_runtime;
        ctx->total_runs += ctx->program->segmap_intragroup_17459_runs;
        str_builder(&builder, "segred_large_17044                     ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segred_large_17044_runs, (long) ctx->program->segred_large_17044_total_runtime / (ctx->program->segred_large_17044_runs != 0 ? ctx->program->segred_large_17044_runs : 1), (long) ctx->program->segred_large_17044_total_runtime);
        ctx->total_runtime += ctx->program->segred_large_17044_total_runtime;
        ctx->total_runs += ctx->program->segred_large_17044_runs;
        str_builder(&builder, "segred_nonseg_17190                    ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segred_nonseg_17190_runs, (long) ctx->program->segred_nonseg_17190_total_runtime / (ctx->program->segred_nonseg_17190_runs != 0 ? ctx->program->segred_nonseg_17190_runs : 1), (long) ctx->program->segred_nonseg_17190_total_runtime);
        ctx->total_runtime += ctx->program->segred_nonseg_17190_total_runtime;
        ctx->total_runs += ctx->program->segred_nonseg_17190_runs;
        str_builder(&builder, "segred_small_17044                     ran %5d times; avg: %8ldus; total: %8ldus\n", ctx->program->segred_small_17044_runs, (long) ctx->program->segred_small_17044_total_runtime / (ctx->program->segred_small_17044_runs != 0 ? ctx->program->segred_small_17044_runs : 1), (long) ctx->program->segred_small_17044_total_runtime);
        ctx->total_runtime += ctx->program->segred_small_17044_total_runtime;
        ctx->total_runs += ctx->program->segred_small_17044_runs;
        str_builder(&builder, "%d operations with cumulative runtime: %6ldus\n", ctx->total_runs, ctx->total_runtime);
    }
    return builder.str;
}
char *futhark_context_get_error(struct futhark_context *ctx)
{
    char *error = ctx->error;
    
    ctx->error = NULL;
    return error;
}
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f)
{
    ctx->log = f;
}
void futhark_context_pause_profiling(struct futhark_context *ctx)
{
    ctx->profiling_paused = 1;
}
void futhark_context_unpause_profiling(struct futhark_context *ctx)
{
    ctx->profiling_paused = 0;
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        CUDA_SUCCEED_NONFATAL(cuda_free_all(ctx));
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Eventually it would be nice to move the context definition in here
// instead of generating it in the compiler.  For now it defines
// various helper functions that must be available.

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->detail_memory = cfg->debugging;
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  if (backend_context_setup(ctx) == 0) {
    setup_program(ctx);
    init_constants(ctx);
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  free_constants(ctx);
  teardown_program(ctx);
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  free(ctx->constants);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

static int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_19059, int64_t num_elems_19060, int32_t val_19061);
static int futrts_builtinzhgpu_map_transpose_i16(struct futhark_context *ctx, struct memblock_device destmem_0, int32_t destoffset_1, struct memblock_device srcmem_2, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6);
static int futrts_builtinzhgpu_map_transpose_bool(struct futhark_context *ctx, struct memblock_device destmem_0, int32_t destoffset_1, struct memblock_device srcmem_2, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6);
static int futrts_builtinzhreplicate_bool(struct futhark_context *ctx, struct memblock_device mem_18792, int64_t num_elems_18793, bool val_18794);
static int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_18772, int64_t num_elems_18773, int64_t val_18774);
static int futrts_builtinzhreplicate_i16(struct futhark_context *ctx, struct memblock_device mem_18752, int64_t num_elems_18753, int16_t val_18754);
static int futrts_entry_main(struct futhark_context *ctx, struct memblock_device *mem_out_p_19373, struct memblock_device *mem_out_p_19374, struct memblock_device *mem_out_p_19375, struct memblock_device *mem_out_p_19376, struct memblock_device *mem_out_p_19377, struct memblock_device *mem_out_p_19378, bool *out_prim_out_19379);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_19057 (ctx->constants->counters_mem_19057)
    #define counters_mem_19143 (ctx->constants->counters_mem_19143)
    #define main_res_8974 (ctx->constants->main_res_8974)
    #define mem_18296 (ctx->constants->mem_18296)
    #define triplayer2_9262 (ctx->constants->triplayer2_9262)
    #define triplayer3_9268 (ctx->constants->triplayer3_9268)
    #define triplayer4_9274 (ctx->constants->triplayer4_9274)
    #define triplayer5_9280 (ctx->constants->triplayer5_9280)
    
    struct memblock_device mem_param_tmp_18815;
    
    mem_param_tmp_18815.references = NULL;
    
    struct memblock_device mem_param_tmp_18814;
    
    mem_param_tmp_18814.references = NULL;
    
    struct memblock_device mem_param_tmp_18813;
    
    mem_param_tmp_18813.references = NULL;
    
    struct memblock_device mem_param_tmp_18812;
    
    mem_param_tmp_18812.references = NULL;
    
    struct memblock_device mem_param_tmp_18826;
    
    mem_param_tmp_18826.references = NULL;
    
    struct memblock_device mem_param_tmp_18825;
    
    mem_param_tmp_18825.references = NULL;
    
    struct memblock_device mem_param_tmp_18824;
    
    mem_param_tmp_18824.references = NULL;
    
    struct memblock_device mem_param_tmp_18823;
    
    mem_param_tmp_18823.references = NULL;
    
    struct memblock_device mem_param_tmp_18837;
    
    mem_param_tmp_18837.references = NULL;
    
    struct memblock_device mem_param_tmp_18836;
    
    mem_param_tmp_18836.references = NULL;
    
    struct memblock_device mem_param_tmp_18835;
    
    mem_param_tmp_18835.references = NULL;
    
    struct memblock_device mem_param_tmp_18834;
    
    mem_param_tmp_18834.references = NULL;
    
    struct memblock_device mem_param_tmp_18850;
    
    mem_param_tmp_18850.references = NULL;
    
    struct memblock_device mem_param_tmp_18849;
    
    mem_param_tmp_18849.references = NULL;
    
    struct memblock_device mem_param_tmp_18848;
    
    mem_param_tmp_18848.references = NULL;
    
    struct memblock_device mem_param_tmp_18847;
    
    mem_param_tmp_18847.references = NULL;
    
    struct memblock_device mem_param_tmp_18846;
    
    mem_param_tmp_18846.references = NULL;
    
    struct memblock_device mem_param_tmp_18845;
    
    mem_param_tmp_18845.references = NULL;
    
    struct memblock_device mem_18542;
    
    mem_18542.references = NULL;
    
    struct memblock_device mem_18540;
    
    mem_18540.references = NULL;
    
    struct memblock_device mem_18538;
    
    mem_18538.references = NULL;
    
    struct memblock_device mem_18536;
    
    mem_18536.references = NULL;
    
    struct memblock_device mem_18534;
    
    mem_18534.references = NULL;
    
    struct memblock_device mem_18532;
    
    mem_18532.references = NULL;
    
    struct memblock_device segred_tmp_mem_19145;
    
    segred_tmp_mem_19145.references = NULL;
    
    struct memblock_device mem_18436;
    
    mem_18436.references = NULL;
    
    struct memblock_device mem_18400;
    
    mem_18400.references = NULL;
    
    struct memblock_device segred_tmp_mem_19055;
    
    segred_tmp_mem_19055.references = NULL;
    
    struct memblock_device mem_18397;
    
    mem_18397.references = NULL;
    
    struct memblock_device mem_18434;
    
    mem_18434.references = NULL;
    
    struct memblock_device mem_18432;
    
    mem_18432.references = NULL;
    
    struct memblock_device ext_mem_18438;
    
    ext_mem_18438.references = NULL;
    
    struct memblock_device ext_mem_18439;
    
    ext_mem_18439.references = NULL;
    
    struct memblock_device mem_18454;
    
    mem_18454.references = NULL;
    
    struct memblock_device mem_18451;
    
    mem_18451.references = NULL;
    
    struct memblock_device mem_18449;
    
    mem_18449.references = NULL;
    
    struct memblock_device mem_18448;
    
    mem_18448.references = NULL;
    
    struct memblock_device ext_mem_18456;
    
    ext_mem_18456.references = NULL;
    
    struct memblock_device ext_mem_18457;
    
    ext_mem_18457.references = NULL;
    
    struct memblock_device mem_18482;
    
    mem_18482.references = NULL;
    
    struct memblock_device mem_18479;
    
    mem_18479.references = NULL;
    
    struct memblock_device mem_18477;
    
    mem_18477.references = NULL;
    
    struct memblock_device mem_18476;
    
    mem_18476.references = NULL;
    
    struct memblock_device ext_mem_18484;
    
    ext_mem_18484.references = NULL;
    
    struct memblock_device ext_mem_18485;
    
    ext_mem_18485.references = NULL;
    
    struct memblock_device mem_18524;
    
    mem_18524.references = NULL;
    
    struct memblock_device mem_18521;
    
    mem_18521.references = NULL;
    
    struct memblock_device mem_18519;
    
    mem_18519.references = NULL;
    
    struct memblock_device mem_18518;
    
    mem_18518.references = NULL;
    
    struct memblock_device ext_mem_18526;
    
    ext_mem_18526.references = NULL;
    
    struct memblock_device ext_mem_18527;
    
    ext_mem_18527.references = NULL;
    
    struct memblock_device mem_param_18392;
    
    mem_param_18392.references = NULL;
    
    struct memblock_device mem_param_18387;
    
    mem_param_18387.references = NULL;
    
    struct memblock_device mem_param_18382;
    
    mem_param_18382.references = NULL;
    
    struct memblock_device mem_param_18377;
    
    mem_param_18377.references = NULL;
    
    struct memblock_device mem_param_18372;
    
    mem_param_18372.references = NULL;
    
    struct memblock_device mem_param_18367;
    
    mem_param_18367.references = NULL;
    
    struct memblock_device ext_mem_18569;
    
    ext_mem_18569.references = NULL;
    
    struct memblock_device ext_mem_18570;
    
    ext_mem_18570.references = NULL;
    
    struct memblock_device ext_mem_18571;
    
    ext_mem_18571.references = NULL;
    
    struct memblock_device ext_mem_18572;
    
    ext_mem_18572.references = NULL;
    
    struct memblock_device ext_mem_18573;
    
    ext_mem_18573.references = NULL;
    
    struct memblock_device ext_mem_18574;
    
    ext_mem_18574.references = NULL;
    
    struct memblock_device mem_param_18362;
    
    mem_param_18362.references = NULL;
    
    struct memblock_device mem_param_18357;
    
    mem_param_18357.references = NULL;
    
    struct memblock_device mem_param_18352;
    
    mem_param_18352.references = NULL;
    
    struct memblock_device mem_param_18347;
    
    mem_param_18347.references = NULL;
    
    struct memblock_device ext_mem_18591;
    
    ext_mem_18591.references = NULL;
    
    struct memblock_device ext_mem_18592;
    
    ext_mem_18592.references = NULL;
    
    struct memblock_device ext_mem_18593;
    
    ext_mem_18593.references = NULL;
    
    struct memblock_device ext_mem_18594;
    
    ext_mem_18594.references = NULL;
    
    struct memblock_device mem_param_18342;
    
    mem_param_18342.references = NULL;
    
    struct memblock_device mem_param_18337;
    
    mem_param_18337.references = NULL;
    
    struct memblock_device mem_param_18332;
    
    mem_param_18332.references = NULL;
    
    struct memblock_device mem_param_18327;
    
    mem_param_18327.references = NULL;
    
    struct memblock_device ext_mem_18611;
    
    ext_mem_18611.references = NULL;
    
    struct memblock_device ext_mem_18612;
    
    ext_mem_18612.references = NULL;
    
    struct memblock_device ext_mem_18613;
    
    ext_mem_18613.references = NULL;
    
    struct memblock_device ext_mem_18614;
    
    ext_mem_18614.references = NULL;
    
    struct memblock_device mem_param_18322;
    
    mem_param_18322.references = NULL;
    
    struct memblock_device mem_param_18317;
    
    mem_param_18317.references = NULL;
    
    struct memblock_device mem_param_18312;
    
    mem_param_18312.references = NULL;
    
    struct memblock_device mem_param_18307;
    
    mem_param_18307.references = NULL;
    
    struct memblock_device ext_mem_18631;
    
    ext_mem_18631.references = NULL;
    
    struct memblock_device ext_mem_18632;
    
    ext_mem_18632.references = NULL;
    
    struct memblock_device ext_mem_18633;
    
    ext_mem_18633.references = NULL;
    
    struct memblock_device ext_mem_18634;
    
    ext_mem_18634.references = NULL;
    
    struct memblock_device mem_18544;
    
    mem_18544.references = NULL;
    
    struct memblock_device mem_18530;
    
    mem_18530.references = NULL;
    
    struct memblock_device mem_18394;
    
    mem_18394.references = NULL;
    
    struct memblock_device mem_18302;
    
    mem_18302.references = NULL;
    
    struct memblock_device mem_18300;
    
    mem_18300.references = NULL;
    
    struct memblock_device mem_18298;
    
    mem_18298.references = NULL;
    
    struct memblock_device mem_18292;
    
    mem_18292.references = NULL;
    
    struct memblock_device mem_18289;
    
    mem_18289.references = NULL;
    
    struct memblock_device mem_18286;
    
    mem_18286.references = NULL;
    
    struct memblock_device mem_18283;
    
    mem_18283.references = NULL;
    
    struct memblock_device mem_18281;
    
    mem_18281.references = NULL;
    counters_mem_19057.references = NULL;
    counters_mem_19143.references = NULL;
    mem_18296.references = NULL;
    if (memblock_alloc_device(ctx, &counters_mem_19057, (int64_t) 40960, "counters_mem_19057")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_19057, (int64_t) 10240, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_19143, (int64_t) 40, "counters_mem_19143")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_19143, (int64_t) 10, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18281, (int64_t) 2, "mem_18281")) {
        err = 1;
        goto cleanup;
    }
    
    struct memblock static_array_18677 = (struct memblock) {NULL, (unsigned char *) static_array_realtype_19179, 0, "static_array_18677"};
    
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_host_to_dev_runs, &ctx->program->copy_host_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(mem_18281.mem + (int64_t) 0, static_array_18677.mem + (int64_t) 0, (int64_t) 2));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (memblock_alloc_device(ctx, &mem_18283, (int64_t) 16, "mem_18283")) {
        err = 1;
        goto cleanup;
    }
    
    struct memblock static_array_18678 = (struct memblock) {NULL, (unsigned char *) static_array_realtype_19180, 0, "static_array_18678"};
    
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_host_to_dev_runs, &ctx->program->copy_host_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(mem_18283.mem + (int64_t) 0, static_array_18678.mem + (int64_t) 0, (int64_t) 16));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    
    int64_t segmap_group_sizze_14634;
    
    segmap_group_sizze_14634 = *ctx->tuning_params.segmap_group_sizze_14423;
    
    int64_t segmap_usable_groups_14635 = sdiv_up64((int64_t) 512, segmap_group_sizze_14634);
    
    if (memblock_alloc_device(ctx, &mem_18286, (int64_t) 512, "mem_18286")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_18679 = sext_i64_i32(sdiv_up64((int64_t) 512, segmap_group_sizze_14634));
    CUdeviceptr kernel_arg_19184 = mem_18281.mem;
    CUdeviceptr kernel_arg_19185 = mem_18286.mem;
    
    if ((((((1 && segmap_usable_groups_14635 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segmap_group_sizze_14423 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = segmap_usable_groups_14635;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_19181[] = {&ctx->global_failure, &kernel_arg_19184, &kernel_arg_19185};
        int64_t time_start_19182 = 0, time_end_19183 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segmap_14640", (long) segmap_usable_groups_14635, (long) 1, (long) 1, (long) *ctx->tuning_params.segmap_group_sizze_14423, (long) 1, (long) 1, (int) 0);
            time_start_19182 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->segmap_14640_runs, &ctx->program->segmap_14640_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segmap_14640, grid[0], grid[1], grid[2], *ctx->tuning_params.segmap_group_sizze_14423, 1, 1, 0, NULL, kernel_args_19181, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_19183 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segmap_14640", time_end_19183 - time_start_19182);
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segmap_group_sizze_14654;
    
    segmap_group_sizze_14654 = *ctx->tuning_params.segmap_group_sizze_14337;
    
    int64_t segmap_usable_groups_14655 = sdiv_up64((int64_t) 1024, segmap_group_sizze_14654);
    
    if (memblock_alloc_device(ctx, &mem_18289, (int64_t) 1024, "mem_18289")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_18692 = sext_i64_i32(sdiv_up64((int64_t) 1024, segmap_group_sizze_14654));
    CUdeviceptr kernel_arg_19189 = mem_18281.mem;
    CUdeviceptr kernel_arg_19190 = mem_18289.mem;
    
    if ((((((1 && segmap_usable_groups_14655 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segmap_group_sizze_14337 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = segmap_usable_groups_14655;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_19186[] = {&ctx->global_failure, &kernel_arg_19189, &kernel_arg_19190};
        int64_t time_start_19187 = 0, time_end_19188 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segmap_14661", (long) segmap_usable_groups_14655, (long) 1, (long) 1, (long) *ctx->tuning_params.segmap_group_sizze_14337, (long) 1, (long) 1, (int) 0);
            time_start_19187 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->segmap_14661_runs, &ctx->program->segmap_14661_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segmap_14661, grid[0], grid[1], grid[2], *ctx->tuning_params.segmap_group_sizze_14337, 1, 1, 0, NULL, kernel_args_19186, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_19188 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segmap_14661", time_end_19188 - time_start_19187);
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segmap_group_sizze_14676;
    
    segmap_group_sizze_14676 = *ctx->tuning_params.segmap_group_sizze_14275;
    
    int64_t segmap_usable_groups_14677 = sdiv_up64((int64_t) 16384, segmap_group_sizze_14676);
    
    if (memblock_alloc_device(ctx, &mem_18292, (int64_t) 16384, "mem_18292")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_18707 = sext_i64_i32(sdiv_up64((int64_t) 16384, segmap_group_sizze_14676));
    CUdeviceptr kernel_arg_19194 = mem_18283.mem;
    CUdeviceptr kernel_arg_19195 = mem_18286.mem;
    CUdeviceptr kernel_arg_19196 = mem_18289.mem;
    CUdeviceptr kernel_arg_19197 = mem_18292.mem;
    
    if ((((((1 && segmap_usable_groups_14677 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segmap_group_sizze_14275 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = segmap_usable_groups_14677;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_19191[] = {&ctx->global_failure, &kernel_arg_19194, &kernel_arg_19195, &kernel_arg_19196, &kernel_arg_19197};
        int64_t time_start_19192 = 0, time_end_19193 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segmap_14684", (long) segmap_usable_groups_14677, (long) 1, (long) 1, (long) *ctx->tuning_params.segmap_group_sizze_14275, (long) 1, (long) 1, (int) 0);
            time_start_19192 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->segmap_14684_runs, &ctx->program->segmap_14684_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segmap_14684, grid[0], grid[1], grid[2], *ctx->tuning_params.segmap_group_sizze_14275, 1, 1, 0, NULL, kernel_args_19191, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_19193 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segmap_14684", time_end_19193 - time_start_19192);
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_18286, "mem_18286") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18289, "mem_18289") != 0)
        return 1;
    
    int64_t segmap_group_sizze_14705;
    
    segmap_group_sizze_14705 = *ctx->tuning_params.segmap_group_sizze_14231;
    
    int64_t num_groups_14706;
    int32_t max_num_groups_18724;
    
    max_num_groups_18724 = *ctx->tuning_params.segmap_num_groups_14233;
    num_groups_14706 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64((int64_t) 1024, segmap_group_sizze_14705), sext_i32_i64(max_num_groups_18724))));
    if (memblock_alloc_device(ctx, &mem_18296, (int64_t) 4096, "mem_18296")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_18725 = sext_i64_i32(sdiv_up64((int64_t) 1024, segmap_group_sizze_14705));
    CUdeviceptr kernel_arg_19201 = mem_18281.mem;
    CUdeviceptr kernel_arg_19202 = mem_18283.mem;
    CUdeviceptr kernel_arg_19203 = mem_18296.mem;
    
    if ((((((1 && num_groups_14706 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segmap_group_sizze_14231 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = num_groups_14706;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_19198[] = {&ctx->global_failure, &num_groups_14706, &virt_num_groups_18725, &kernel_arg_19201, &kernel_arg_19202, &kernel_arg_19203};
        int64_t time_start_19199 = 0, time_end_19200 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segmap_14713", (long) num_groups_14706, (long) 1, (long) 1, (long) *ctx->tuning_params.segmap_group_sizze_14231, (long) 1, (long) 1, (int) 0);
            time_start_19199 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->segmap_14713_runs, &ctx->program->segmap_14713_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segmap_14713, grid[0], grid[1], grid[2], *ctx->tuning_params.segmap_group_sizze_14231, 1, 1, 0, NULL, kernel_args_19198, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_19200 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segmap_14713", time_end_19200 - time_start_19199);
        }
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_18281, "mem_18281") != 0)
        return 1;
    
    bool suff_outer_par_14750;
    
    suff_outer_par_14750 = *ctx->tuning_params.suff_outer_par_0 <= (int64_t) 128;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "suff_outer_par_0", (long) (int64_t) 128, suff_outer_par_14750 ? "true" : "false");
    
    int64_t segmap_group_sizze_16599;
    
    segmap_group_sizze_16599 = *ctx->tuning_params.segmap_group_sizze_15014;
    
    int64_t num_groups_16600;
    int32_t max_num_groups_18746;
    
    max_num_groups_18746 = *ctx->tuning_params.segmap_num_groups_15016;
    num_groups_16600 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64((int64_t) 16384, segmap_group_sizze_16599), sext_i32_i64(max_num_groups_18746))));
    
    bool suff_outer_par_16604;
    
    suff_outer_par_16604 = *ctx->tuning_params.suff_outer_par_1 <= (int64_t) 16384;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "suff_outer_par_1", (long) (int64_t) 16384, suff_outer_par_16604 ? "true" : "false");
    
    int64_t segmap_group_sizze_16744;
    
    segmap_group_sizze_16744 = *ctx->tuning_params.segmap_group_sizze_15153;
    
    int64_t num_groups_16745;
    int32_t max_num_groups_18747;
    
    max_num_groups_18747 = *ctx->tuning_params.segmap_num_groups_15155;
    num_groups_16745 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64((int64_t) 2097152, segmap_group_sizze_16744), sext_i32_i64(max_num_groups_18747))));
    
    bool suff_outer_par_16750;
    
    suff_outer_par_16750 = *ctx->tuning_params.suff_outer_par_2 <= (int64_t) 2097152;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "suff_outer_par_2", (long) (int64_t) 2097152, suff_outer_par_16750 ? "true" : "false");
    
    bool suff_outer_par_16897;
    
    suff_outer_par_16897 = *ctx->tuning_params.suff_outer_par_3 <= (int64_t) 268435456;
    if (ctx->logging)
        fprintf(ctx->log, "Compared %s <= %ld: %s.\n", "suff_outer_par_3", (long) (int64_t) 268435456, suff_outer_par_16897 ? "true" : "false");
    
    int64_t segred_group_sizze_17035;
    
    segred_group_sizze_17035 = *ctx->tuning_params.segred_group_sizze_15459;
    
    int64_t num_groups_17036;
    int32_t max_num_groups_18748;
    
    max_num_groups_18748 = *ctx->tuning_params.segred_num_groups_15461;
    num_groups_17036 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64((int64_t) 4294967296, segred_group_sizze_17035), sext_i32_i64(max_num_groups_18748))));
    
    int64_t segmap_group_sizze_17158;
    
    segmap_group_sizze_17158 = *ctx->tuning_params.segmap_group_sizze_15426;
    
    int64_t num_groups_17159;
    int32_t max_num_groups_18749;
    
    max_num_groups_18749 = *ctx->tuning_params.segmap_num_groups_15428;
    num_groups_17159 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64((int64_t) 268435456, segmap_group_sizze_17158), sext_i32_i64(max_num_groups_18749))));
    
    int64_t segmap_group_sizze_14880;
    
    segmap_group_sizze_14880 = *ctx->tuning_params.segmap_group_sizze_14754;
    
    int64_t num_groups_14881;
    int32_t max_num_groups_18750;
    
    max_num_groups_18750 = *ctx->tuning_params.segmap_num_groups_14756;
    num_groups_14881 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64((int64_t) 128, segmap_group_sizze_14880), sext_i32_i64(max_num_groups_18750))));
    
    int64_t segred_group_sizze_17183;
    
    segred_group_sizze_17183 = *ctx->tuning_params.segred_group_sizze_17182;
    
    int64_t num_groups_17185;
    int32_t max_num_groups_18751;
    
    max_num_groups_18751 = *ctx->tuning_params.segred_num_groups_17184;
    num_groups_17185 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64((int64_t) 268435456, segred_group_sizze_17183), sext_i32_i64(max_num_groups_18751))));
    
    int64_t tile_sizze_17461;
    
    tile_sizze_17461 = *ctx->tuning_params.tile_sizze_17460;
    
    int64_t ldim_17462 = sdiv_up_safe64((int64_t) 128, tile_sizze_17461);
    int64_t computed_num_groups_17465 = (int64_t) 2097152 * ldim_17462;
    int64_t num_whole_tiles_17493 = squot_safe64((int64_t) 16, tile_sizze_17461);
    int64_t residual_input_17822 = srem_safe64((int64_t) 16, tile_sizze_17461);
    bool cond_17823 = residual_input_17822 == (int64_t) 0;
    int64_t binop_x_17833 = tile_sizze_17461 * num_whole_tiles_17493;
    
    if (memblock_alloc_device(ctx, &mem_18298, (int64_t) 2, "mem_18298")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i16(ctx, mem_18298, (int64_t) 1, (int16_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18300, (int64_t) 8, "mem_18300")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_18300, (int64_t) 1, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18302, (int64_t) 1, "mem_18302")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_bool(ctx, mem_18302, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18394, (int64_t) 8, "mem_18394")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t bytes_18404 = (int64_t) 8 * tile_sizze_17461;
    int64_t bytes_18412 = smax64((int64_t) 0, tile_sizze_17461);
    
    if (memblock_alloc_device(ctx, &mem_18530, (int64_t) 8, "mem_18530")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_18544, (int64_t) 1, "mem_18544")) {
        err = 1;
        goto cleanup;
    }
    
    bool main_res_8972;
    int64_t main_res_8973;
    bool loop_while_8981;
    int64_t i3_8982;
    bool res1_8983;
    
    if (memblock_set_device(ctx, &mem_param_18307, &mem_18298, "mem_18298") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_18312, &mem_18298, "mem_18298") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_18317, &mem_18298, "mem_18298") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_param_18322, &mem_18298, "mem_18298") != 0)
        return 1;
    loop_while_8981 = 1;
    i3_8982 = (int64_t) 0;
    res1_8983 = 0;
    while (loop_while_8981) {
        int64_t arg_12396 = mul64((int64_t) 128, i3_8982);
        bool loopres_9001;
        int64_t loopres_9002;
        bool loopres_9003;
        bool loop_while_9010;
        int64_t i4_9011;
        bool res1_9012;
        
        if (memblock_set_device(ctx, &mem_param_18327, &mem_18298, "mem_18298") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_18332, &mem_18298, "mem_18298") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_18337, &mem_18298, "mem_18298") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_18342, &mem_18298, "mem_18298") != 0)
            return 1;
        loop_while_9010 = 1;
        i4_9011 = (int64_t) 0;
        res1_9012 = 0;
        while (loop_while_9010) {
            int64_t arg_12814 = mul64((int64_t) 128, i4_9011);
            bool loopres_9030;
            int64_t loopres_9031;
            bool loopres_9032;
            bool loop_while_9039;
            int64_t i5_9040;
            bool res1_9041;
            
            if (memblock_set_device(ctx, &mem_param_18347, &mem_18298, "mem_18298") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_18352, &mem_18298, "mem_18298") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_18357, &mem_18298, "mem_18298") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_18362, &mem_18298, "mem_18298") != 0)
                return 1;
            loop_while_9039 = 1;
            i5_9040 = (int64_t) 0;
            res1_9041 = 0;
            while (loop_while_9039) {
                int64_t arg_12818 = mul64((int64_t) 128, i5_9040);
                bool loopres_9059;
                bool loop_while_9068;
                
                if (memblock_set_device(ctx, &mem_param_18367, &mem_18300, "mem_18300") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_18372, &mem_18302, "mem_18302") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_18377, &mem_18298, "mem_18298") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_18382, &mem_18298, "mem_18298") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_18387, &mem_18298, "mem_18298") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_18392, &mem_18298, "mem_18298") != 0)
                    return 1;
                loop_while_9068 = 1;
                while (loop_while_9068) {
                    CUdeviceptr kernel_arg_19207 = mem_param_18367.mem;
                    CUdeviceptr kernel_arg_19208 = mem_18394.mem;
                    
                    if ((((((1 && (int64_t) 1 != 0) && 1 != 0) && 1 != 0) && (int64_t) 1 != 0) && 1 != 0) && 1 != 0) {
                        int perm[3] = {0, 1, 2};
                        
                        if (1 >= 1 << 16) {
                            perm[1] = perm[0];
                            perm[0] = 1;
                        }
                        if (1 >= 1 << 16) {
                            perm[2] = perm[0];
                            perm[0] = 2;
                        }
                        
                        size_t grid[3];
                        
                        grid[perm[0]] = (int64_t) 1;
                        grid[perm[1]] = 1;
                        grid[perm[2]] = 1;
                        
                        void *kernel_args_19204[] = {&ctx->global_failure, &kernel_arg_19207, &kernel_arg_19208};
                        int64_t time_start_19205 = 0, time_end_19206 = 0;
                        
                        if (ctx->debugging) {
                            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "gpuseq_18858", (long) (int64_t) 1, (long) 1, (long) 1, (long) (int64_t) 1, (long) 1, (long) 1, (int) 0);
                            time_start_19205 = get_wall_time();
                        }
                        
                        cudaEvent_t *pevents = NULL;
                        
                        if (ctx->profiling && !ctx->profiling_paused) {
                            pevents = cuda_get_events(ctx, &ctx->program->gpuseq_18858_runs, &ctx->program->gpuseq_18858_total_runtime);
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                        }
                        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->gpuseq_18858, grid[0], grid[1], grid[2], (int64_t) 1, 1, 1, 0, NULL, kernel_args_19204, NULL));
                        if (pevents != NULL)
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                        if (ctx->debugging) {
                            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                            time_end_19206 = get_wall_time();
                            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "gpuseq_18858", time_end_19206 - time_start_19205);
                        }
                    }
                    
                    int32_t local_memory_capacity_19142;
                    
                    local_memory_capacity_19142 = ctx->max_shared_memory;
                    if (suff_outer_par_14750 == 1 && sle64((int64_t) 0, sext_i32_i64(local_memory_capacity_19142))) {
                        if (memblock_alloc_device(ctx, &mem_18518, (int64_t) 268435456, "mem_18518")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_alloc_device(ctx, &mem_18519, (int64_t) 2147483648, "mem_18519")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "\n# SegMap");
                        
                        int32_t virt_num_groups_18864 = sext_i64_i32(sdiv_up64((int64_t) 128, segmap_group_sizze_14880));
                        CUdeviceptr kernel_arg_19212 = mem_18283.mem;
                        CUdeviceptr kernel_arg_19213 = mem_18292.mem;
                        CUdeviceptr kernel_arg_19214 = mem_18394.mem;
                        CUdeviceptr kernel_arg_19215 = mem_18518.mem;
                        CUdeviceptr kernel_arg_19216 = mem_18519.mem;
                        
                        if ((((((1 && num_groups_14881 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segmap_group_sizze_14754 != 0) && 1 != 0) && 1 != 0) {
                            int perm[3] = {0, 1, 2};
                            
                            if (1 >= 1 << 16) {
                                perm[1] = perm[0];
                                perm[0] = 1;
                            }
                            if (1 >= 1 << 16) {
                                perm[2] = perm[0];
                                perm[0] = 2;
                            }
                            
                            size_t grid[3];
                            
                            grid[perm[0]] = num_groups_14881;
                            grid[perm[1]] = 1;
                            grid[perm[2]] = 1;
                            
                            void *kernel_args_19209[] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg_12396, &arg_12814, &arg_12818, &num_groups_14881, &virt_num_groups_18864, &kernel_arg_19212, &kernel_arg_19213, &kernel_arg_19214, &kernel_arg_19215, &kernel_arg_19216};
                            int64_t time_start_19210 = 0, time_end_19211 = 0;
                            
                            if (ctx->debugging) {
                                fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segmap_14886", (long) num_groups_14881, (long) 1, (long) 1, (long) *ctx->tuning_params.segmap_group_sizze_14754, (long) 1, (long) 1, (int) 0);
                                time_start_19210 = get_wall_time();
                            }
                            
                            cudaEvent_t *pevents = NULL;
                            
                            if (ctx->profiling && !ctx->profiling_paused) {
                                pevents = cuda_get_events(ctx, &ctx->program->segmap_14886_runs, &ctx->program->segmap_14886_total_runtime);
                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                            }
                            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segmap_14886, grid[0], grid[1], grid[2], *ctx->tuning_params.segmap_group_sizze_14754, 1, 1, 0, NULL, kernel_args_19209, NULL));
                            if (pevents != NULL)
                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                            if (ctx->debugging) {
                                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                time_end_19211 = get_wall_time();
                                fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segmap_14886", time_end_19211 - time_start_19210);
                            }
                        }
                        ctx->failure_is_an_option = 1;
                        if (ctx->debugging)
                            fprintf(ctx->log, "%s\n", "");
                        if (memblock_alloc_device(ctx, &mem_18521, (int64_t) 268435456, "mem_18521")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (futrts_builtinzhgpu_map_transpose_bool(ctx, mem_18521, (int64_t) 0, mem_18518, (int64_t) 0, (int64_t) 1, (int64_t) 128, (int64_t) 2097152) != 0) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_unref_device(ctx, &mem_18518, "mem_18518") != 0)
                            return 1;
                        if (memblock_alloc_device(ctx, &mem_18524, (int64_t) 2147483648, "mem_18524")) {
                            err = 1;
                            goto cleanup;
                        }
                        if (futrts_builtinzhgpu_map_transpose_i16(ctx, mem_18524, (int64_t) 0, mem_18519, (int64_t) 0, (int64_t) 1, (int64_t) 128, (int64_t) 8388608) != 0) {
                            err = 1;
                            goto cleanup;
                        }
                        if (memblock_unref_device(ctx, &mem_18519, "mem_18519") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_18527, &mem_18521, "mem_18521") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_18526, &mem_18524, "mem_18524") != 0)
                            return 1;
                    } else {
                        int32_t local_memory_capacity_19141;
                        
                        local_memory_capacity_19141 = ctx->max_shared_memory;
                        if (suff_outer_par_16604 == 1 && sle64((int64_t) 0, sext_i32_i64(local_memory_capacity_19141))) {
                            if (memblock_alloc_device(ctx, &mem_18476, (int64_t) 268435456, "mem_18476")) {
                                err = 1;
                                goto cleanup;
                            }
                            if (memblock_alloc_device(ctx, &mem_18477, (int64_t) 2147483648, "mem_18477")) {
                                err = 1;
                                goto cleanup;
                            }
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "\n# SegMap");
                            
                            int32_t virt_num_groups_18895 = sext_i64_i32(sdiv_up64((int64_t) 16384, segmap_group_sizze_16599));
                            CUdeviceptr kernel_arg_19220 = mem_18283.mem;
                            CUdeviceptr kernel_arg_19221 = mem_18292.mem;
                            CUdeviceptr kernel_arg_19222 = mem_18394.mem;
                            CUdeviceptr kernel_arg_19223 = mem_18476.mem;
                            CUdeviceptr kernel_arg_19224 = mem_18477.mem;
                            
                            if ((((((1 && num_groups_16600 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segmap_group_sizze_15014 != 0) && 1 != 0) && 1 != 0) {
                                int perm[3] = {0, 1, 2};
                                
                                if (1 >= 1 << 16) {
                                    perm[1] = perm[0];
                                    perm[0] = 1;
                                }
                                if (1 >= 1 << 16) {
                                    perm[2] = perm[0];
                                    perm[0] = 2;
                                }
                                
                                size_t grid[3];
                                
                                grid[perm[0]] = num_groups_16600;
                                grid[perm[1]] = 1;
                                grid[perm[2]] = 1;
                                
                                void *kernel_args_19217[] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg_12396, &arg_12814, &arg_12818, &num_groups_16600, &virt_num_groups_18895, &kernel_arg_19220, &kernel_arg_19221, &kernel_arg_19222, &kernel_arg_19223, &kernel_arg_19224};
                                int64_t time_start_19218 = 0, time_end_19219 = 0;
                                
                                if (ctx->debugging) {
                                    fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segmap_16611", (long) num_groups_16600, (long) 1, (long) 1, (long) *ctx->tuning_params.segmap_group_sizze_15014, (long) 1, (long) 1, (int) 0);
                                    time_start_19218 = get_wall_time();
                                }
                                
                                cudaEvent_t *pevents = NULL;
                                
                                if (ctx->profiling && !ctx->profiling_paused) {
                                    pevents = cuda_get_events(ctx, &ctx->program->segmap_16611_runs, &ctx->program->segmap_16611_total_runtime);
                                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                                }
                                CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segmap_16611, grid[0], grid[1], grid[2], *ctx->tuning_params.segmap_group_sizze_15014, 1, 1, 0, NULL, kernel_args_19217, NULL));
                                if (pevents != NULL)
                                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                                if (ctx->debugging) {
                                    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                    time_end_19219 = get_wall_time();
                                    fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segmap_16611", time_end_19219 - time_start_19218);
                                }
                            }
                            ctx->failure_is_an_option = 1;
                            if (ctx->debugging)
                                fprintf(ctx->log, "%s\n", "");
                            if (memblock_alloc_device(ctx, &mem_18479, (int64_t) 268435456, "mem_18479")) {
                                err = 1;
                                goto cleanup;
                            }
                            if (futrts_builtinzhgpu_map_transpose_bool(ctx, mem_18479, (int64_t) 0, mem_18476, (int64_t) 0, (int64_t) 1, (int64_t) 16384, (int64_t) 16384) != 0) {
                                err = 1;
                                goto cleanup;
                            }
                            if (memblock_unref_device(ctx, &mem_18476, "mem_18476") != 0)
                                return 1;
                            if (memblock_alloc_device(ctx, &mem_18482, (int64_t) 2147483648, "mem_18482")) {
                                err = 1;
                                goto cleanup;
                            }
                            if (futrts_builtinzhgpu_map_transpose_i16(ctx, mem_18482, (int64_t) 0, mem_18477, (int64_t) 0, (int64_t) 1, (int64_t) 16384, (int64_t) 65536) != 0) {
                                err = 1;
                                goto cleanup;
                            }
                            if (memblock_unref_device(ctx, &mem_18477, "mem_18477") != 0)
                                return 1;
                            if (memblock_set_device(ctx, &ext_mem_18485, &mem_18479, "mem_18479") != 0)
                                return 1;
                            if (memblock_set_device(ctx, &ext_mem_18484, &mem_18482, "mem_18482") != 0)
                                return 1;
                        } else {
                            int32_t local_memory_capacity_19140;
                            
                            local_memory_capacity_19140 = ctx->max_shared_memory;
                            if (suff_outer_par_16750 == 1 && sle64((int64_t) 0, sext_i32_i64(local_memory_capacity_19140))) {
                                if (memblock_alloc_device(ctx, &mem_18448, (int64_t) 268435456, "mem_18448")) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (memblock_alloc_device(ctx, &mem_18449, (int64_t) 2147483648, "mem_18449")) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (ctx->debugging)
                                    fprintf(ctx->log, "%s\n", "\n# SegMap");
                                
                                int32_t virt_num_groups_18924 = sext_i64_i32(sdiv_up64((int64_t) 2097152, segmap_group_sizze_16744));
                                CUdeviceptr kernel_arg_19228 = mem_18283.mem;
                                CUdeviceptr kernel_arg_19229 = mem_18292.mem;
                                CUdeviceptr kernel_arg_19230 = mem_18394.mem;
                                CUdeviceptr kernel_arg_19231 = mem_18448.mem;
                                CUdeviceptr kernel_arg_19232 = mem_18449.mem;
                                
                                if ((((((1 && num_groups_16745 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segmap_group_sizze_15153 != 0) && 1 != 0) && 1 != 0) {
                                    int perm[3] = {0, 1, 2};
                                    
                                    if (1 >= 1 << 16) {
                                        perm[1] = perm[0];
                                        perm[0] = 1;
                                    }
                                    if (1 >= 1 << 16) {
                                        perm[2] = perm[0];
                                        perm[0] = 2;
                                    }
                                    
                                    size_t grid[3];
                                    
                                    grid[perm[0]] = num_groups_16745;
                                    grid[perm[1]] = 1;
                                    grid[perm[2]] = 1;
                                    
                                    void *kernel_args_19225[] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg_12396, &arg_12814, &arg_12818, &num_groups_16745, &virt_num_groups_18924, &kernel_arg_19228, &kernel_arg_19229, &kernel_arg_19230, &kernel_arg_19231, &kernel_arg_19232};
                                    int64_t time_start_19226 = 0, time_end_19227 = 0;
                                    
                                    if (ctx->debugging) {
                                        fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segmap_16758", (long) num_groups_16745, (long) 1, (long) 1, (long) *ctx->tuning_params.segmap_group_sizze_15153, (long) 1, (long) 1, (int) 0);
                                        time_start_19226 = get_wall_time();
                                    }
                                    
                                    cudaEvent_t *pevents = NULL;
                                    
                                    if (ctx->profiling && !ctx->profiling_paused) {
                                        pevents = cuda_get_events(ctx, &ctx->program->segmap_16758_runs, &ctx->program->segmap_16758_total_runtime);
                                        CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                                    }
                                    CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segmap_16758, grid[0], grid[1], grid[2], *ctx->tuning_params.segmap_group_sizze_15153, 1, 1, 0, NULL, kernel_args_19225, NULL));
                                    if (pevents != NULL)
                                        CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                                    if (ctx->debugging) {
                                        CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                        time_end_19227 = get_wall_time();
                                        fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segmap_16758", time_end_19227 - time_start_19226);
                                    }
                                }
                                ctx->failure_is_an_option = 1;
                                if (ctx->debugging)
                                    fprintf(ctx->log, "%s\n", "");
                                if (memblock_alloc_device(ctx, &mem_18451, (int64_t) 268435456, "mem_18451")) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (futrts_builtinzhgpu_map_transpose_bool(ctx, mem_18451, (int64_t) 0, mem_18448, (int64_t) 0, (int64_t) 1, (int64_t) 2097152, (int64_t) 128) != 0) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (memblock_unref_device(ctx, &mem_18448, "mem_18448") != 0)
                                    return 1;
                                if (memblock_alloc_device(ctx, &mem_18454, (int64_t) 2147483648, "mem_18454")) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (futrts_builtinzhgpu_map_transpose_i16(ctx, mem_18454, (int64_t) 0, mem_18449, (int64_t) 0, (int64_t) 1, (int64_t) 2097152, (int64_t) 512) != 0) {
                                    err = 1;
                                    goto cleanup;
                                }
                                if (memblock_unref_device(ctx, &mem_18449, "mem_18449") != 0)
                                    return 1;
                                if (memblock_set_device(ctx, &ext_mem_18457, &mem_18451, "mem_18451") != 0)
                                    return 1;
                                if (memblock_set_device(ctx, &ext_mem_18456, &mem_18454, "mem_18454") != 0)
                                    return 1;
                            } else {
                                int32_t local_memory_capacity_19139;
                                
                                local_memory_capacity_19139 = ctx->max_shared_memory;
                                if (suff_outer_par_16897 == 1 && sle64(bytes_18412 + srem64((int64_t) 8 - srem64(bytes_18412, (int64_t) 8), (int64_t) 8), sext_i32_i64(local_memory_capacity_19139))) {
                                    if (memblock_alloc_device(ctx, &mem_18432, (int64_t) 268435456, "mem_18432")) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    if (memblock_alloc_device(ctx, &mem_18434, (int64_t) 2147483648, "mem_18434")) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    if (ctx->debugging)
                                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                                    
                                    int32_t num_chunks_18951 = sext_i64_i32(sdiv_up64(tile_sizze_17461, tile_sizze_17461));
                                    int32_t virt_num_groups_18952 = sext_i64_i32((int64_t) 2097152 * ldim_17462);
                                    unsigned int shared_sizze_19236 = bytes_18412;
                                    CUdeviceptr kernel_arg_19238 = mem_18283.mem;
                                    CUdeviceptr kernel_arg_19239 = mem_18292.mem;
                                    CUdeviceptr kernel_arg_19240 = mem_18394.mem;
                                    CUdeviceptr kernel_arg_19241 = mem_18432.mem;
                                    CUdeviceptr kernel_arg_19242 = mem_18434.mem;
                                    unsigned int shared_offset_19237 = 0;
                                    
                                    if ((((((1 && computed_num_groups_17465 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.tile_sizze_17460 != 0) && 1 != 0) && 1 != 0) {
                                        int perm[3] = {0, 1, 2};
                                        
                                        if (1 >= 1 << 16) {
                                            perm[1] = perm[0];
                                            perm[0] = 1;
                                        }
                                        if (1 >= 1 << 16) {
                                            perm[2] = perm[0];
                                            perm[0] = 2;
                                        }
                                        
                                        size_t grid[3];
                                        
                                        grid[perm[0]] = computed_num_groups_17465;
                                        grid[perm[1]] = 1;
                                        grid[perm[2]] = 1;
                                        
                                        void *kernel_args_19233[] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &shared_offset_19237, &arg_12396, &arg_12814, &arg_12818, &kernel_arg_19238, &kernel_arg_19239, &kernel_arg_19240, &kernel_arg_19241, &kernel_arg_19242};
                                        int64_t time_start_19234 = 0, time_end_19235 = 0;
                                        
                                        if (ctx->debugging) {
                                            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segmap_intragroup_17459", (long) computed_num_groups_17465, (long) 1, (long) 1, (long) *ctx->tuning_params.tile_sizze_17460, (long) 1, (long) 1, (int) (0 + (shared_sizze_19236 + (8 - shared_sizze_19236 % 8) % 8)));
                                            time_start_19234 = get_wall_time();
                                        }
                                        
                                        cudaEvent_t *pevents = NULL;
                                        
                                        if (ctx->profiling && !ctx->profiling_paused) {
                                            pevents = cuda_get_events(ctx, &ctx->program->segmap_intragroup_17459_runs, &ctx->program->segmap_intragroup_17459_total_runtime);
                                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                                        }
                                        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segmap_intragroup_17459, grid[0], grid[1], grid[2], *ctx->tuning_params.tile_sizze_17460, 1, 1, 0 + (shared_sizze_19236 + (8 - shared_sizze_19236 % 8) % 8), NULL, kernel_args_19233, NULL));
                                        if (pevents != NULL)
                                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                                        if (ctx->debugging) {
                                            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                            time_end_19235 = get_wall_time();
                                            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segmap_intragroup_17459", time_end_19235 - time_start_19234);
                                        }
                                    }
                                    ctx->failure_is_an_option = 1;
                                    if (ctx->debugging)
                                        fprintf(ctx->log, "%s\n", "");
                                    if (memblock_set_device(ctx, &ext_mem_18439, &mem_18432, "mem_18432") != 0)
                                        return 1;
                                    if (memblock_set_device(ctx, &ext_mem_18438, &mem_18434, "mem_18434") != 0)
                                        return 1;
                                } else {
                                    if (memblock_alloc_device(ctx, &mem_18397, (int64_t) 268435456, "mem_18397")) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    if (slt64((int64_t) 32, segred_group_sizze_17035)) {
                                        int64_t segment_sizze_nonzzero_19016 = smax64((int64_t) 1, (int64_t) 16);
                                        int64_t num_threads_19017 = num_groups_17036 * segred_group_sizze_17035;
                                        
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s\n", "\n# SegRed-small");
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (int64_t) 268435456, '\n');
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) (int64_t) 16, '\n');
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "segments_per_group", (long long) squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016), '\n');
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "required_groups", (long long) sext_i64_i32(sdiv_up64((int64_t) 268435456, squot64(segred_group_sizze_17035, segment_sizze_nonzzero_19016))), '\n');
                                        
                                        unsigned int shared_sizze_19246 = segred_group_sizze_17035;
                                        CUdeviceptr kernel_arg_19248 = mem_18283.mem;
                                        CUdeviceptr kernel_arg_19249 = mem_18292.mem;
                                        CUdeviceptr kernel_arg_19250 = mem_18394.mem;
                                        CUdeviceptr kernel_arg_19251 = mem_18397.mem;
                                        unsigned int shared_offset_19247 = 0;
                                        
                                        if ((((((1 && num_groups_17036 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segred_group_sizze_15459 != 0) && 1 != 0) && 1 != 0) {
                                            int perm[3] = {0, 1, 2};
                                            
                                            if (1 >= 1 << 16) {
                                                perm[1] = perm[0];
                                                perm[0] = 1;
                                            }
                                            if (1 >= 1 << 16) {
                                                perm[2] = perm[0];
                                                perm[0] = 2;
                                            }
                                            
                                            size_t grid[3];
                                            
                                            grid[perm[0]] = num_groups_17036;
                                            grid[perm[1]] = 1;
                                            grid[perm[2]] = 1;
                                            
                                            void *kernel_args_19243[] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &shared_offset_19247, &arg_12396, &arg_12814, &arg_12818, &num_groups_17036, &segment_sizze_nonzzero_19016, &kernel_arg_19248, &kernel_arg_19249, &kernel_arg_19250, &kernel_arg_19251};
                                            int64_t time_start_19244 = 0, time_end_19245 = 0;
                                            
                                            if (ctx->debugging) {
                                                fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segred_small_17044", (long) num_groups_17036, (long) 1, (long) 1, (long) *ctx->tuning_params.segred_group_sizze_15459, (long) 1, (long) 1, (int) (0 + (shared_sizze_19246 + (8 - shared_sizze_19246 % 8) % 8)));
                                                time_start_19244 = get_wall_time();
                                            }
                                            
                                            cudaEvent_t *pevents = NULL;
                                            
                                            if (ctx->profiling && !ctx->profiling_paused) {
                                                pevents = cuda_get_events(ctx, &ctx->program->segred_small_17044_runs, &ctx->program->segred_small_17044_total_runtime);
                                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                                            }
                                            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segred_small_17044, grid[0], grid[1], grid[2], *ctx->tuning_params.segred_group_sizze_15459, 1, 1, 0 + (shared_sizze_19246 + (8 - shared_sizze_19246 % 8) % 8), NULL, kernel_args_19243, NULL));
                                            if (pevents != NULL)
                                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                                            if (ctx->debugging) {
                                                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                                time_end_19245 = get_wall_time();
                                                fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segred_small_17044", time_end_19245 - time_start_19244);
                                            }
                                        }
                                        ctx->failure_is_an_option = 1;
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s\n", "");
                                    } else {
                                        int64_t groups_per_segment_19050 = sdiv_up64(num_groups_17036, smax64((int64_t) 1, (int64_t) 268435456));
                                        int64_t elements_per_thread_19051 = sdiv_up64((int64_t) 16, segred_group_sizze_17035 * groups_per_segment_19050);
                                        int64_t virt_num_groups_19052 = groups_per_segment_19050 * (int64_t) 268435456;
                                        int64_t num_threads_19053 = num_groups_17036 * segred_group_sizze_17035;
                                        int64_t threads_per_segment_19054 = groups_per_segment_19050 * segred_group_sizze_17035;
                                        
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s\n", "\n# SegRed-large");
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "num_segments", (long long) (int64_t) 268435456, '\n');
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "segment_size", (long long) (int64_t) 16, '\n');
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "virt_num_groups", (long long) virt_num_groups_19052, '\n');
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "num_groups", (long long) num_groups_17036, '\n');
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "group_size", (long long) segred_group_sizze_17035, '\n');
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "elems_per_thread", (long long) elements_per_thread_19051, '\n');
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s: %llu%c", "groups_per_segment", (long long) groups_per_segment_19050, '\n');
                                        if (memblock_alloc_device(ctx, &segred_tmp_mem_19055, virt_num_groups_19052, "segred_tmp_mem_19055")) {
                                            err = 1;
                                            goto cleanup;
                                        }
                                        
                                        unsigned int shared_sizze_19255 = 1;
                                        unsigned int shared_sizze_19257 = segred_group_sizze_17035;
                                        CUdeviceptr kernel_arg_19259 = mem_18283.mem;
                                        CUdeviceptr kernel_arg_19260 = mem_18292.mem;
                                        CUdeviceptr kernel_arg_19261 = mem_18394.mem;
                                        CUdeviceptr kernel_arg_19262 = mem_18397.mem;
                                        CUdeviceptr kernel_arg_19263 = segred_tmp_mem_19055.mem;
                                        CUdeviceptr kernel_arg_19264 = counters_mem_19057.mem;
                                        unsigned int shared_offset_19256 = 0;
                                        unsigned int shared_offset_19258 = 0 + (shared_sizze_19255 + (8 - shared_sizze_19255 % 8) % 8);
                                        
                                        if ((((((1 && num_groups_17036 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segred_group_sizze_15459 != 0) && 1 != 0) && 1 != 0) {
                                            int perm[3] = {0, 1, 2};
                                            
                                            if (1 >= 1 << 16) {
                                                perm[1] = perm[0];
                                                perm[0] = 1;
                                            }
                                            if (1 >= 1 << 16) {
                                                perm[2] = perm[0];
                                                perm[0] = 2;
                                            }
                                            
                                            size_t grid[3];
                                            
                                            grid[perm[0]] = num_groups_17036;
                                            grid[perm[1]] = 1;
                                            grid[perm[2]] = 1;
                                            
                                            void *kernel_args_19252[] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &shared_offset_19256, &shared_offset_19258, &arg_12396, &arg_12814, &arg_12818, &num_groups_17036, &groups_per_segment_19050, &elements_per_thread_19051, &virt_num_groups_19052, &threads_per_segment_19054, &kernel_arg_19259, &kernel_arg_19260, &kernel_arg_19261, &kernel_arg_19262, &kernel_arg_19263, &kernel_arg_19264};
                                            int64_t time_start_19253 = 0, time_end_19254 = 0;
                                            
                                            if (ctx->debugging) {
                                                fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segred_large_17044", (long) num_groups_17036, (long) 1, (long) 1, (long) *ctx->tuning_params.segred_group_sizze_15459, (long) 1, (long) 1, (int) (0 + (shared_sizze_19255 + (8 - shared_sizze_19255 % 8) % 8) + (shared_sizze_19257 + (8 - shared_sizze_19257 % 8) % 8)));
                                                time_start_19253 = get_wall_time();
                                            }
                                            
                                            cudaEvent_t *pevents = NULL;
                                            
                                            if (ctx->profiling && !ctx->profiling_paused) {
                                                pevents = cuda_get_events(ctx, &ctx->program->segred_large_17044_runs, &ctx->program->segred_large_17044_total_runtime);
                                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                                            }
                                            CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segred_large_17044, grid[0], grid[1], grid[2], *ctx->tuning_params.segred_group_sizze_15459, 1, 1, 0 + (shared_sizze_19255 + (8 - shared_sizze_19255 % 8) % 8) + (shared_sizze_19257 + (8 - shared_sizze_19257 % 8) % 8), NULL, kernel_args_19252, NULL));
                                            if (pevents != NULL)
                                                CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                                            if (ctx->debugging) {
                                                CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                                time_end_19254 = get_wall_time();
                                                fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segred_large_17044", time_end_19254 - time_start_19253);
                                            }
                                        }
                                        ctx->failure_is_an_option = 1;
                                        if (ctx->debugging)
                                            fprintf(ctx->log, "%s\n", "");
                                    }
                                    if (memblock_alloc_device(ctx, &mem_18400, (int64_t) 2147483648, "mem_18400")) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    if (ctx->debugging)
                                        fprintf(ctx->log, "%s\n", "\n# SegMap");
                                    
                                    int32_t virt_num_groups_19118 = sext_i64_i32(sdiv_up64((int64_t) 268435456, segmap_group_sizze_17158));
                                    CUdeviceptr kernel_arg_19268 = mem_18394.mem;
                                    CUdeviceptr kernel_arg_19269 = mem_18400.mem;
                                    
                                    if ((((((1 && num_groups_17159 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segmap_group_sizze_15426 != 0) && 1 != 0) && 1 != 0) {
                                        int perm[3] = {0, 1, 2};
                                        
                                        if (1 >= 1 << 16) {
                                            perm[1] = perm[0];
                                            perm[0] = 1;
                                        }
                                        if (1 >= 1 << 16) {
                                            perm[2] = perm[0];
                                            perm[0] = 2;
                                        }
                                        
                                        size_t grid[3];
                                        
                                        grid[perm[0]] = num_groups_17159;
                                        grid[perm[1]] = 1;
                                        grid[perm[2]] = 1;
                                        
                                        void *kernel_args_19265[] = {&ctx->global_failure, &arg_12396, &arg_12814, &arg_12818, &num_groups_17159, &virt_num_groups_19118, &kernel_arg_19268, &kernel_arg_19269};
                                        int64_t time_start_19266 = 0, time_end_19267 = 0;
                                        
                                        if (ctx->debugging) {
                                            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segmap_17166", (long) num_groups_17159, (long) 1, (long) 1, (long) *ctx->tuning_params.segmap_group_sizze_15426, (long) 1, (long) 1, (int) 0);
                                            time_start_19266 = get_wall_time();
                                        }
                                        
                                        cudaEvent_t *pevents = NULL;
                                        
                                        if (ctx->profiling && !ctx->profiling_paused) {
                                            pevents = cuda_get_events(ctx, &ctx->program->segmap_17166_runs, &ctx->program->segmap_17166_total_runtime);
                                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                                        }
                                        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segmap_17166, grid[0], grid[1], grid[2], *ctx->tuning_params.segmap_group_sizze_15426, 1, 1, 0, NULL, kernel_args_19265, NULL));
                                        if (pevents != NULL)
                                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                                        if (ctx->debugging) {
                                            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                                            time_end_19267 = get_wall_time();
                                            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segmap_17166", time_end_19267 - time_start_19266);
                                        }
                                    }
                                    if (ctx->debugging)
                                        fprintf(ctx->log, "%s\n", "");
                                    if (memblock_alloc_device(ctx, &mem_18436, (int64_t) 2147483648, "mem_18436")) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    if (futrts_builtinzhgpu_map_transpose_i16(ctx, mem_18436, (int64_t) 0, mem_18400, (int64_t) 0, (int64_t) 1, (int64_t) 268435456, (int64_t) 4) != 0) {
                                        err = 1;
                                        goto cleanup;
                                    }
                                    if (memblock_unref_device(ctx, &mem_18400, "mem_18400") != 0)
                                        return 1;
                                    if (memblock_set_device(ctx, &ext_mem_18439, &mem_18397, "mem_18397") != 0)
                                        return 1;
                                    if (memblock_set_device(ctx, &ext_mem_18438, &mem_18436, "mem_18436") != 0)
                                        return 1;
                                }
                                if (memblock_set_device(ctx, &ext_mem_18457, &ext_mem_18439, "ext_mem_18439") != 0)
                                    return 1;
                                if (memblock_set_device(ctx, &ext_mem_18456, &ext_mem_18438, "ext_mem_18438") != 0)
                                    return 1;
                            }
                            if (memblock_set_device(ctx, &ext_mem_18485, &ext_mem_18457, "ext_mem_18457") != 0)
                                return 1;
                            if (memblock_set_device(ctx, &ext_mem_18484, &ext_mem_18456, "ext_mem_18456") != 0)
                                return 1;
                        }
                        if (memblock_set_device(ctx, &ext_mem_18527, &ext_mem_18485, "ext_mem_18485") != 0)
                            return 1;
                        if (memblock_set_device(ctx, &ext_mem_18526, &ext_mem_18484, "ext_mem_18484") != 0)
                            return 1;
                    }
                    if (memblock_alloc_device(ctx, &segred_tmp_mem_19145, (int64_t) 8 * num_groups_17185, "segred_tmp_mem_19145")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    int64_t num_threads_19147 = num_groups_17185 * segred_group_sizze_17183;
                    
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "\n# SegRed");
                    
                    unsigned int shared_sizze_19273 = (int64_t) 8 * segred_group_sizze_17183;
                    unsigned int shared_sizze_19275 = 1;
                    CUdeviceptr kernel_arg_19277 = ext_mem_18527.mem;
                    CUdeviceptr kernel_arg_19278 = mem_18530.mem;
                    CUdeviceptr kernel_arg_19279 = counters_mem_19143.mem;
                    CUdeviceptr kernel_arg_19280 = segred_tmp_mem_19145.mem;
                    unsigned int shared_offset_19274 = 0;
                    unsigned int shared_offset_19276 = 0 + (shared_sizze_19273 + (8 - shared_sizze_19273 % 8) % 8);
                    
                    if ((((((1 && num_groups_17185 != 0) && 1 != 0) && 1 != 0) && *ctx->tuning_params.segred_group_sizze_17182 != 0) && 1 != 0) && 1 != 0) {
                        int perm[3] = {0, 1, 2};
                        
                        if (1 >= 1 << 16) {
                            perm[1] = perm[0];
                            perm[0] = 1;
                        }
                        if (1 >= 1 << 16) {
                            perm[2] = perm[0];
                            perm[0] = 2;
                        }
                        
                        size_t grid[3];
                        
                        grid[perm[0]] = num_groups_17185;
                        grid[perm[1]] = 1;
                        grid[perm[2]] = 1;
                        
                        void *kernel_args_19270[] = {&ctx->global_failure, &shared_offset_19274, &shared_offset_19276, &num_groups_17185, &num_threads_19147, &kernel_arg_19277, &kernel_arg_19278, &kernel_arg_19279, &kernel_arg_19280};
                        int64_t time_start_19271 = 0, time_end_19272 = 0;
                        
                        if (ctx->debugging) {
                            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "segred_nonseg_17190", (long) num_groups_17185, (long) 1, (long) 1, (long) *ctx->tuning_params.segred_group_sizze_17182, (long) 1, (long) 1, (int) (0 + (shared_sizze_19273 + (8 - shared_sizze_19273 % 8) % 8) + (shared_sizze_19275 + (8 - shared_sizze_19275 % 8) % 8)));
                            time_start_19271 = get_wall_time();
                        }
                        
                        cudaEvent_t *pevents = NULL;
                        
                        if (ctx->profiling && !ctx->profiling_paused) {
                            pevents = cuda_get_events(ctx, &ctx->program->segred_nonseg_17190_runs, &ctx->program->segred_nonseg_17190_total_runtime);
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                        }
                        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->segred_nonseg_17190, grid[0], grid[1], grid[2], *ctx->tuning_params.segred_group_sizze_17182, 1, 1, 0 + (shared_sizze_19273 + (8 - shared_sizze_19273 % 8) % 8) + (shared_sizze_19275 + (8 - shared_sizze_19275 % 8) % 8), NULL, kernel_args_19270, NULL));
                        if (pevents != NULL)
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                        if (ctx->debugging) {
                            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                            time_end_19272 = get_wall_time();
                            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "segred_nonseg_17190", time_end_19272 - time_start_19271);
                        }
                    }
                    if (ctx->debugging)
                        fprintf(ctx->log, "%s\n", "");
                    if (memblock_alloc_device(ctx, &mem_18532, (int64_t) 8, "mem_18532")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_18534, (int64_t) 1, "mem_18534")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_18536, (int64_t) 2, "mem_18536")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_18538, (int64_t) 2, "mem_18538")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_18540, (int64_t) 2, "mem_18540")) {
                        err = 1;
                        goto cleanup;
                    }
                    if (memblock_alloc_device(ctx, &mem_18542, (int64_t) 2, "mem_18542")) {
                        err = 1;
                        goto cleanup;
                    }
                    
                    CUdeviceptr kernel_arg_19284 = mem_param_18367.mem;
                    CUdeviceptr kernel_arg_19285 = ext_mem_18526.mem;
                    CUdeviceptr kernel_arg_19286 = ext_mem_18527.mem;
                    CUdeviceptr kernel_arg_19287 = mem_18530.mem;
                    CUdeviceptr kernel_arg_19288 = mem_18532.mem;
                    CUdeviceptr kernel_arg_19289 = mem_18534.mem;
                    CUdeviceptr kernel_arg_19290 = mem_18536.mem;
                    CUdeviceptr kernel_arg_19291 = mem_18538.mem;
                    CUdeviceptr kernel_arg_19292 = mem_18540.mem;
                    CUdeviceptr kernel_arg_19293 = mem_18542.mem;
                    CUdeviceptr kernel_arg_19294 = mem_18544.mem;
                    
                    if ((((((1 && (int64_t) 1 != 0) && 1 != 0) && 1 != 0) && (int64_t) 1 != 0) && 1 != 0) && 1 != 0) {
                        int perm[3] = {0, 1, 2};
                        
                        if (1 >= 1 << 16) {
                            perm[1] = perm[0];
                            perm[0] = 1;
                        }
                        if (1 >= 1 << 16) {
                            perm[2] = perm[0];
                            perm[0] = 2;
                        }
                        
                        size_t grid[3];
                        
                        grid[perm[0]] = (int64_t) 1;
                        grid[perm[1]] = 1;
                        grid[perm[2]] = 1;
                        
                        void *kernel_args_19281[] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &kernel_arg_19284, &kernel_arg_19285, &kernel_arg_19286, &kernel_arg_19287, &kernel_arg_19288, &kernel_arg_19289, &kernel_arg_19290, &kernel_arg_19291, &kernel_arg_19292, &kernel_arg_19293, &kernel_arg_19294};
                        int64_t time_start_19282 = 0, time_end_19283 = 0;
                        
                        if (ctx->debugging) {
                            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "gpuseq_19173", (long) (int64_t) 1, (long) 1, (long) 1, (long) (int64_t) 1, (long) 1, (long) 1, (int) 0);
                            time_start_19282 = get_wall_time();
                        }
                        
                        cudaEvent_t *pevents = NULL;
                        
                        if (ctx->profiling && !ctx->profiling_paused) {
                            pevents = cuda_get_events(ctx, &ctx->program->gpuseq_19173_runs, &ctx->program->gpuseq_19173_total_runtime);
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                        }
                        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->gpuseq_19173, grid[0], grid[1], grid[2], (int64_t) 1, 1, 1, 0, NULL, kernel_args_19281, NULL));
                        if (pevents != NULL)
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                        if (ctx->debugging) {
                            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                            time_end_19283 = get_wall_time();
                            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "gpuseq_19173", time_end_19283 - time_start_19282);
                        }
                    }
                    ctx->failure_is_an_option = 1;
                    if (memblock_unref_device(ctx, &ext_mem_18526, "ext_mem_18526") != 0)
                        return 1;
                    if (memblock_unref_device(ctx, &ext_mem_18527, "ext_mem_18527") != 0)
                        return 1;
                    
                    bool read_res_19295;
                    
                    {
                        cudaEvent_t *pevents = NULL;
                        
                        if (ctx->profiling && !ctx->profiling_paused) {
                            pevents = cuda_get_events(ctx, &ctx->program->copy_scalar_from_dev_runs, &ctx->program->copy_scalar_from_dev_total_runtime);
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                        }
                        CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&read_res_19295, mem_18544.mem + (int64_t) 0 * sizeof(bool), sizeof(bool)));
                        if (pevents != NULL)
                            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                    }
                    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0)
                        return 1;
                    
                    bool x_11637 = read_res_19295;
                    
                    if (memblock_set_device(ctx, &mem_param_tmp_18845, &mem_18532, "mem_18532") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_tmp_18846, &mem_18534, "mem_18534") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_tmp_18847, &mem_18536, "mem_18536") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_tmp_18848, &mem_18538, "mem_18538") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_tmp_18849, &mem_18540, "mem_18540") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_tmp_18850, &mem_18542, "mem_18542") != 0)
                        return 1;
                    
                    bool loop_while_tmp_18851 = x_11637;
                    
                    if (memblock_set_device(ctx, &mem_param_18367, &mem_param_tmp_18845, "mem_param_tmp_18845") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_18372, &mem_param_tmp_18846, "mem_param_tmp_18846") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_18377, &mem_param_tmp_18847, "mem_param_tmp_18847") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_18382, &mem_param_tmp_18848, "mem_param_tmp_18848") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_18387, &mem_param_tmp_18849, "mem_param_tmp_18849") != 0)
                        return 1;
                    if (memblock_set_device(ctx, &mem_param_18392, &mem_param_tmp_18850, "mem_param_tmp_18850") != 0)
                        return 1;
                    loop_while_9068 = loop_while_tmp_18851;
                }
                if (memblock_set_device(ctx, &ext_mem_18574, &mem_param_18367, "mem_param_18367") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_18573, &mem_param_18372, "mem_param_18372") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_18572, &mem_param_18377, "mem_param_18377") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_18571, &mem_param_18382, "mem_param_18382") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_18570, &mem_param_18387, "mem_param_18387") != 0)
                    return 1;
                if (memblock_set_device(ctx, &ext_mem_18569, &mem_param_18392, "mem_param_18392") != 0)
                    return 1;
                loopres_9059 = loop_while_9068;
                
                bool read_res_19296;
                
                {
                    cudaEvent_t *pevents = NULL;
                    
                    if (ctx->profiling && !ctx->profiling_paused) {
                        pevents = cuda_get_events(ctx, &ctx->program->copy_scalar_from_dev_runs, &ctx->program->copy_scalar_from_dev_total_runtime);
                        CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                    }
                    CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&read_res_19296, ext_mem_18573.mem + (int64_t) 0 * sizeof(bool), sizeof(bool)));
                    if (pevents != NULL)
                        CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                }
                if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0)
                    return 1;
                
                bool loopres_9061 = read_res_19296;
                
                if (memblock_unref_device(ctx, &ext_mem_18573, "ext_mem_18573") != 0)
                    return 1;
                
                int64_t loopres_9202 = add64((int64_t) 1, i5_9040);
                bool cond_9211 = slt64(loopres_9202, (int64_t) 8);
                bool loop_cond_t_res_9213 = loopres_9061 == 0;
                bool x_11634 = cond_9211 && loop_cond_t_res_9213;
                
                if (memblock_set_device(ctx, &mem_param_tmp_18834, &ext_mem_18572, "ext_mem_18572") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_tmp_18835, &ext_mem_18571, "ext_mem_18571") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_tmp_18836, &ext_mem_18570, "ext_mem_18570") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_tmp_18837, &ext_mem_18569, "ext_mem_18569") != 0)
                    return 1;
                
                bool loop_while_tmp_18838 = x_11634;
                int64_t i5_tmp_18839 = loopres_9202;
                bool res1_tmp_18840 = loopres_9061;
                
                if (memblock_set_device(ctx, &mem_param_18347, &mem_param_tmp_18834, "mem_param_tmp_18834") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_18352, &mem_param_tmp_18835, "mem_param_tmp_18835") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_18357, &mem_param_tmp_18836, "mem_param_tmp_18836") != 0)
                    return 1;
                if (memblock_set_device(ctx, &mem_param_18362, &mem_param_tmp_18837, "mem_param_tmp_18837") != 0)
                    return 1;
                loop_while_9039 = loop_while_tmp_18838;
                i5_9040 = i5_tmp_18839;
                res1_9041 = res1_tmp_18840;
            }
            if (memblock_set_device(ctx, &ext_mem_18594, &mem_param_18347, "mem_param_18347") != 0)
                return 1;
            if (memblock_set_device(ctx, &ext_mem_18593, &mem_param_18352, "mem_param_18352") != 0)
                return 1;
            if (memblock_set_device(ctx, &ext_mem_18592, &mem_param_18357, "mem_param_18357") != 0)
                return 1;
            if (memblock_set_device(ctx, &ext_mem_18591, &mem_param_18362, "mem_param_18362") != 0)
                return 1;
            loopres_9030 = loop_while_9039;
            loopres_9031 = i5_9040;
            loopres_9032 = res1_9041;
            
            int64_t loopres_9222 = add64((int64_t) 1, i4_9011);
            bool cond_9231 = slt64(loopres_9222, (int64_t) 8);
            bool loop_cond_t_res_9233 = loopres_9032 == 0;
            bool x_11631 = cond_9231 && loop_cond_t_res_9233;
            
            if (memblock_set_device(ctx, &mem_param_tmp_18823, &ext_mem_18594, "ext_mem_18594") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_18824, &ext_mem_18593, "ext_mem_18593") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_18825, &ext_mem_18592, "ext_mem_18592") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_tmp_18826, &ext_mem_18591, "ext_mem_18591") != 0)
                return 1;
            
            bool loop_while_tmp_18827 = x_11631;
            int64_t i4_tmp_18828 = loopres_9222;
            bool res1_tmp_18829 = loopres_9032;
            
            if (memblock_set_device(ctx, &mem_param_18327, &mem_param_tmp_18823, "mem_param_tmp_18823") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_18332, &mem_param_tmp_18824, "mem_param_tmp_18824") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_18337, &mem_param_tmp_18825, "mem_param_tmp_18825") != 0)
                return 1;
            if (memblock_set_device(ctx, &mem_param_18342, &mem_param_tmp_18826, "mem_param_tmp_18826") != 0)
                return 1;
            loop_while_9010 = loop_while_tmp_18827;
            i4_9011 = i4_tmp_18828;
            res1_9012 = res1_tmp_18829;
        }
        if (memblock_set_device(ctx, &ext_mem_18614, &mem_param_18327, "mem_param_18327") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_18613, &mem_param_18332, "mem_param_18332") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_18612, &mem_param_18337, "mem_param_18337") != 0)
            return 1;
        if (memblock_set_device(ctx, &ext_mem_18611, &mem_param_18342, "mem_param_18342") != 0)
            return 1;
        loopres_9001 = loop_while_9010;
        loopres_9002 = i4_9011;
        loopres_9003 = res1_9012;
        
        int64_t loopres_9242 = add64((int64_t) 1, i3_8982);
        bool cond_9251 = slt64(loopres_9242, (int64_t) 8);
        bool loop_cond_t_res_9253 = loopres_9003 == 0;
        bool x_11628 = cond_9251 && loop_cond_t_res_9253;
        
        if (memblock_set_device(ctx, &mem_param_tmp_18812, &ext_mem_18614, "ext_mem_18614") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_18813, &ext_mem_18613, "ext_mem_18613") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_18814, &ext_mem_18612, "ext_mem_18612") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_tmp_18815, &ext_mem_18611, "ext_mem_18611") != 0)
            return 1;
        
        bool loop_while_tmp_18816 = x_11628;
        int64_t i3_tmp_18817 = loopres_9242;
        bool res1_tmp_18818 = loopres_9003;
        
        if (memblock_set_device(ctx, &mem_param_18307, &mem_param_tmp_18812, "mem_param_tmp_18812") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_18312, &mem_param_tmp_18813, "mem_param_tmp_18813") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_18317, &mem_param_tmp_18814, "mem_param_tmp_18814") != 0)
            return 1;
        if (memblock_set_device(ctx, &mem_param_18322, &mem_param_tmp_18815, "mem_param_tmp_18815") != 0)
            return 1;
        loop_while_8981 = loop_while_tmp_18816;
        i3_8982 = i3_tmp_18817;
        res1_8983 = res1_tmp_18818;
    }
    if (memblock_set_device(ctx, &ext_mem_18634, &mem_param_18307, "mem_param_18307") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_18633, &mem_param_18312, "mem_param_18312") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_18632, &mem_param_18317, "mem_param_18317") != 0)
        return 1;
    if (memblock_set_device(ctx, &ext_mem_18631, &mem_param_18322, "mem_param_18322") != 0)
        return 1;
    main_res_8972 = loop_while_8981;
    main_res_8973 = i3_8982;
    main_res_8974 = res1_8983;
    if (memblock_unref_device(ctx, &mem_18283, "mem_18283") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18292, "mem_18292") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18298, "mem_18298") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18300, "mem_18300") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18302, "mem_18302") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18394, "mem_18394") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18530, "mem_18530") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18544, "mem_18544") != 0)
        return 1;
    
    int16_t read_res_19297;
    
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_scalar_from_dev_runs, &ctx->program->copy_scalar_from_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&read_res_19297, ext_mem_18634.mem + (int64_t) 0 * sizeof(int16_t), sizeof(int16_t)));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0)
        return 1;
    
    int16_t main_res_8975 = read_res_19297;
    
    if (memblock_unref_device(ctx, &ext_mem_18634, "ext_mem_18634") != 0)
        return 1;
    
    int16_t read_res_19298;
    
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_scalar_from_dev_runs, &ctx->program->copy_scalar_from_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&read_res_19298, ext_mem_18633.mem + (int64_t) 0 * sizeof(int16_t), sizeof(int16_t)));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0)
        return 1;
    
    int16_t main_res_8976 = read_res_19298;
    
    if (memblock_unref_device(ctx, &ext_mem_18633, "ext_mem_18633") != 0)
        return 1;
    
    int16_t read_res_19299;
    
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_scalar_from_dev_runs, &ctx->program->copy_scalar_from_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&read_res_19299, ext_mem_18632.mem + (int64_t) 0 * sizeof(int16_t), sizeof(int16_t)));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0)
        return 1;
    
    int16_t main_res_8977 = read_res_19299;
    
    if (memblock_unref_device(ctx, &ext_mem_18632, "ext_mem_18632") != 0)
        return 1;
    
    int16_t read_res_19300;
    
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_scalar_from_dev_runs, &ctx->program->copy_scalar_from_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(&read_res_19300, ext_mem_18631.mem + (int64_t) 0 * sizeof(int16_t), sizeof(int16_t)));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0)
        return 1;
    
    int16_t main_res_8978 = read_res_19300;
    
    if (memblock_unref_device(ctx, &ext_mem_18631, "ext_mem_18631") != 0)
        return 1;
    triplayer2_9262 = sext_i16_i64(main_res_8975);
    
    bool x_9263 = sle64((int64_t) 0, triplayer2_9262);
    bool y_9264 = slt64(triplayer2_9262, (int64_t) 1024);
    bool bounds_check_9265 = x_9263 && y_9264;
    bool index_certs_9266;
    
    if (!bounds_check_9265) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) triplayer2_9262, "] out of bounds for array of shape [", (long long) (int64_t) 1024, "].", "-> #0  main.fut:108:18-35\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    triplayer3_9268 = sext_i16_i64(main_res_8976);
    
    bool x_9269 = sle64((int64_t) 0, triplayer3_9268);
    bool y_9270 = slt64(triplayer3_9268, (int64_t) 1024);
    bool bounds_check_9271 = x_9269 && y_9270;
    bool index_certs_9272;
    
    if (!bounds_check_9271) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) triplayer3_9268, "] out of bounds for array of shape [", (long long) (int64_t) 1024, "].", "-> #0  main.fut:108:38-55\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    triplayer4_9274 = sext_i16_i64(main_res_8977);
    
    bool x_9275 = sle64((int64_t) 0, triplayer4_9274);
    bool y_9276 = slt64(triplayer4_9274, (int64_t) 1024);
    bool bounds_check_9277 = x_9275 && y_9276;
    bool index_certs_9278;
    
    if (!bounds_check_9277) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) triplayer4_9274, "] out of bounds for array of shape [", (long long) (int64_t) 1024, "].", "-> #0  main.fut:108:58-75\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    triplayer5_9280 = sext_i16_i64(main_res_8978);
    
    bool x_9281 = sle64((int64_t) 0, triplayer5_9280);
    bool y_9282 = slt64(triplayer5_9280, (int64_t) 1024);
    bool bounds_check_9283 = x_9281 && y_9282;
    bool index_certs_9284;
    
    if (!bounds_check_9283) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) triplayer5_9280, "] out of bounds for array of shape [", (long long) (int64_t) 1024, "].", "-> #0  main.fut:108:78-95\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    if (memblock_unref_device(ctx, &mem_param_tmp_18815, "mem_param_tmp_18815") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18814, "mem_param_tmp_18814") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18813, "mem_param_tmp_18813") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18812, "mem_param_tmp_18812") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18826, "mem_param_tmp_18826") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18825, "mem_param_tmp_18825") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18824, "mem_param_tmp_18824") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18823, "mem_param_tmp_18823") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18837, "mem_param_tmp_18837") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18836, "mem_param_tmp_18836") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18835, "mem_param_tmp_18835") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18834, "mem_param_tmp_18834") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18850, "mem_param_tmp_18850") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18849, "mem_param_tmp_18849") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18848, "mem_param_tmp_18848") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18847, "mem_param_tmp_18847") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18846, "mem_param_tmp_18846") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_tmp_18845, "mem_param_tmp_18845") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18542, "mem_18542") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18540, "mem_18540") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18538, "mem_18538") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18536, "mem_18536") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18534, "mem_18534") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18532, "mem_18532") != 0)
        return 1;
    if (memblock_unref_device(ctx, &segred_tmp_mem_19145, "segred_tmp_mem_19145") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18436, "mem_18436") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18400, "mem_18400") != 0)
        return 1;
    if (memblock_unref_device(ctx, &segred_tmp_mem_19055, "segred_tmp_mem_19055") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18397, "mem_18397") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18434, "mem_18434") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18432, "mem_18432") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18438, "ext_mem_18438") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18439, "ext_mem_18439") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18454, "mem_18454") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18451, "mem_18451") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18449, "mem_18449") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18448, "mem_18448") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18456, "ext_mem_18456") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18457, "ext_mem_18457") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18482, "mem_18482") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18479, "mem_18479") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18477, "mem_18477") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18476, "mem_18476") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18484, "ext_mem_18484") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18485, "ext_mem_18485") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18524, "mem_18524") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18521, "mem_18521") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18519, "mem_18519") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18518, "mem_18518") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18526, "ext_mem_18526") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18527, "ext_mem_18527") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18392, "mem_param_18392") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18387, "mem_param_18387") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18382, "mem_param_18382") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18377, "mem_param_18377") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18372, "mem_param_18372") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18367, "mem_param_18367") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18569, "ext_mem_18569") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18570, "ext_mem_18570") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18571, "ext_mem_18571") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18572, "ext_mem_18572") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18573, "ext_mem_18573") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18574, "ext_mem_18574") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18362, "mem_param_18362") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18357, "mem_param_18357") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18352, "mem_param_18352") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18347, "mem_param_18347") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18591, "ext_mem_18591") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18592, "ext_mem_18592") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18593, "ext_mem_18593") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18594, "ext_mem_18594") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18342, "mem_param_18342") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18337, "mem_param_18337") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18332, "mem_param_18332") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18327, "mem_param_18327") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18611, "ext_mem_18611") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18612, "ext_mem_18612") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18613, "ext_mem_18613") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18614, "ext_mem_18614") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18322, "mem_param_18322") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18317, "mem_param_18317") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18312, "mem_param_18312") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_param_18307, "mem_param_18307") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18631, "ext_mem_18631") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18632, "ext_mem_18632") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18633, "ext_mem_18633") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ext_mem_18634, "ext_mem_18634") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18544, "mem_18544") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18530, "mem_18530") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18394, "mem_18394") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18302, "mem_18302") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18300, "mem_18300") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18298, "mem_18298") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18292, "mem_18292") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18289, "mem_18289") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18286, "mem_18286") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18283, "mem_18283") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_18281, "mem_18281") != 0)
        return 1;
    #undef counters_mem_19057
    #undef counters_mem_19143
    #undef main_res_8974
    #undef mem_18296
    #undef triplayer2_9262
    #undef triplayer3_9268
    #undef triplayer4_9274
    #undef triplayer5_9280
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_19057, "ctx->constants->counters_mem_19057") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_19143, "ctx->constants->counters_mem_19143") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->mem_18296, "ctx->constants->mem_18296") != 0)
        return 1;
    return 0;
}
struct futhark_u8_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_u8_1d *futhark_new_u8_1d(struct futhark_context *ctx, const uint8_t *data, int64_t dim0)
{
    struct futhark_u8_1d *bad = NULL;
    struct futhark_u8_1d *arr = (struct futhark_u8_1d *) malloc(sizeof(struct futhark_u8_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 1, "arr->mem"))
        return NULL;
    arr->shape[0] = dim0;
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_host_to_dev_runs, &ctx->program->copy_host_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoDAsync(arr->mem.mem + 0, data + 0, (size_t) dim0 * 1, 0));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
struct futhark_u8_1d *futhark_new_raw_u8_1d(struct futhark_context *ctx, const CUdeviceptr data, int64_t offset, int64_t dim0)
{
    struct futhark_u8_1d *bad = NULL;
    struct futhark_u8_1d *arr = (struct futhark_u8_1d *) malloc(sizeof(struct futhark_u8_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 1, "arr->mem"))
        return NULL;
    arr->shape[0] = dim0;
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_dev_to_dev_runs, &ctx->program->copy_dev_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpy(arr->mem.mem + 0, data + offset, (size_t) dim0 * 1));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_u8_1d(struct futhark_context *ctx, struct futhark_u8_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_u8_1d(struct futhark_context *ctx, struct futhark_u8_1d *arr, uint8_t *data)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_dev_to_host_runs, &ctx->program->copy_dev_to_host_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoHAsync(data + 0, arr->mem.mem + 0, (size_t) arr->shape[0] * 1, 0));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return 0;
}
CUdeviceptr futhark_values_raw_u8_1d(struct futhark_context *ctx, struct futhark_u8_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_u8_1d(struct futhark_context *ctx, struct futhark_u8_1d *arr)
{
    (void) ctx;
    return arr->shape;
}

static int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_19059, int64_t num_elems_19060, int32_t val_19061)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_19057 = ctx->constants->counters_mem_19057;
    struct memblock_device counters_mem_19143 = ctx->constants->counters_mem_19143;
    bool main_res_8974 = ctx->constants->main_res_8974;
    struct memblock_device mem_18296 = ctx->constants->mem_18296;
    int64_t triplayer2_9262 = ctx->constants->triplayer2_9262;
    int64_t triplayer3_9268 = ctx->constants->triplayer3_9268;
    int64_t triplayer4_9274 = ctx->constants->triplayer4_9274;
    int64_t triplayer5_9280 = ctx->constants->triplayer5_9280;
    int64_t replicate_n_19063 = num_elems_19060;
    int64_t group_sizze_19068;
    
    group_sizze_19068 = *ctx->tuning_params.builtinzhreplicate_i32zigroup_sizze_19068;
    
    int64_t virt_num_groups_19069 = sdiv_up64(replicate_n_19063, group_sizze_19068);
    int64_t num_groups_19070 = smin64(virt_num_groups_19069, (int64_t) 1048576);
    CUdeviceptr kernel_arg_19304 = mem_19059.mem;
    
    if ((((((1 && num_groups_19070 != 0) && 1 != 0) && 1 != 0) && group_sizze_19068 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = num_groups_19070;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_19301[] = {&num_elems_19060, &val_19061, &replicate_n_19063, &virt_num_groups_19069, &num_groups_19070, &kernel_arg_19304};
        int64_t time_start_19302 = 0, time_end_19303 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "builtin#replicate_i32.replicate_19064", (long) num_groups_19070, (long) 1, (long) 1, (long) group_sizze_19068, (long) 1, (long) 1, (int) 0);
            time_start_19302 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_19064_runs, &ctx->program->builtinzhreplicate_i32zireplicate_19064_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->builtinzhreplicate_i32zireplicate_19064, grid[0], grid[1], grid[2], group_sizze_19068, 1, 1, 0, NULL, kernel_args_19301, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_19303 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "builtin#replicate_i32.replicate_19064", time_end_19303 - time_start_19302);
        }
    }
    
  cleanup:
    { }
    return err;
}
static int futrts_builtinzhgpu_map_transpose_i16(struct futhark_context *ctx, struct memblock_device destmem_0, int32_t destoffset_1, struct memblock_device srcmem_2, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_19057 = ctx->constants->counters_mem_19057;
    struct memblock_device counters_mem_19143 = ctx->constants->counters_mem_19143;
    bool main_res_8974 = ctx->constants->main_res_8974;
    struct memblock_device mem_18296 = ctx->constants->mem_18296;
    int64_t triplayer2_9262 = ctx->constants->triplayer2_9262;
    int64_t triplayer3_9268 = ctx->constants->triplayer3_9268;
    int64_t triplayer4_9274 = ctx->constants->triplayer4_9274;
    int64_t triplayer5_9280 = ctx->constants->triplayer5_9280;
    
    if (!(num_arrays_4 == 0 || (x_elems_5 == 0 || y_elems_6 == 0))) {
        int32_t muly_8 = squot32(16, x_elems_5);
        int32_t mulx_7 = squot32(16, y_elems_6);
        
        if (num_arrays_4 == 1 && (x_elems_5 == 1 || y_elems_6 == 1)) {
            {
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(ctx, &ctx->program->copy_dev_to_dev_runs, &ctx->program->copy_dev_to_dev_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuMemcpy(destmem_0.mem + sext_i32_i64(destoffset_1), srcmem_2.mem + sext_i32_i64(srcoffset_3), sext_i32_i64(x_elems_5 * y_elems_6 * 2)));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            }
        } else if (sle32(x_elems_5, 8) && slt32(16, y_elems_6)) {
            unsigned int shared_sizze_19308 = (int64_t) 544;
            CUdeviceptr kernel_arg_19310 = destmem_0.mem;
            CUdeviceptr kernel_arg_19311 = srcmem_2.mem;
            unsigned int shared_offset_19309 = 0;
            
            if ((((((1 && sdiv_up32(x_elems_5, 16) != 0) && sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16) != 0) && num_arrays_4 != 0) && 16 != 0) && 16 != 0) && 1 != 0) {
                int perm[3] = {0, 1, 2};
                
                if (sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16) >= 1 << 16) {
                    perm[1] = perm[0];
                    perm[0] = 1;
                }
                if (num_arrays_4 >= 1 << 16) {
                    perm[2] = perm[0];
                    perm[0] = 2;
                }
                
                size_t grid[3];
                
                grid[perm[0]] = sdiv_up32(x_elems_5, 16);
                grid[perm[1]] = sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16);
                grid[perm[2]] = num_arrays_4;
                
                void *kernel_args_19305[] = {&perm[0], &perm[1], &perm[2], &shared_offset_19309, &destoffset_1, &srcoffset_3, &num_arrays_4, &x_elems_5, &y_elems_6, &mulx_7, &muly_8, &kernel_arg_19310, &kernel_arg_19311};
                int64_t time_start_19306 = 0, time_end_19307 = 0;
                
                if (ctx->debugging) {
                    fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "gpu_map_transpose_i16_low_width", (long) sdiv_up32(x_elems_5, 16), (long) sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16), (long) num_arrays_4, (long) 16, (long) 16, (long) 1, (int) (0 + (shared_sizze_19308 + (8 - shared_sizze_19308 % 8) % 8)));
                    time_start_19306 = get_wall_time();
                }
                
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(ctx, &ctx->program->gpu_map_transpose_i16_low_width_runs, &ctx->program->gpu_map_transpose_i16_low_width_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->gpu_map_transpose_i16_low_width, grid[0], grid[1], grid[2], 16, 16, 1, 0 + (shared_sizze_19308 + (8 - shared_sizze_19308 % 8) % 8), NULL, kernel_args_19305, NULL));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                if (ctx->debugging) {
                    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                    time_end_19307 = get_wall_time();
                    fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "gpu_map_transpose_i16_low_width", time_end_19307 - time_start_19306);
                }
            }
        } else if (sle32(y_elems_6, 8) && slt32(16, x_elems_5)) {
            unsigned int shared_sizze_19315 = (int64_t) 544;
            CUdeviceptr kernel_arg_19317 = destmem_0.mem;
            CUdeviceptr kernel_arg_19318 = srcmem_2.mem;
            unsigned int shared_offset_19316 = 0;
            
            if ((((((1 && sdiv_up32(sdiv_up32(x_elems_5, mulx_7), 16) != 0) && sdiv_up32(y_elems_6, 16) != 0) && num_arrays_4 != 0) && 16 != 0) && 16 != 0) && 1 != 0) {
                int perm[3] = {0, 1, 2};
                
                if (sdiv_up32(y_elems_6, 16) >= 1 << 16) {
                    perm[1] = perm[0];
                    perm[0] = 1;
                }
                if (num_arrays_4 >= 1 << 16) {
                    perm[2] = perm[0];
                    perm[0] = 2;
                }
                
                size_t grid[3];
                
                grid[perm[0]] = sdiv_up32(sdiv_up32(x_elems_5, mulx_7), 16);
                grid[perm[1]] = sdiv_up32(y_elems_6, 16);
                grid[perm[2]] = num_arrays_4;
                
                void *kernel_args_19312[] = {&perm[0], &perm[1], &perm[2], &shared_offset_19316, &destoffset_1, &srcoffset_3, &num_arrays_4, &x_elems_5, &y_elems_6, &mulx_7, &muly_8, &kernel_arg_19317, &kernel_arg_19318};
                int64_t time_start_19313 = 0, time_end_19314 = 0;
                
                if (ctx->debugging) {
                    fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "gpu_map_transpose_i16_low_height", (long) sdiv_up32(sdiv_up32(x_elems_5, mulx_7), 16), (long) sdiv_up32(y_elems_6, 16), (long) num_arrays_4, (long) 16, (long) 16, (long) 1, (int) (0 + (shared_sizze_19315 + (8 - shared_sizze_19315 % 8) % 8)));
                    time_start_19313 = get_wall_time();
                }
                
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(ctx, &ctx->program->gpu_map_transpose_i16_low_height_runs, &ctx->program->gpu_map_transpose_i16_low_height_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->gpu_map_transpose_i16_low_height, grid[0], grid[1], grid[2], 16, 16, 1, 0 + (shared_sizze_19315 + (8 - shared_sizze_19315 % 8) % 8), NULL, kernel_args_19312, NULL));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                if (ctx->debugging) {
                    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                    time_end_19314 = get_wall_time();
                    fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "gpu_map_transpose_i16_low_height", time_end_19314 - time_start_19313);
                }
            }
        } else if (sle32(x_elems_5, 8) && sle32(y_elems_6, 8)) {
            unsigned int shared_sizze_19322 = (int64_t) 1;
            CUdeviceptr kernel_arg_19324 = destmem_0.mem;
            CUdeviceptr kernel_arg_19325 = srcmem_2.mem;
            unsigned int shared_offset_19323 = 0;
            
            if ((((((1 && sdiv_up32(num_arrays_4 * x_elems_5 * y_elems_6, 256) != 0) && 1 != 0) && 1 != 0) && 256 != 0) && 1 != 0) && 1 != 0) {
                int perm[3] = {0, 1, 2};
                
                if (1 >= 1 << 16) {
                    perm[1] = perm[0];
                    perm[0] = 1;
                }
                if (1 >= 1 << 16) {
                    perm[2] = perm[0];
                    perm[0] = 2;
                }
                
                size_t grid[3];
                
                grid[perm[0]] = sdiv_up32(num_arrays_4 * x_elems_5 * y_elems_6, 256);
                grid[perm[1]] = 1;
                grid[perm[2]] = 1;
                
                void *kernel_args_19319[] = {&shared_offset_19323, &destoffset_1, &srcoffset_3, &num_arrays_4, &x_elems_5, &y_elems_6, &mulx_7, &muly_8, &kernel_arg_19324, &kernel_arg_19325};
                int64_t time_start_19320 = 0, time_end_19321 = 0;
                
                if (ctx->debugging) {
                    fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "gpu_map_transpose_i16_small", (long) sdiv_up32(num_arrays_4 * x_elems_5 * y_elems_6, 256), (long) 1, (long) 1, (long) 256, (long) 1, (long) 1, (int) (0 + (shared_sizze_19322 + (8 - shared_sizze_19322 % 8) % 8)));
                    time_start_19320 = get_wall_time();
                }
                
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(ctx, &ctx->program->gpu_map_transpose_i16_small_runs, &ctx->program->gpu_map_transpose_i16_small_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->gpu_map_transpose_i16_small, grid[0], grid[1], grid[2], 256, 1, 1, 0 + (shared_sizze_19322 + (8 - shared_sizze_19322 % 8) % 8), NULL, kernel_args_19319, NULL));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                if (ctx->debugging) {
                    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                    time_end_19321 = get_wall_time();
                    fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "gpu_map_transpose_i16_small", time_end_19321 - time_start_19320);
                }
            }
        } else {
            unsigned int shared_sizze_19329 = (int64_t) 2112;
            CUdeviceptr kernel_arg_19331 = destmem_0.mem;
            CUdeviceptr kernel_arg_19332 = srcmem_2.mem;
            unsigned int shared_offset_19330 = 0;
            
            if ((((((1 && sdiv_up32(x_elems_5, 32) != 0) && sdiv_up32(y_elems_6, 32) != 0) && num_arrays_4 != 0) && 32 != 0) && 8 != 0) && 1 != 0) {
                int perm[3] = {0, 1, 2};
                
                if (sdiv_up32(y_elems_6, 32) >= 1 << 16) {
                    perm[1] = perm[0];
                    perm[0] = 1;
                }
                if (num_arrays_4 >= 1 << 16) {
                    perm[2] = perm[0];
                    perm[0] = 2;
                }
                
                size_t grid[3];
                
                grid[perm[0]] = sdiv_up32(x_elems_5, 32);
                grid[perm[1]] = sdiv_up32(y_elems_6, 32);
                grid[perm[2]] = num_arrays_4;
                
                void *kernel_args_19326[] = {&perm[0], &perm[1], &perm[2], &shared_offset_19330, &destoffset_1, &srcoffset_3, &num_arrays_4, &x_elems_5, &y_elems_6, &mulx_7, &muly_8, &kernel_arg_19331, &kernel_arg_19332};
                int64_t time_start_19327 = 0, time_end_19328 = 0;
                
                if (ctx->debugging) {
                    fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "gpu_map_transpose_i16", (long) sdiv_up32(x_elems_5, 32), (long) sdiv_up32(y_elems_6, 32), (long) num_arrays_4, (long) 32, (long) 8, (long) 1, (int) (0 + (shared_sizze_19329 + (8 - shared_sizze_19329 % 8) % 8)));
                    time_start_19327 = get_wall_time();
                }
                
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(ctx, &ctx->program->gpu_map_transpose_i16_runs, &ctx->program->gpu_map_transpose_i16_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->gpu_map_transpose_i16, grid[0], grid[1], grid[2], 32, 8, 1, 0 + (shared_sizze_19329 + (8 - shared_sizze_19329 % 8) % 8), NULL, kernel_args_19326, NULL));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                if (ctx->debugging) {
                    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                    time_end_19328 = get_wall_time();
                    fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "gpu_map_transpose_i16", time_end_19328 - time_start_19327);
                }
            }
        }
    }
    
  cleanup:
    { }
    return err;
}
static int futrts_builtinzhgpu_map_transpose_bool(struct futhark_context *ctx, struct memblock_device destmem_0, int32_t destoffset_1, struct memblock_device srcmem_2, int32_t srcoffset_3, int32_t num_arrays_4, int32_t x_elems_5, int32_t y_elems_6)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_19057 = ctx->constants->counters_mem_19057;
    struct memblock_device counters_mem_19143 = ctx->constants->counters_mem_19143;
    bool main_res_8974 = ctx->constants->main_res_8974;
    struct memblock_device mem_18296 = ctx->constants->mem_18296;
    int64_t triplayer2_9262 = ctx->constants->triplayer2_9262;
    int64_t triplayer3_9268 = ctx->constants->triplayer3_9268;
    int64_t triplayer4_9274 = ctx->constants->triplayer4_9274;
    int64_t triplayer5_9280 = ctx->constants->triplayer5_9280;
    
    if (!(num_arrays_4 == 0 || (x_elems_5 == 0 || y_elems_6 == 0))) {
        int32_t muly_8 = squot32(16, x_elems_5);
        int32_t mulx_7 = squot32(16, y_elems_6);
        
        if (num_arrays_4 == 1 && (x_elems_5 == 1 || y_elems_6 == 1)) {
            {
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(ctx, &ctx->program->copy_dev_to_dev_runs, &ctx->program->copy_dev_to_dev_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuMemcpy(destmem_0.mem + sext_i32_i64(destoffset_1), srcmem_2.mem + sext_i32_i64(srcoffset_3), sext_i32_i64(x_elems_5 * y_elems_6)));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
            }
        } else if (sle32(x_elems_5, 8) && slt32(16, y_elems_6)) {
            unsigned int shared_sizze_19336 = (int64_t) 272;
            CUdeviceptr kernel_arg_19338 = destmem_0.mem;
            CUdeviceptr kernel_arg_19339 = srcmem_2.mem;
            unsigned int shared_offset_19337 = 0;
            
            if ((((((1 && sdiv_up32(x_elems_5, 16) != 0) && sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16) != 0) && num_arrays_4 != 0) && 16 != 0) && 16 != 0) && 1 != 0) {
                int perm[3] = {0, 1, 2};
                
                if (sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16) >= 1 << 16) {
                    perm[1] = perm[0];
                    perm[0] = 1;
                }
                if (num_arrays_4 >= 1 << 16) {
                    perm[2] = perm[0];
                    perm[0] = 2;
                }
                
                size_t grid[3];
                
                grid[perm[0]] = sdiv_up32(x_elems_5, 16);
                grid[perm[1]] = sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16);
                grid[perm[2]] = num_arrays_4;
                
                void *kernel_args_19333[] = {&perm[0], &perm[1], &perm[2], &shared_offset_19337, &destoffset_1, &srcoffset_3, &num_arrays_4, &x_elems_5, &y_elems_6, &mulx_7, &muly_8, &kernel_arg_19338, &kernel_arg_19339};
                int64_t time_start_19334 = 0, time_end_19335 = 0;
                
                if (ctx->debugging) {
                    fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "gpu_map_transpose_bool_low_width", (long) sdiv_up32(x_elems_5, 16), (long) sdiv_up32(sdiv_up32(y_elems_6, muly_8), 16), (long) num_arrays_4, (long) 16, (long) 16, (long) 1, (int) (0 + (shared_sizze_19336 + (8 - shared_sizze_19336 % 8) % 8)));
                    time_start_19334 = get_wall_time();
                }
                
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(ctx, &ctx->program->gpu_map_transpose_bool_low_width_runs, &ctx->program->gpu_map_transpose_bool_low_width_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->gpu_map_transpose_bool_low_width, grid[0], grid[1], grid[2], 16, 16, 1, 0 + (shared_sizze_19336 + (8 - shared_sizze_19336 % 8) % 8), NULL, kernel_args_19333, NULL));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                if (ctx->debugging) {
                    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                    time_end_19335 = get_wall_time();
                    fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "gpu_map_transpose_bool_low_width", time_end_19335 - time_start_19334);
                }
            }
        } else if (sle32(y_elems_6, 8) && slt32(16, x_elems_5)) {
            unsigned int shared_sizze_19343 = (int64_t) 272;
            CUdeviceptr kernel_arg_19345 = destmem_0.mem;
            CUdeviceptr kernel_arg_19346 = srcmem_2.mem;
            unsigned int shared_offset_19344 = 0;
            
            if ((((((1 && sdiv_up32(sdiv_up32(x_elems_5, mulx_7), 16) != 0) && sdiv_up32(y_elems_6, 16) != 0) && num_arrays_4 != 0) && 16 != 0) && 16 != 0) && 1 != 0) {
                int perm[3] = {0, 1, 2};
                
                if (sdiv_up32(y_elems_6, 16) >= 1 << 16) {
                    perm[1] = perm[0];
                    perm[0] = 1;
                }
                if (num_arrays_4 >= 1 << 16) {
                    perm[2] = perm[0];
                    perm[0] = 2;
                }
                
                size_t grid[3];
                
                grid[perm[0]] = sdiv_up32(sdiv_up32(x_elems_5, mulx_7), 16);
                grid[perm[1]] = sdiv_up32(y_elems_6, 16);
                grid[perm[2]] = num_arrays_4;
                
                void *kernel_args_19340[] = {&perm[0], &perm[1], &perm[2], &shared_offset_19344, &destoffset_1, &srcoffset_3, &num_arrays_4, &x_elems_5, &y_elems_6, &mulx_7, &muly_8, &kernel_arg_19345, &kernel_arg_19346};
                int64_t time_start_19341 = 0, time_end_19342 = 0;
                
                if (ctx->debugging) {
                    fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "gpu_map_transpose_bool_low_height", (long) sdiv_up32(sdiv_up32(x_elems_5, mulx_7), 16), (long) sdiv_up32(y_elems_6, 16), (long) num_arrays_4, (long) 16, (long) 16, (long) 1, (int) (0 + (shared_sizze_19343 + (8 - shared_sizze_19343 % 8) % 8)));
                    time_start_19341 = get_wall_time();
                }
                
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(ctx, &ctx->program->gpu_map_transpose_bool_low_height_runs, &ctx->program->gpu_map_transpose_bool_low_height_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->gpu_map_transpose_bool_low_height, grid[0], grid[1], grid[2], 16, 16, 1, 0 + (shared_sizze_19343 + (8 - shared_sizze_19343 % 8) % 8), NULL, kernel_args_19340, NULL));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                if (ctx->debugging) {
                    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                    time_end_19342 = get_wall_time();
                    fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "gpu_map_transpose_bool_low_height", time_end_19342 - time_start_19341);
                }
            }
        } else if (sle32(x_elems_5, 8) && sle32(y_elems_6, 8)) {
            unsigned int shared_sizze_19350 = (int64_t) 1;
            CUdeviceptr kernel_arg_19352 = destmem_0.mem;
            CUdeviceptr kernel_arg_19353 = srcmem_2.mem;
            unsigned int shared_offset_19351 = 0;
            
            if ((((((1 && sdiv_up32(num_arrays_4 * x_elems_5 * y_elems_6, 256) != 0) && 1 != 0) && 1 != 0) && 256 != 0) && 1 != 0) && 1 != 0) {
                int perm[3] = {0, 1, 2};
                
                if (1 >= 1 << 16) {
                    perm[1] = perm[0];
                    perm[0] = 1;
                }
                if (1 >= 1 << 16) {
                    perm[2] = perm[0];
                    perm[0] = 2;
                }
                
                size_t grid[3];
                
                grid[perm[0]] = sdiv_up32(num_arrays_4 * x_elems_5 * y_elems_6, 256);
                grid[perm[1]] = 1;
                grid[perm[2]] = 1;
                
                void *kernel_args_19347[] = {&shared_offset_19351, &destoffset_1, &srcoffset_3, &num_arrays_4, &x_elems_5, &y_elems_6, &mulx_7, &muly_8, &kernel_arg_19352, &kernel_arg_19353};
                int64_t time_start_19348 = 0, time_end_19349 = 0;
                
                if (ctx->debugging) {
                    fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "gpu_map_transpose_bool_small", (long) sdiv_up32(num_arrays_4 * x_elems_5 * y_elems_6, 256), (long) 1, (long) 1, (long) 256, (long) 1, (long) 1, (int) (0 + (shared_sizze_19350 + (8 - shared_sizze_19350 % 8) % 8)));
                    time_start_19348 = get_wall_time();
                }
                
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(ctx, &ctx->program->gpu_map_transpose_bool_small_runs, &ctx->program->gpu_map_transpose_bool_small_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->gpu_map_transpose_bool_small, grid[0], grid[1], grid[2], 256, 1, 1, 0 + (shared_sizze_19350 + (8 - shared_sizze_19350 % 8) % 8), NULL, kernel_args_19347, NULL));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                if (ctx->debugging) {
                    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                    time_end_19349 = get_wall_time();
                    fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "gpu_map_transpose_bool_small", time_end_19349 - time_start_19348);
                }
            }
        } else {
            unsigned int shared_sizze_19357 = (int64_t) 1056;
            CUdeviceptr kernel_arg_19359 = destmem_0.mem;
            CUdeviceptr kernel_arg_19360 = srcmem_2.mem;
            unsigned int shared_offset_19358 = 0;
            
            if ((((((1 && sdiv_up32(x_elems_5, 32) != 0) && sdiv_up32(y_elems_6, 32) != 0) && num_arrays_4 != 0) && 32 != 0) && 8 != 0) && 1 != 0) {
                int perm[3] = {0, 1, 2};
                
                if (sdiv_up32(y_elems_6, 32) >= 1 << 16) {
                    perm[1] = perm[0];
                    perm[0] = 1;
                }
                if (num_arrays_4 >= 1 << 16) {
                    perm[2] = perm[0];
                    perm[0] = 2;
                }
                
                size_t grid[3];
                
                grid[perm[0]] = sdiv_up32(x_elems_5, 32);
                grid[perm[1]] = sdiv_up32(y_elems_6, 32);
                grid[perm[2]] = num_arrays_4;
                
                void *kernel_args_19354[] = {&perm[0], &perm[1], &perm[2], &shared_offset_19358, &destoffset_1, &srcoffset_3, &num_arrays_4, &x_elems_5, &y_elems_6, &mulx_7, &muly_8, &kernel_arg_19359, &kernel_arg_19360};
                int64_t time_start_19355 = 0, time_end_19356 = 0;
                
                if (ctx->debugging) {
                    fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "gpu_map_transpose_bool", (long) sdiv_up32(x_elems_5, 32), (long) sdiv_up32(y_elems_6, 32), (long) num_arrays_4, (long) 32, (long) 8, (long) 1, (int) (0 + (shared_sizze_19357 + (8 - shared_sizze_19357 % 8) % 8)));
                    time_start_19355 = get_wall_time();
                }
                
                cudaEvent_t *pevents = NULL;
                
                if (ctx->profiling && !ctx->profiling_paused) {
                    pevents = cuda_get_events(ctx, &ctx->program->gpu_map_transpose_bool_runs, &ctx->program->gpu_map_transpose_bool_total_runtime);
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
                }
                CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->gpu_map_transpose_bool, grid[0], grid[1], grid[2], 32, 8, 1, 0 + (shared_sizze_19357 + (8 - shared_sizze_19357 % 8) % 8), NULL, kernel_args_19354, NULL));
                if (pevents != NULL)
                    CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
                if (ctx->debugging) {
                    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
                    time_end_19356 = get_wall_time();
                    fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "gpu_map_transpose_bool", time_end_19356 - time_start_19355);
                }
            }
        }
    }
    
  cleanup:
    { }
    return err;
}
static int futrts_builtinzhreplicate_bool(struct futhark_context *ctx, struct memblock_device mem_18792, int64_t num_elems_18793, bool val_18794)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_19057 = ctx->constants->counters_mem_19057;
    struct memblock_device counters_mem_19143 = ctx->constants->counters_mem_19143;
    bool main_res_8974 = ctx->constants->main_res_8974;
    struct memblock_device mem_18296 = ctx->constants->mem_18296;
    int64_t triplayer2_9262 = ctx->constants->triplayer2_9262;
    int64_t triplayer3_9268 = ctx->constants->triplayer3_9268;
    int64_t triplayer4_9274 = ctx->constants->triplayer4_9274;
    int64_t triplayer5_9280 = ctx->constants->triplayer5_9280;
    int64_t replicate_n_18796 = num_elems_18793;
    int64_t group_sizze_18801;
    
    group_sizze_18801 = *ctx->tuning_params.builtinzhreplicate_boolzigroup_sizze_18801;
    
    int64_t virt_num_groups_18802 = sdiv_up64(replicate_n_18796, group_sizze_18801);
    int64_t num_groups_18803 = smin64(virt_num_groups_18802, (int64_t) 1048576);
    CUdeviceptr kernel_arg_19364 = mem_18792.mem;
    
    if ((((((1 && num_groups_18803 != 0) && 1 != 0) && 1 != 0) && group_sizze_18801 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = num_groups_18803;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_19361[] = {&num_elems_18793, &val_18794, &replicate_n_18796, &virt_num_groups_18802, &num_groups_18803, &kernel_arg_19364};
        int64_t time_start_19362 = 0, time_end_19363 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "builtin#replicate_bool.replicate_18797", (long) num_groups_18803, (long) 1, (long) 1, (long) group_sizze_18801, (long) 1, (long) 1, (int) 0);
            time_start_19362 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->builtinzhreplicate_boolzireplicate_18797_runs, &ctx->program->builtinzhreplicate_boolzireplicate_18797_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->builtinzhreplicate_boolzireplicate_18797, grid[0], grid[1], grid[2], group_sizze_18801, 1, 1, 0, NULL, kernel_args_19361, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_19363 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "builtin#replicate_bool.replicate_18797", time_end_19363 - time_start_19362);
        }
    }
    
  cleanup:
    { }
    return err;
}
static int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_18772, int64_t num_elems_18773, int64_t val_18774)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_19057 = ctx->constants->counters_mem_19057;
    struct memblock_device counters_mem_19143 = ctx->constants->counters_mem_19143;
    bool main_res_8974 = ctx->constants->main_res_8974;
    struct memblock_device mem_18296 = ctx->constants->mem_18296;
    int64_t triplayer2_9262 = ctx->constants->triplayer2_9262;
    int64_t triplayer3_9268 = ctx->constants->triplayer3_9268;
    int64_t triplayer4_9274 = ctx->constants->triplayer4_9274;
    int64_t triplayer5_9280 = ctx->constants->triplayer5_9280;
    int64_t replicate_n_18776 = num_elems_18773;
    int64_t group_sizze_18781;
    
    group_sizze_18781 = *ctx->tuning_params.builtinzhreplicate_i64zigroup_sizze_18781;
    
    int64_t virt_num_groups_18782 = sdiv_up64(replicate_n_18776, group_sizze_18781);
    int64_t num_groups_18783 = smin64(virt_num_groups_18782, (int64_t) 1048576);
    CUdeviceptr kernel_arg_19368 = mem_18772.mem;
    
    if ((((((1 && num_groups_18783 != 0) && 1 != 0) && 1 != 0) && group_sizze_18781 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = num_groups_18783;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_19365[] = {&num_elems_18773, &val_18774, &replicate_n_18776, &virt_num_groups_18782, &num_groups_18783, &kernel_arg_19368};
        int64_t time_start_19366 = 0, time_end_19367 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "builtin#replicate_i64.replicate_18777", (long) num_groups_18783, (long) 1, (long) 1, (long) group_sizze_18781, (long) 1, (long) 1, (int) 0);
            time_start_19366 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->builtinzhreplicate_i64zireplicate_18777_runs, &ctx->program->builtinzhreplicate_i64zireplicate_18777_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->builtinzhreplicate_i64zireplicate_18777, grid[0], grid[1], grid[2], group_sizze_18781, 1, 1, 0, NULL, kernel_args_19365, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_19367 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "builtin#replicate_i64.replicate_18777", time_end_19367 - time_start_19366);
        }
    }
    
  cleanup:
    { }
    return err;
}
static int futrts_builtinzhreplicate_i16(struct futhark_context *ctx, struct memblock_device mem_18752, int64_t num_elems_18753, int16_t val_18754)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_19057 = ctx->constants->counters_mem_19057;
    struct memblock_device counters_mem_19143 = ctx->constants->counters_mem_19143;
    bool main_res_8974 = ctx->constants->main_res_8974;
    struct memblock_device mem_18296 = ctx->constants->mem_18296;
    int64_t triplayer2_9262 = ctx->constants->triplayer2_9262;
    int64_t triplayer3_9268 = ctx->constants->triplayer3_9268;
    int64_t triplayer4_9274 = ctx->constants->triplayer4_9274;
    int64_t triplayer5_9280 = ctx->constants->triplayer5_9280;
    int64_t replicate_n_18756 = num_elems_18753;
    int64_t group_sizze_18761;
    
    group_sizze_18761 = *ctx->tuning_params.builtinzhreplicate_i16zigroup_sizze_18761;
    
    int64_t virt_num_groups_18762 = sdiv_up64(replicate_n_18756, group_sizze_18761);
    int64_t num_groups_18763 = smin64(virt_num_groups_18762, (int64_t) 1048576);
    CUdeviceptr kernel_arg_19372 = mem_18752.mem;
    
    if ((((((1 && num_groups_18763 != 0) && 1 != 0) && 1 != 0) && group_sizze_18761 != 0) && 1 != 0) && 1 != 0) {
        int perm[3] = {0, 1, 2};
        
        if (1 >= 1 << 16) {
            perm[1] = perm[0];
            perm[0] = 1;
        }
        if (1 >= 1 << 16) {
            perm[2] = perm[0];
            perm[0] = 2;
        }
        
        size_t grid[3];
        
        grid[perm[0]] = num_groups_18763;
        grid[perm[1]] = 1;
        grid[perm[2]] = 1;
        
        void *kernel_args_19369[] = {&num_elems_18753, &val_18754, &replicate_n_18756, &virt_num_groups_18762, &num_groups_18763, &kernel_arg_19372};
        int64_t time_start_19370 = 0, time_end_19371 = 0;
        
        if (ctx->debugging) {
            fprintf(ctx->log, "Launching %s with grid size [%ld, %ld, %ld] and block size [%ld, %ld, %ld]; shared memory: %d bytes.\n", "builtin#replicate_i16.replicate_18757", (long) num_groups_18763, (long) 1, (long) 1, (long) group_sizze_18761, (long) 1, (long) 1, (int) 0);
            time_start_19370 = get_wall_time();
        }
        
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->builtinzhreplicate_i16zireplicate_18757_runs, &ctx->program->builtinzhreplicate_i16zireplicate_18757_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuLaunchKernel(ctx->program->builtinzhreplicate_i16zireplicate_18757, grid[0], grid[1], grid[2], group_sizze_18761, 1, 1, 0, NULL, kernel_args_19369, NULL));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
        if (ctx->debugging) {
            CUDA_SUCCEED_FATAL(cuCtxSynchronize());
            time_end_19371 = get_wall_time();
            fprintf(ctx->log, "Kernel %s runtime: %ldus\n", "builtin#replicate_i16.replicate_18757", time_end_19371 - time_start_19370);
        }
    }
    
  cleanup:
    { }
    return err;
}
static int futrts_entry_main(struct futhark_context *ctx, struct memblock_device *mem_out_p_19373, struct memblock_device *mem_out_p_19374, struct memblock_device *mem_out_p_19375, struct memblock_device *mem_out_p_19376, struct memblock_device *mem_out_p_19377, struct memblock_device *mem_out_p_19378, bool *out_prim_out_19379)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_18651;
    
    mem_18651.references = NULL;
    
    struct memblock_device mem_18648;
    
    mem_18648.references = NULL;
    
    struct memblock_device mem_18645;
    
    mem_18645.references = NULL;
    
    struct memblock_device mem_18642;
    
    mem_18642.references = NULL;
    
    struct memblock_device mem_18639;
    
    mem_18639.references = NULL;
    
    struct memblock_device mem_18636;
    
    mem_18636.references = NULL;
    
    struct memblock_device mem_out_18675;
    
    mem_out_18675.references = NULL;
    
    struct memblock_device mem_out_18674;
    
    mem_out_18674.references = NULL;
    
    struct memblock_device mem_out_18673;
    
    mem_out_18673.references = NULL;
    
    struct memblock_device mem_out_18672;
    
    mem_out_18672.references = NULL;
    
    struct memblock_device mem_out_18671;
    
    mem_out_18671.references = NULL;
    
    struct memblock_device mem_out_18670;
    
    mem_out_18670.references = NULL;
    
    struct memblock_device counters_mem_19057 = ctx->constants->counters_mem_19057;
    struct memblock_device counters_mem_19143 = ctx->constants->counters_mem_19143;
    bool main_res_8974 = ctx->constants->main_res_8974;
    struct memblock_device mem_18296 = ctx->constants->mem_18296;
    int64_t triplayer2_9262 = ctx->constants->triplayer2_9262;
    int64_t triplayer3_9268 = ctx->constants->triplayer3_9268;
    int64_t triplayer4_9274 = ctx->constants->triplayer4_9274;
    int64_t triplayer5_9280 = ctx->constants->triplayer5_9280;
    bool prim_out_18676;
    
    if (memblock_alloc_device(ctx, &mem_18636, (int64_t) 4, "mem_18636")) {
        err = 1;
        goto cleanup;
    }
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_dev_to_dev_runs, &ctx->program->copy_dev_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpy(mem_18636.mem + (int64_t) 0, mem_18296.mem + triplayer2_9262 * (int64_t) 4, (int64_t) 4));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (memblock_alloc_device(ctx, &mem_18639, (int64_t) 4, "mem_18639")) {
        err = 1;
        goto cleanup;
    }
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_dev_to_dev_runs, &ctx->program->copy_dev_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpy(mem_18639.mem + (int64_t) 0, mem_18296.mem + triplayer3_9268 * (int64_t) 4, (int64_t) 4));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (memblock_alloc_device(ctx, &mem_18642, (int64_t) 4, "mem_18642")) {
        err = 1;
        goto cleanup;
    }
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_dev_to_dev_runs, &ctx->program->copy_dev_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpy(mem_18642.mem + (int64_t) 0, mem_18296.mem + triplayer4_9274 * (int64_t) 4, (int64_t) 4));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (memblock_alloc_device(ctx, &mem_18645, (int64_t) 4, "mem_18645")) {
        err = 1;
        goto cleanup;
    }
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_dev_to_dev_runs, &ctx->program->copy_dev_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpy(mem_18645.mem + (int64_t) 0, mem_18296.mem + triplayer5_9280 * (int64_t) 4, (int64_t) 4));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (memblock_alloc_device(ctx, &mem_18648, (int64_t) 4, "mem_18648")) {
        err = 1;
        goto cleanup;
    }
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_dev_to_dev_runs, &ctx->program->copy_dev_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpy(mem_18648.mem + (int64_t) 0, mem_18296.mem + (int64_t) 0, (int64_t) 4));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (memblock_alloc_device(ctx, &mem_18651, (int64_t) 4, "mem_18651")) {
        err = 1;
        goto cleanup;
    }
    {
        cudaEvent_t *pevents = NULL;
        
        if (ctx->profiling && !ctx->profiling_paused) {
            pevents = cuda_get_events(ctx, &ctx->program->copy_dev_to_dev_runs, &ctx->program->copy_dev_to_dev_total_runtime);
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[0], 0));
        }
        CUDA_SUCCEED_OR_RETURN(cuMemcpy(mem_18651.mem + (int64_t) 0, mem_18296.mem + (int64_t) 0, (int64_t) 4));
        if (pevents != NULL)
            CUDA_SUCCEED_FATAL(cudaEventRecord(pevents[1], 0));
    }
    if (memblock_set_device(ctx, &mem_out_18670, &mem_18636, "mem_18636") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18671, &mem_18639, "mem_18639") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18672, &mem_18642, "mem_18642") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18673, &mem_18645, "mem_18645") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18674, &mem_18648, "mem_18648") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_18675, &mem_18651, "mem_18651") != 0)
        return 1;
    prim_out_18676 = main_res_8974;
    if (memblock_set_device(ctx, &*mem_out_p_19373, &mem_out_18670, "mem_out_18670") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19374, &mem_out_18671, "mem_out_18671") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19375, &mem_out_18672, "mem_out_18672") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19376, &mem_out_18673, "mem_out_18673") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19377, &mem_out_18674, "mem_out_18674") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_19378, &mem_out_18675, "mem_out_18675") != 0)
        return 1;
    *out_prim_out_19379 = prim_out_18676;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_18651, "mem_18651") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18648, "mem_18648") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18645, "mem_18645") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18642, "mem_18642") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18639, "mem_18639") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_18636, "mem_18636") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18675, "mem_out_18675") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18674, "mem_out_18674") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18673, "mem_out_18673") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18672, "mem_out_18672") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18671, "mem_out_18671") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_18670, "mem_out_18670") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_main(struct futhark_context *ctx, bool *out0, struct futhark_u8_1d **out1, struct futhark_u8_1d **out2, struct futhark_u8_1d **out3, struct futhark_u8_1d **out4, struct futhark_u8_1d **out5, struct futhark_u8_1d **out6)
{
    bool prim_out_18676 = 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_18675;
    
    mem_out_18675.references = NULL;
    
    struct memblock_device mem_out_18674;
    
    mem_out_18674.references = NULL;
    
    struct memblock_device mem_out_18673;
    
    mem_out_18673.references = NULL;
    
    struct memblock_device mem_out_18672;
    
    mem_out_18672.references = NULL;
    
    struct memblock_device mem_out_18671;
    
    mem_out_18671.references = NULL;
    
    struct memblock_device mem_out_18670;
    
    mem_out_18670.references = NULL;
    if (ret == 0) {
        ret = futrts_entry_main(ctx, &mem_out_18670, &mem_out_18671, &mem_out_18672, &mem_out_18673, &mem_out_18674, &mem_out_18675, &prim_out_18676);
        if (ret == 0) {
            struct memblock_device counters_mem_19057 = ctx->constants->counters_mem_19057;
            struct memblock_device counters_mem_19143 = ctx->constants->counters_mem_19143;
            bool main_res_8974 = ctx->constants->main_res_8974;
            struct memblock_device mem_18296 = ctx->constants->mem_18296;
            int64_t triplayer2_9262 = ctx->constants->triplayer2_9262;
            int64_t triplayer3_9268 = ctx->constants->triplayer3_9268;
            int64_t triplayer4_9274 = ctx->constants->triplayer4_9274;
            int64_t triplayer5_9280 = ctx->constants->triplayer5_9280;
            
            *out0 = prim_out_18676;
            assert((*out1 = (struct futhark_u8_1d *) malloc(sizeof(struct futhark_u8_1d))) != NULL);
            (*out1)->mem = mem_out_18670;
            (*out1)->shape[0] = (int64_t) 4;
            assert((*out2 = (struct futhark_u8_1d *) malloc(sizeof(struct futhark_u8_1d))) != NULL);
            (*out2)->mem = mem_out_18671;
            (*out2)->shape[0] = (int64_t) 4;
            assert((*out3 = (struct futhark_u8_1d *) malloc(sizeof(struct futhark_u8_1d))) != NULL);
            (*out3)->mem = mem_out_18672;
            (*out3)->shape[0] = (int64_t) 4;
            assert((*out4 = (struct futhark_u8_1d *) malloc(sizeof(struct futhark_u8_1d))) != NULL);
            (*out4)->mem = mem_out_18673;
            (*out4)->shape[0] = (int64_t) 4;
            assert((*out5 = (struct futhark_u8_1d *) malloc(sizeof(struct futhark_u8_1d))) != NULL);
            (*out5)->mem = mem_out_18674;
            (*out5)->shape[0] = (int64_t) 4;
            assert((*out6 = (struct futhark_u8_1d *) malloc(sizeof(struct futhark_u8_1d))) != NULL);
            (*out6)->mem = mem_out_18675;
            (*out6)->shape[0] = (int64_t) 4;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
